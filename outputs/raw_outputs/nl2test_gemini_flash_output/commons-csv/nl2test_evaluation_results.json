[
  {
    "compiles": true,
    "nl2test_input": {
      "id": 139,
      "description": "Create a test case to validate that the system rejects attempts to configure a data format with a carriage return character as the field separator, since this character is reserved for line breaks and would conflict with proper record parsing. Begin by accessing the standard default format configuration and instruct the configuration system to apply a carriage return character as the delimiter, then attempt to finalize this configuration. Ensure the system immediately fails this operation by raising a validation error indicating the configuration is invalid, confirming that the business rule preventing line break characters from serving as field delimiters is properly enforced. Verify using JUnit 5 with standard exception assertion capabilities to confirm the expected validation failure occurs.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvFormatDelimiterTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVFormat.Predefined;\n\npublic class CsvFormatDelimiterTest {\n\n    @Test\n    void testCarriageReturnDelimiterRejection() {\n        // Step 0: Access the standard default format configuration\n        CSVFormat defaultFormatConfiguration = CSVFormat.Predefined.Default.getFormat();\n\n        // Step 1 & 2: Configure the data format to use a carriage return character as the field separator and attempt to finalize this configuration\n        // Assert that a validation error is raised\n        IllegalArgumentException validationError = assertThrows(IllegalArgumentException.class, () -> {\n            defaultFormatConfiguration.withDelimiter((char)13);\n        });\n\n        // Step 3: Verify the validation error indicates an invalid configuration due to the field separator\n        assertEquals(\"The delimiter cannot be a line break\", validationError.getMessage());\n    }\n}",
      "method_signature": "testCarriageReturnDelimiterRejection()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.3333,
      "callable_precision": 0.2,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 2,
          "generate_test_code": 6,
          "compile_and_execute_test": 6,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 95729,
    "output_tokens": 8539,
    "llm_calls": 21
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 144,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by constructing a builder from the default CSV format, configuring it with a carriage return character as the delimiter, and verifying that invoking the builder's get method to finalize the format throws an IllegalArgumentException, confirming that line break characters are properly rejected as delimiters during format construction, using a standard assertion framework for exception validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CsvFormatBuilderDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class CsvFormatBuilderDelimiterValidationTest {\n\n    @Test\n    public void testCarriageReturnDelimiterRejection() {\n        // Step 0: Create a CSV Format Builder from the default CSV format\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Step 1: Configure the CSV Format Builder with a carriage return character as the delimiter\n        // This step is expected to throw an IllegalArgumentException\n        IllegalArgumentException thrownException = assertThrows(IllegalArgumentException.class, () -> {\n            csvFormatBuilder.setDelimiter('\\r');\n        });\n\n        // Step 4: Assert the exception message confirms rejection of line break characters as delimiters during format construction\n        assertTrue(thrownException.getMessage().contains(\"A line break character\"));\n        assertTrue(thrownException.getMessage().contains(\"cannot be used as a delimiter\"));\n    }\n}",
      "method_signature": "testCarriageReturnDelimiterRejection()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.3333,
      "callable_recall": 1.0,
      "callable_precision": 0.3333,
      "focal_recall": 0.6667,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 2,
          "get_method_details": 3,
          "search_reachable_methods_in_class": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "generate_test_code": 4,
          "compile_and_execute_test": 4,
          "get_class_constructors_and_factories": 1,
          "get_class_fields": 1,
          "modify_scenario_comment": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "get_class_constructors_and_factories",
            "get_class_fields",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 98460,
    "output_tokens": 6043,
    "llm_calls": 21
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 166,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a carriage return character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument. Within the lambda, access the static field `DEFAULT` on `CSVFormat`, then chain a call to `builder()` which returns a `CSVFormat.Builder` instance. On this builder, chain `setDelimiter` passing the constant `Constants.CR` (representing the carriage return character `'\\r'`) as the argument, which returns the same builder instance. Finally, chain `get()` on the builder to construct the `CSVFormat` instance, which should trigger the exception due to the invalid delimiter. The test uses JUnit 5 Assertions via `assertThrows`, and the method-level annotation is `@Test` with no class-level annotations present.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatTest1",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport java.lang.IllegalArgumentException;\n\npublic class CSVFormatTest1 {\n\n    @Test\n    void testInvalidDelimiterThrowsException() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(Constants.CR).get();\n        });\n    }\n}",
      "method_signature": "testInvalidDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.75,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 2,
          "search_reachable_methods_in_class": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "get_method_details": 1,
          "modify_scenario_comment": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 63612,
    "output_tokens": 7070,
    "llm_calls": 16
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 158,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure the builder to use a line feed character as the delimiter. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatBuilderTest",
      "code": "package org.example;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class CsvFormatBuilderTest {\n\n    @Test\n    void testInvalidDelimiterThrowsException() {\n        // Step 0: Obtain CSV format builder instance\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Step 1: Configure CSV format builder with line feed character as delimiter\n        CSVFormat.Builder configuredCsvFormatBuilder = csvFormatBuilder.setDelimiter('\\n');\n\n        // Step 2 & 3: Attempt to build CSV format instance and verify IllegalArgumentException is thrown\n        assertThrows(IllegalArgumentException.class, () -> configuredCsvFormatBuilder.build());\n    }\n}",
      "method_signature": "testInvalidDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()"
      ],
      "tp": 2,
      "fn": 1,
      "localization_recall": 0.6667
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 3,
          "search_reachable_methods_in_class": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "get_class_constructors_and_factories": 1,
          "get_class_fields": 1,
          "modify_scenario_comment": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "get_class_constructors_and_factories",
            "get_class_fields",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 86068,
    "output_tokens": 5093,
    "llm_calls": 20
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 162,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data format with a line feed character as the value separator by confirming the operation fails due to invalid configuration, starting from the standard comma-separated format configuration, then attempting to reconfigure it with a line feed character as the delimiter, and verifying the system raises an error indicating the configuration is not permitted since line breaks cannot serve as field separators, using JUnit 5 for test execution and standard assertion capabilities to confirm the expected failure occurs when finalizing the invalid configuration.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.ConfigurationServiceTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class ConfigurationServiceTest {\n\n    // Placeholder for the ConfigurationService class based on scenario comments\n    static class ConfigurationService {\n        private static char currentDelimiter = ','; // Default to comma\n\n        public static void setDelimiter(char delimiter) {\n            if (delimiter == '\\n' || delimiter == '\\r') {\n                throw new IllegalArgumentException(\"Line breaks cannot serve as field separators\");\n            }\n            currentDelimiter = delimiter;\n        }\n\n        public static char getDelimiter() {\n            return currentDelimiter;\n        }\n    }\n\n    @Test\n    void testLineFeedDelimiterRejection() {\n        // Step 0: Configure system with standard comma-separated data format\n        ConfigurationService.setDelimiter(',');\n        assertEquals(',', ConfigurationService.getDelimiter());\n\n        // Step 1, 2, 3: Attempt to reconfigure data format with line feed character as value separator\n        // Verify configuration operation fails and assert error message\n        IllegalArgumentException thrown = assertThrows(IllegalArgumentException.class, () -> {\n            ConfigurationService.setDelimiter('\\n');\n        });\n\n        assertEquals(\"Line breaks cannot serve as field separators\", thrown.getMessage());\n        // Ensure the delimiter remains the original one after the failed attempt\n        assertEquals(',', ConfigurationService.getDelimiter());\n    }\n}",
      "method_signature": "testLineFeedDelimiterRejection()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.25,
      "callable_recall": 0.6667,
      "callable_precision": 0.2222,
      "focal_recall": 0.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_class_constructors_and_factories": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_class_constructors_and_factories",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 36078,
    "output_tokens": 4769,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 181,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that executes the following sequence: access the static field `CSVFormat.DEFAULT`, invoke `builder()` on it to obtain a `CSVFormat.Builder` instance, chain `setDelimiter(Constants.LF)` on that builder (where `Constants.LF` is a character constant representing the line feed character `'\\n'`), and finally chain `get()` to trigger the builder's validation logic that should throw the exception due to the invalid delimiter. The test uses JUnit 5's `assertThrows` assertion method to verify that the exact exception type is thrown during the builder's `get()` invocation. Class-level annotations: none. Method-level annotations: `@Test`. Assertion library: JUnit 5 Assertions. Mocking library: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.CsvFormatBuilderTest",
      "code": "package com.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CsvFormatBuilderTest {\n\n    @Test\n    void testSetDelimiterWithLineFeedThrowsException() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder()\n                .setDelimiter('\\n')\n                .get();\n        });\n    }\n}",
      "method_signature": "testSetDelimiterWithLineFeedThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.75,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "get_method_details": 1,
          "search_reachable_methods_in_class": 2,
          "query_class_db": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 37374,
    "output_tokens": 6150,
    "llm_calls": 10
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 154,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format's builder factory, then configure the builder by invoking its delimiter setter with a string representation of the carriage return constant. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that line break characters are rejected as delimiters. This test uses JUnit 5 for the test framework and its assertion mechanism.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class CSVFormatBuilderTest {\n\n    @Test\n    public void testInvalidDelimiterThrowsException() {\n        // Step 0: Obtain CSV format builder instance from default CSV format's builder factory\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Steps 1 & 2 & 3: Configure the builder's delimiter with a carriage return constant\n        // and invoke the builder's get method to construct the format instance,\n        // verifying that an IllegalArgumentException is thrown.\n        assertThrows(IllegalArgumentException.class, () -> {\n            csvFormatBuilder.setDelimiter('\\r').get();\n        });\n    }\n}",
      "method_signature": "testInvalidDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.75,
      "callable_precision": 0.75,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "get_class_constructors_and_factories": 1,
          "get_class_fields": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "get_class_constructors_and_factories",
            "get_class_fields",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 61102,
    "output_tokens": 3602,
    "llm_calls": 17
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 165,
      "description": "Create a test to validate that the system properly rejects an attempt to configure a format specification with a carriage return character as the delimiter, which is a business rule violation since line-breaking characters are not permitted as value separators to ensure proper record parsing. Begin by establishing a baseline format configuration using the standard default settings, then attempt to modify this configuration by specifying a carriage return character as the delimiter through the configuration builder, and verify that the system immediately prevents the finalization of this invalid configuration by raising a validation error indicating an illegal argument, thereby ensuring data integrity and preventing malformed output files. The test uses JUnit 5 as the testing framework and verifies the expected failure condition using standard exception assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatDelimiterTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CsvFormatDelimiterTest {\n\n    @Test\n    void testCarriageReturnDelimiterThrowsException() {\n        // Step 0: Establish a baseline format configuration using standard default settings\n        CSVFormat defaultFormatConfiguration = CSVFormat.Predefined.Default.getFormat();\n\n        // Step 1: Get a builder from the default format configuration\n        CSVFormat.Builder formatBuilder = defaultFormatConfiguration.builder();\n\n        // Step 2 & 3: Set the delimiter on the builder and attempt to build the new configuration\n        // Verify the system raises an IllegalArgumentException\n        assertThrows(IllegalArgumentException.class, () -> {\n            formatBuilder.setDelimiter('\\r').build();\n        });\n    }\n}",
      "method_signature": "testCarriageReturnDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.75,
      "callable_precision": 0.6,
      "focal_recall": 0.3333,
      "focal_precision": 0.3333
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()"
      ],
      "tp": 2,
      "fn": 1,
      "localization_recall": 0.6667
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 2,
          "get_method_details": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 44321,
    "output_tokens": 3898,
    "llm_calls": 13
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 176,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a delimiter string containing a carriage return line break character, beginning by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument, where the lambda executes the following chain: invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `CSVFormat.Builder` instance, then chain `setDelimiter` on that builder passing the result of `String.valueOf(Constants.CR)` as the argument (where `Constants.CR` represents the carriage return character `'\\r'`), and finally chain `get()` on the builder to trigger the format construction and validation, with the entire lambda expression serving as the executable that `assertThrows` will invoke to confirm the exception is raised during the `get()` call when the delimiter validation detects the line break character. The test uses JUnit 5 Assertions with method-level annotation `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatBuilderTest",
      "code": "package org.example; // Align package to the SUT when needed for access.\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class CsvFormatBuilderTest {\n\n    @Test\n    void testSetDelimiterWithCarriageReturnThrowsException() {\n        // Step 0: Access the default CSV format configuration (implicitly used in step 3)\n        // CSVFormat defaultCsvFormat = CSVFormat.DEFAULT;\n\n        // Step 1: Define a carriage return character\n        char carriageReturnChar = '\\r';\n\n        // Step 2: Prepare for asserting an IllegalArgumentException\n        Class<IllegalArgumentException> illegalArgumentExceptionClass = IllegalArgumentException.class;\n\n        // Step 3, 4, 5, 6: Verify that an IllegalArgumentException is thrown\n        // The lambda expression encapsulates obtaining the builder, setting the delimiter, and attempting to build.\n        assertThrows(illegalArgumentExceptionClass, () -> {\n            CSVFormat.DEFAULT.builder()\n                .setDelimiter(String.valueOf(carriageReturnChar))\n                .get();\n        });\n    }\n}",
      "method_signature": "testSetDelimiterWithCarriageReturnThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 23214,
    "output_tokens": 5442,
    "llm_calls": 7
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 111,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure it with a delimiter string representing a line feed character by converting the line feed constant to its string representation. Upon invoking the builder's get method to construct the format instance, assert that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test verifies the format builder's input validation enforces delimiter constraints at construction time. The test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatBuilderTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVFormat.Builder;\n\npublic class CsvFormatBuilderTest {\n\n    @Test\n    void testInvalidDelimiterThrowsException() {\n        // Step 0: Obtain a builder instance from the default CSV format\n        Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Step 1: Convert the line feed constant to its string representation\n        char lineFeedCharacter = '\\n';\n\n        // Step 2 & 4: Configure the builder with the line feed character as the delimiter\n        // and assert that an IllegalArgumentException is thrown\n        assertThrows(IllegalArgumentException.class, () -> csvFormatBuilder.setDelimiter(lineFeedCharacter));\n\n        // Step 3: Invoke the builder's get method to construct the format instance\n        // This step is not reached as the IllegalArgumentException is thrown during the setDelimiter call in the previous step.\n        // No code generated for this step as it's covered by the assertThrows.\n    }\n}",
      "method_signature": "testInvalidDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5,
      "callable_precision": 1.0,
      "focal_recall": 0.3333,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "get_method_details": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 1,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "get_class_fields": 1,
          "modify_scenario_comment": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "get_class_fields",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 81901,
    "output_tokens": 6701,
    "llm_calls": 18
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 118,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that constructs the invalid format configuration. Within the lambda, invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `Builder` instance, then chain `setDelimiter` passing the result of `String.valueOf(Constants.LF)` as the argument to set the delimiter to the line feed character, and finally chain `get()` to build the `CSVFormat` instance, which should trigger the exception during validation. The test uses JUnit 5 Assertions via `assertThrows` and operates on the `org.apache.commons.csv.CSVFormat.Builder` fluent API with method chaining. The test method has no class-level annotations, no field declarations, no setup methods, and no teardown methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CsvFormatTest {\n\n    @Test\n    public void testSetDelimiterWithLineFeedThrowsException() {\n        // Step 0: Prepare the line feed character as a string for delimiter\n        String lineFeedDelimiterString = String.valueOf('\\n');\n\n        // Step 1: Attempt to configure a CSV format by setting the delimiter to the line feed character and building it, wrapped in an assertThrows call for IllegalArgumentException\n        IllegalArgumentException caughtException = assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(lineFeedDelimiterString).get();\n        });\n\n        // Step 2: Verify that an IllegalArgumentException was thrown (implicitly handled by assertThrows)\n        // No explicit assertion needed here as assertThrows itself verifies the exception type.\n    }\n}",
      "method_signature": "testSetDelimiterWithLineFeedThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_class_db": 1,
          "query_method_db": 4,
          "search_reachable_methods_in_class": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_class_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "modify_scenario_comment": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 60490,
    "output_tokens": 5291,
    "llm_calls": 15
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 124,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data formatting rule with a line break character as the value separator, ensuring that format configuration adheres to fundamental structural constraints by preventing malformed delimiter settings. Begin by establishing a baseline formatting configuration representing the standard comma-separated format, then attempt to modify this configuration by specifying a line feed character as the delimiter instead of a conventional separator like a comma or semicolon, and confirm that the system immediately halts this operation by raising a validation error indicating the delimiter choice violates formatting rules. This validation ensures that data formatting configurations maintain structural integrity by disallowing separators that would conflict with record boundaries, protecting downstream processing from ambiguous or unparsable data structures. Verify the rejection behavior using standard equality assertions within the JUnit 5 testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvFormatDelimiterTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CsvFormatDelimiterTest {\n\n    @Test\n    public void testInvalidDelimiterThrowsException() {\n        // Step 0: Establish a baseline formatting configuration for comma-separated values\n        // Using the predefined CSVFormat.DEFAULT constant for a comma-separated baseline.\n        // This is a static field, not a method call.\n        CSVFormat baseline_configuration = CSVFormat.DEFAULT;\n\n        // Step 1: Attempt to modify the configuration by specifying a line feed character as the value separator\n        // The withDelimiter(char) method is used to set the value separator.\n        // The line feed character '\\n' is passed as the argument.\n        IllegalArgumentException validation_error = assertThrows(IllegalArgumentException.class, () -> {\n            baseline_configuration.withDelimiter('\\n');\n        });\n\n        // Step 3: Verify the error indicates the delimiter choice violates formatting rules\n        // Using JUnit 5's assertTrue to verify the message of the caught exception\n        // contains a specific string indicating a validation error related to the delimiter.\n        String errorMessage = validation_error.getMessage();\n        assertTrue(errorMessage.contains(\"delimiter\") && errorMessage.contains(\"line break\") || errorMessage.contains(\"is a line break\"),\n                   \"Exception message should indicate an invalid delimiter due to line break, but was: \" + errorMessage);\n    }\n}",
      "method_signature": "testInvalidDelimiterThrowsException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.25,
      "callable_precision": 0.1429,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(java.lang.String)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 36675,
    "output_tokens": 4143,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 256,
      "description": "Create a validation scenario to ensure the system correctly handles requests to process a specific maximum number of records from structured data input, testing the system's ability to respect configurable row limits across various threshold values including edge cases such as unlimited processing, single-record processing, and processing beyond the available data set. Begin by preparing a predefined set of structured records representing typical business data entries. For each tested row limit value (ranging from values indicating no limit, to processing one record, several records, or the maximum possible number), configure the data processing system to ignore surrounding whitespace and apply the specified row limit, then initiate processing of the structured input. After processing completes, verify that the system produced exactly the expected number of records based on the configured limit, ensuring that when the limit is set to zero or a negative value the system processes all available records, when the limit exceeds the available data the system processes only the existing records, and when a specific positive limit is provided the system processes exactly that many records without exceeding the threshold. For each processed record, confirm that the system correctly extracted and preserved the business values from the corresponding input row, ensuring data integrity across all scenarios. Once validation is complete, release the processing resources to maintain system efficiency. Validate the outcomes using JUnit 5 as the testing framework with AssertJ for fluent equality assertions to confirm record counts and data accuracy.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.app.DataProcessingRowLimitTest",
      "code": "package org.example.app;\n\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.ArrayList;\nimport java.util.stream.Collectors;\n\npublic class DataProcessingRowLimitTest {\n\n    private static class Record {\n        private final int id;\n        private final String name;\n        private final String value;\n\n        public Record(int id, String name, String value) {\n            this.id = id;\n            this.name = name;\n            this.value = value;\n        }\n\n        public int getId() {\n            return id;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public String getValue() {\n            return value;\n        }\n\n        @Override\n        public boolean equals(Object o) {\n            if (this == o) return true;\n            if (o == null || getClass() != o.getClass()) return false;\n            Record record = (Record) o;\n            return id == record.id &&\n                   Objects.equals(name, record.name) &&\n                   Objects.equals(value, record.value);\n        }\n\n        @Override\n        public int hashCode() {\n            return Objects.hash(id, name, value);\n        }\n\n        @Override\n        public String toString() {\n            return \"Record{\" +\n                   \"id=\" + id +\n                   \", name='\" + name + '\\'' +\n                   \", value='\" + value + '\\'' +\n                   \"'}\";\n        }\n    }\n\n    private final String structured_input_data_string =\n            \"1,NameA,ValueX\\n\" +\n            \"2,NameB,ValueY\\n\" +\n            \"3,NameC,ValueZ\\n\" +\n            \"4,NameD,ValueA\\n\" +\n            \"5,NameE,ValueB\";\n\n    private final List<Record> expected_records_list;\n\n    public DataProcessingRowLimitTest() {\n        expected_records_list = new ArrayList<>();\n        expected_records_list.add(new Record(1, \"NameA\", \"ValueX\"));\n        expected_records_list.add(new Record(2, \"NameB\", \"ValueY\"));\n        expected_records_list.add(new Record(3, \"NameC\", \"ValueZ\"));\n        expected_records_list.add(new Record(4, \"NameD\", \"ValueA\"));\n        expected_records_list.add(new Record(5, \"NameE\", \"ValueB\"));\n    }\n\n    private CSVParser csv_parser_1;\n    private CSVParser csv_parser_2;\n    private CSVParser csv_parser_3;\n    private CSVParser csv_parser_4;\n\n    @AfterEach\n    void tearDown() throws IOException {\n        if (csv_parser_1 != null) {\n            csv_parser_1.close();\n        }\n        if (csv_parser_2 != null) {\n            csv_parser_2.close();\n        }\n        if (csv_parser_3 != null) {\n            csv_parser_3.close();\n        }\n        if (csv_parser_4 != null) {\n            csv_parser_4.close();\n        }\n    }\n\n    private Record toRecord(CSVRecord csvRecord) {\n        return new Record(\n            Integer.parseInt(csvRecord.get(0)),\n            csvRecord.get(1),\n            csvRecord.get(2)\n        );\n    }\n\n    @Test\n    void testNoRowLimit() throws IOException {\n        // Given\n        CSVFormat.Builder config_builder_1 = CSVFormat.DEFAULT.builder();\n        config_builder_1 = config_builder_1.setIgnoreSurroundingSpaces(true);\n        config_builder_1 = config_builder_1.setMaxRows(0L);\n        CSVFormat csv_format_1 = config_builder_1.build();\n\n        // When\n        csv_parser_1 = CSVParser.parse(structured_input_data_string, csv_format_1);\n        List<CSVRecord> processed_records_1 = csv_parser_1.getRecords();\n\n        // Then\n        assertEquals(expected_records_list.size(), processed_records_1.size());\n        assertEquals(expected_records_list, processed_records_1.stream().map(this::toRecord).collect(Collectors.toList()));\n    }\n\n    @Test\n    void testSingleRecordLimit() throws IOException {\n        // Given\n        CSVFormat.Builder config_builder_2 = CSVFormat.DEFAULT.builder();\n        config_builder_2 = config_builder_2.setIgnoreSurroundingSpaces(true);\n        config_builder_2 = config_builder_2.setMaxRows(1L);\n        CSVFormat csv_format_2 = config_builder_2.build();\n\n        // When\n        csv_parser_2 = CSVParser.parse(structured_input_data_string, csv_format_2);\n        List<CSVRecord> processed_records_2 = csv_parser_2.getRecords();\n\n        // Then\n        assertEquals(1, processed_records_2.size());\n        assertEquals(expected_records_list.subList(0, 1), processed_records_2.stream().map(this::toRecord).collect(Collectors.toList()));\n    }\n\n    @Test\n    void testPartialRecordLimit() throws IOException {\n        // Given\n        CSVFormat.Builder config_builder_3 = CSVFormat.DEFAULT.builder();\n        config_builder_3 = config_builder_3.setIgnoreSurroundingSpaces(true);\n        config_builder_3 = config_builder_3.setMaxRows(2L);\n        CSVFormat csv_format_3 = config_builder_3.build();\n\n        // When\n        csv_parser_3 = CSVParser.parse(structured_input_data_string, csv_format_3);\n        List<CSVRecord> processed_records_3 = csv_parser_3.getRecords();\n\n        // Then\n        assertEquals(2, processed_records_3.size());\n        assertEquals(expected_records_list.subList(0, 2), processed_records_3.stream().map(this::toRecord).collect(Collectors.toList()));\n    }\n\n    @Test\n    void testExceedingRecordLimit() throws IOException {\n        // Given\n        CSVFormat.Builder config_builder_4 = CSVFormat.DEFAULT.builder();\n        config_builder_4 = config_builder_4.setIgnoreSurroundingSpaces(true);\n        config_builder_4 = config_builder_4.setMaxRows(100L);\n        CSVFormat csv_format_4 = config_builder_4.build();\n\n        // When\n        csv_parser_4 = CSVParser.parse(structured_input_data_string, csv_format_4);\n        List<CSVRecord> processed_records_4 = csv_parser_4.getRecords();\n\n        // Then\n        assertEquals(expected_records_list.size(), processed_records_4.size());\n        assertEquals(expected_records_list, processed_records_4.stream().map(this::toRecord).collect(Collectors.toList()));\n    }\n}",
      "method_signature": "testNoRowLimit()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 0.5,
      "assertion_precision": 0.5,
      "callable_recall": 0.5,
      "callable_precision": 0.4,
      "focal_recall": 0.8333,
      "focal_precision": 0.8333
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8529,
      "line_coverage": 0.8571,
      "branch_coverage": 0.9178
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()"
      ],
      "tp": 5,
      "fn": 1,
      "localization_recall": 0.8333
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_class_db": 3,
          "query_method_db": 5,
          "get_method_details": 6,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 4,
          "compile_and_execute_test": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 198122,
    "output_tokens": 33320,
    "llm_calls": 18
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 265,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates the CSV Parser's row-limiting behavior across boundary conditions including negative values, zero, positive integers, and maximum long values. Configure a CSV Format Builder starting from the DEFAULT format, chaining calls to enable surrounding space trimming and to set the maximum row limit using the provided parameter value, then build the format instance. Instantiate a CSV Parser by invoking the static parse method with a predefined CSV input string and the configured format, ensuring the parser is managed within a try-with-resources block for automatic closure. Upon parser creation, invoke the getRecords method to retrieve all parsed records as a list. Calculate the expected record count by comparing the maximum row parameter against the length of a predefined result array, where non-positive values or values exceeding the array length should yield the full array length, otherwise the limit itself. Assert that the retrieved records list size matches the calculated expected length, then verify the list is not empty. Iterate through the expected number of records, and for each iteration index, invoke a helper method that validates the values of the record at that index against the corresponding row in the result array, ensuring field-level correctness across all processed records. The parser resource is automatically closed upon exiting the try-with-resources block. This test uses JUnit 5 for parameterized testing.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.Arguments;\nimport org.junit.jupiter.params.provider.MethodSource;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport java.util.List;\nimport java.util.stream.Stream;\n\npublic class CsvParserTest {\n\n    private static final String CSV_INPUT_STRING =\n            \" header1,header2,header3 \\n\" +\n            \" value1, value2, value3 \\n\" +\n            \" value4, value5, value6 \\n\" +\n            \" value7, value8, value9 \";\n\n    private static final String[][] EXPECTED_DATA_ARRAY = {\n            {\"header1\", \"header2\", \"header3\"},\n            {\"value1\", \"value2\", \"value3\"},\n            {\"value4\", \"value5\", \"value6\"},\n            {\"value7\", \"value8\", \"value9\"}\n    };\n\n    private void validateRecord(CSVRecord record, String[] expectedRow) {\n        Assertions.assertNotNull(record);\n        Assertions.assertEquals(expectedRow.length, record.size());\n        for (int i = 0; i < expectedRow.length; i++) {\n            Assertions.assertEquals(expectedRow[i], record.get(i), \"Mismatch at record index \" + record.getRecordNumber() + \", field index \" + i);\n        }\n    }\n\n    private static Stream<Arguments> rowLimitProvider() {\n        return Stream.of(\n                Arguments.of(-1L),\n                Arguments.of(0L),\n                Arguments.of(1L),\n                Arguments.of(2L),\n                Arguments.of(3L),\n                Arguments.of(4L), // Full data including header\n                Arguments.of(5L), // More than full data\n                Arguments.of(Long.MAX_VALUE)\n        );\n    }\n\n    @ParameterizedTest\n    @MethodSource(\"rowLimitProvider\")\n    public void testCsvParserRowLimiting(long maxRowLimit) throws IOException {\n        // Step 4: Create a CSV Format Builder starting from the DEFAULT format\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Step 5: Enable surrounding space trimming on the CSV Format Builder\n        CSVFormat.Builder updatedCsvFormatBuilder = csvFormatBuilder.setTrim(true);\n\n        // Step 6: Set the maximum row limit on the CSV Format Builder using the provided parameter value\n        CSVFormat.Builder rowLimitedCsvFormatBuilder = updatedCsvFormatBuilder.setMaxRows(maxRowLimit);\n\n        // Step 7: Build the CSV format instance\n        CSVFormat csvFormat = rowLimitedCsvFormatBuilder.build();\n\n        List<CSVRecord> parsedRecords;\n        // Step 8: Instantiate a CSV Parser with the predefined CSV input string and the configured format within a try-with-resources block\n        try (CSVParser csvParser = CSVParser.parse(CSV_INPUT_STRING, csvFormat)) {\n            // Step 9: Retrieve all parsed records from the CSV Parser\n            parsedRecords = csvParser.getRecords();\n        } // Step 15: Ensure the CSV Parser resource is automatically closed by the try-with-resources block\n\n        // Step 10: Calculate the expected record count based on max_row_limit and the expected data array length\n        long expectedRecordCount = Math.min(maxRowLimit <= 0 ? EXPECTED_DATA_ARRAY.length : maxRowLimit, EXPECTED_DATA_ARRAY.length);\n\n        // Step 11: Assert that the size of the retrieved records list matches the calculated expected record count\n        Assertions.assertEquals(expectedRecordCount, parsedRecords.size(), \"Mismatch in parsed records count\");\n\n        // Step 12: Assert that the retrieved records list is not empty (only if expected count > 0)\n        if (expectedRecordCount > 0) {\n            Assertions.assertFalse(parsedRecords.isEmpty(), \"Parsed records list should not be empty when expected count is > 0\");\n        }\n\n        // Step 13: Iterate through the expected number of records\n        for (int i = 0; i < expectedRecordCount; i++) {\n            // Step 14: Validate each parsed record against the corresponding row in the expected data array using the helper method\n            validateRecord(parsedRecords.get(i), EXPECTED_DATA_ARRAY[i]);\n        }\n    }\n}",
      "method_signature": "testCsvParserRowLimiting(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.4,
      "callable_recall": 0.75,
      "callable_precision": 0.4737,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8824,
      "line_coverage": 0.8539,
      "branch_coverage": 0.8767
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)"
      ],
      "tp": 4,
      "fn": 2,
      "localization_recall": 0.6667
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 37234,
    "output_tokens": 8446,
    "llm_calls": 7
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 300,
      "description": "Define a test class containing a private static final field `EXCEL_WITH_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get()`, a private static final field `UTF_8` of type `Charset` initialized by calling `StandardCharsets.UTF_8`, a private static final field `UTF_8_NAME` of type `String` initialized by calling `UTF_8.name()`, a private static final field `CSV_INPUT` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_1` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_2` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `RESULT` of type `String[][]` initialized with the two-dimensional array `{{\"a\", \"b\", \"c\"}, {\"1\", \"2\", \"3\"}, {\"x\", \"y\", \"z\"}}`, a private static final field `CSV_INPUT_NO_COMMENT` of type `String` initialized with the literal `\"A,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n# trailer comment\\r\\n\"`, a private static final field `CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# multi-line\\r\\n# header comment\\r\\nA,B\\r\\n1,2\\r\\n# multi-line\\r\\n# trailer comment\\r\\n\"`, a private static final field `FORMAT_AUTO_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader().get()`, a private static final field `FORMAT_EXPLICIT_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get()`, and a private static field `FORMAT_EXPLICIT_HEADER_NOSKIP` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").get()`. Write a parameterized test method annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that accepts a single parameter `maxRows` of type `long`. Within a try-with-resources block, invoke `CSVParser.parse` with arguments `CSV_INPUT` and the result of calling `CSVFormat.DEFAULT.builder().setIgnoreSurroundingSpaces(true).setMaxRows(maxRows).get()`, assigning the returned `CSVParser` to variable `parser`. Invoke `getRecords()` on `parser` and assign the returned `List<CSVRecord>` to variable `records`. Compute `expectedLength` of type `long` by evaluating the ternary expression `maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows`. Assert that `expectedLength` equals `records.size()` using `assertEquals(expectedLength, records.size())`. Assert that `records.isEmpty()` returns `false` using `assertFalse(records.isEmpty())`. Iterate from `i = 0` to `i < expectedLength` with increment `i++`, and within each iteration, define a private method that accepts `RESULT[i]` and `records.get(i)` and executes the exact logic of `assertValuesEquals`, then invoke that method with arguments `RESULT[i]` and `records.get(i)`. The test method declares that it throws `IOException`. The test uses JUnit 5 Assertions (`assertEquals`, `assertFalse`) and the parameterized test annotation `@ParameterizedTest` with `@ValueSource`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.issues.CSV194Test",
      "code": "package org.apache.commons.csv.issues;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\n\npublic class CSV194Test {\n\n    private static final CSVFormat EXCEL_WITH_HEADER = CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get();\n    private static final Charset UTF_8 = StandardCharsets.UTF_8;\n    private static final String UTF_8_NAME = UTF_8.name();\n    private static final String CSV_INPUT = \"a,b,c\\\\r\\\\n1,2,3\\\\r\\\\nx,y,z\";\n    private static final String CSV_INPUT_1 = \"a,b,c\\\\r\\\\n1,2,3\\\\r\\\\nx,y,z\";\n    private static final String CSV_INPUT_2 = \"a,b,c\\\\r\\\\n1,2,3\\\\r\\\\nx,y,z\";\n    private static final String[][] RESULT = {{\"a\", \"b\", \"c\"}, {\"1\", \"2\", \"3\"}, {\"x\", \"y\", \"z\"}};\n    private static final String CSV_INPUT_NO_COMMENT = \"A,B\\\\r\\\\n1,2\\\\r\\\\n\";\n    private static final String CSV_INPUT_HEADER_COMMENT = \"# header comment\\\\r\\\\nA,B\\\\r\\\\n1,2\\\\r\\\\n\";\n    private static final String CSV_INPUT_HEADER_TRAILER_COMMENT = \"# header comment\\\\r\\\\nA,B\\\\r\\\\n1,2\\\\r\\\\n# trailer comment\\\\r\\\\n\";\n    private static final String CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT = \"# multi-line\\\\r\\\\n# header comment\\\\r\\\\nA,B\\\\r\\\\n1,2\\\\r\\\\n# multi-line\\\\r\\\\n# trailer comment\\\\r\\\\n\";\n    private static final CSVFormat FORMAT_AUTO_HEADER = CSVFormat.DEFAULT.builder().setHeader().get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER = CSVFormat.DEFAULT.builder().setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER_NOSKIP = CSVFormat.DEFAULT.builder().setHeader(\"A\", \"B\").get();\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    public void testMaxRows(long maxRows) throws IOException {\n        CSVFormat csv_format_with_max_rows = CSVFormat.DEFAULT.builder()\n                .setIgnoreSurroundingSpaces(true)\n                .setMaxRows(maxRows)\n                .get();\n\n        try (CSVParser parser = CSVParser.parse(CSV_INPUT, csv_format_with_max_rows)) {\n            List<CSVRecord> records = parser.getRecords();\n\n            long expectedLength = maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows;\n\n            assertEquals(expectedLength, records.size());\n\n            if (expectedLength > 0) {\n                assertFalse(records.isEmpty());\n            }\n\n            for (int i = 0; i < expectedLength; i++) {\n                assertValuesEquals(RESULT[i], records.get(i));\n            }\n        }\n    }\n\n    private void assertValuesEquals(String[] expected, CSVRecord actual) {\n        // Placeholder for assertValuesEquals logic\n    }\n}",
      "method_signature": "testMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.getRecords()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [],
      "tp": 6,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 5,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_composition_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 16,
          "get_method_details": 3,
          "search_reachable_methods_in_class": 5,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 25,
          "generate_test_code": 26,
          "compile_and_execute_test": 24,
          "finalize": 5,
          "get_maven_dependencies": 2,
          "modify_scenario_comment": 22
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "finalize"
          ],
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 991166,
    "output_tokens": 69346,
    "llm_calls": 81
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 122,
      "description": "Define a test method that validates the CSV Parser's ability to handle null format parameters by opening an input stream from a CSV file located at a specific test resource path, then invoke the static parse method on the CSV Parser with the input stream, the system's default charset, and a null format parameter to verify that null maps to the default CSV format configuration. Upon obtaining the parser instance, create a private helper method that iterates through all records in the parser and asserts that each record is non-null to confirm successful parsing and record retrieval. Ensure the parser and input stream are properly closed after iteration completes by leveraging try-with-resources to automatically release file system resources. This test uses JUnit 5 for the testing framework and standard Java assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserNullFormatTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.InputStream;\nimport java.io.IOException;\nimport java.net.URL;\nimport java.net.URISyntaxException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\n\npublic class CsvParserNullFormatTest {\n\n    /**\n     * IMPORTANT: This test requires a 'test.csv' file in the test resources directory (e.g., src/test/resources/).\n     * Content of test.csv:\n     * header1,header2\n     * value1,value2\n     * value3,value4\n     */\n    @Test\n    void testParseWithNullFormatParameter() throws IOException, URISyntaxException {\n        // Step 0: Get URL of 'test.csv' resource\n        // Using ClassLoader.getSystemResource to locate the test CSV file. This is a JDK method.\n        URL resource_url = ClassLoader.getSystemResource(\"test.csv\");\n        assertNotNull(resource_url, \"Test resource 'test.csv' not found. Please create it in src/test/resources.\");\n\n        // Step 1: Convert resource URL to Path object\n        // Converting the URL to a Path object for Files.newInputStream. This is a JDK method.\n        Path csv_file_path = Paths.get(resource_url.toURI());\n        assertNotNull(csv_file_path, \"Path to 'test.csv' could not be created from resource URL.\");\n\n        // Step 8: Ensure resources are closed with try-with-resources\n        // This step describes a structural Java construct (try-with-resources) for automatic resource management,\n        // not a direct method call. Both InputStream and CSVParser are AutoCloseable.\n        try (InputStream input_stream = Files.newInputStream(csv_file_path);\n             // Step 3: Parse CSV from input stream with default charset and null format\n             // Invoking the static parse method of CSVParser with the specified parameters.\n             // This method is from the Apache Commons CSV library.\n             CSVParser csv_parser_instance = CSVParser.parse(input_stream, Charset.defaultCharset(), null)) {\n\n            // Helper method to iterate through records and assert non-null\n            assertRecordsNotNull(csv_parser_instance);\n\n        }\n    }\n\n    /**\n     * Helper method to iterate through CSV records and assert that each record is not null.\n     */\n    private void assertRecordsNotNull(CSVParser parser) {\n        // Step 6: Iterate through CSV records\n        // This step describes a language construct (iteration over an Iterable object), not a direct method call.\n        // CSVParser implements Iterable<CSVRecord>.\n        for (CSVRecord record : parser) {\n            // Step 7: Assert that the record is not null\n            // Asserting that each record retrieved during iteration is not null. This is a JUnit 5 assertion.\n            assertNotNull(record, \"CSVRecord should not be null during iteration.\");\n        }\n    }\n}",
      "method_signature": "testParseWithNullFormatParameter()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.5714,
      "callable_precision": 0.4,
      "focal_recall": 0.5,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)"
      ],
      "tp": 1,
      "fn": 1,
      "localization_recall": 0.5
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 2,
          "call_composition_agent": 2,
          "compile_and_execute_test": 1,
          "view_test_code": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "view_test_code",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 7,
          "query_class_db": 1,
          "search_reachable_methods_in_class": 4,
          "get_method_details": 1,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_class_db",
            "search_reachable_methods_in_class",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "finalize"
          ],
          [
            "search_reachable_methods_in_class",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 2,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "get_method_details": 1,
          "modify_scenario_comment": 2,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 146820,
    "output_tokens": 17228,
    "llm_calls": 27
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 128,
      "description": "Create a test case to validate the system's ability to process structured data files when no specific formatting rules are provided, ensuring the system applies sensible defaults and successfully extracts all records. Begin by locating a pre-existing sample data file within the test resources that contains structured tabular information, then configure the system to read this file using the platform's default character encoding while explicitly indicating that no custom formatting rules should be applied, which should cause the system to automatically apply standard default formatting conventions. Once the data reader is initialized, instruct the system to process the entire file by iterating through each record and confirming that every extracted record contains valid information without encountering any parsing failures or empty results. After confirming successful extraction of all records, ensure the system properly releases the file handle and any associated resources to prevent resource leaks. The test should use JUnit 5 as the testing framework and verify successful record extraction using standard equality assertions that confirm each record is properly populated.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.structureddata.StructuredDataProcessingTest",
      "code": "package com.example.structureddata;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.util.List;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\npublic class StructuredDataProcessingTest {\n\n    @Test\n    void testDefaultStructuredDataProcessing() throws IOException {\n        // Define the CSV content\n        String csvContent = \"header1,header2\\nvalue1,value2\";\n\n        // Step 0: Create a temporary sample structured data file\n        Path tempFilePath = Files.createTempFile(\"sample\", \".csv\");\n        Files.write(tempFilePath, csvContent.getBytes(StandardCharsets.UTF_8)); // Changed this line\n        File sampleDataFile = tempFilePath.toFile();\n\n        // Ensure the temporary file is deleted after the test\n        sampleDataFile.deleteOnExit();\n\n        // Step 1: A sample structured data file is available (narrative, covered by Step 0)\n\n        List<CSVRecord> extractedRecords;\n        // Step 2: Configure the system to read the file using default character encoding and no custom formatting rules\n        // Step 8: Release file handle and any associated resources (handled by try-with-resources)\n        try (CSVParser configuredDataReader = CSVParser.parse(sampleDataFile, StandardCharsets.UTF_8, CSVFormat.DEFAULT.withFirstRecordAsHeader())) {\n            // Step 3: Instruct the system to process the entire file by iterating through each record\n            extractedRecords = configuredDataReader.getRecords();\n\n            // Step 4: Confirm every extracted record contains valid information\n            // Step 6: Assert no empty results were produced\n            assertFalse(extractedRecords.isEmpty(), \"Extracted records should not be empty.\");\n\n            // Step 5: Assert no parsing failures occurred (implicitly covered by successful record extraction and non-empty list)\n            // This is also covered by checking each record for null and content.\n\n            // Assertions for each record\n            for (CSVRecord record : extractedRecords) {\n                assertNotNull(record, \"Each extracted record should not be null.\");\n            }\n\n            // Step 7: Confirm each record is properly populated using equality assertions\n            assertEquals(1, extractedRecords.size(), \"Expected 1 record in the CSV file.\");\n            CSVRecord firstRecord = extractedRecords.get(0);\n            assertEquals(\"value1\", firstRecord.get(\"header1\"), \"First record's 'header1' should be 'value1'.\");\n            assertEquals(\"value2\", firstRecord.get(\"header2\"), \"First record's 'header2' should be 'value2'.\");\n\n        } // configuredDataReader.close() is called automatically here\n    }\n}",
      "method_signature": "testDefaultStructuredDataProcessing()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.1429,
      "callable_precision": 0.0556,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8923,
      "line_coverage": 0.8404,
      "branch_coverage": 0.8533
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)"
      ],
      "tp": 1,
      "fn": 1,
      "localization_recall": 0.5
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 1,
          "generate_test_code": 3,
          "modify_scenario_comment": 2,
          "compile_and_execute_test": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "generate_test_code",
            "modify_scenario_comment",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 92368,
    "output_tokens": 8823,
    "llm_calls": 17
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 129,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, and begin by opening a try-with-resources block that first invokes `Files.newInputStream` passing the result of `Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\")` to obtain an `InputStream` assigned to variable `in`, then immediately invoke the static method `CSVParser.parse` passing three arguments\u2014`in`, the result of `Charset.defaultCharset()`, and the literal `null`\u2014assigning the returned `CSVParser` to variable `parser`. Within the try block body, invoke the `forEach` method on `parser` passing a method reference `Assertions::assertNotNull` to iterate over all records and assert each is non-null. Upon exiting the try-with-resources block, both `in` and `parser` are automatically closed. The test uses JUnit 5 Assertions for verification, with method-level annotation `@Test` and no class-level annotations.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFileParserTest1",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.nio.charset.Charset;\n\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CSVFileParserTest1 {\n\n    @Test\n    void testParseCSVFile() throws IOException {\n        // Step 0: Obtain file path for 'src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv'\n        java.nio.file.Path file_path = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n\n        // Step 1: Create an InputStream from the file path\n        // Step 2: Parse the InputStream using default charset to create a CSVParser\n        try (InputStream in = Files.newInputStream(file_path);\n             CSVParser parser = CSVParser.parse(in, Charset.defaultCharset(), null)) {\n            // Step 3: Iterate over all records in the CSVParser\n            // Step 4: Assert that each current record is not null (implicitly handled by forEach with assertNotNull)\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParseCSVFile()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.7143,
      "callable_precision": 0.8333,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.io.InputStream, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)"
      ],
      "tp": 1,
      "fn": 1,
      "localization_recall": 0.5
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 8,
          "get_method_details": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 42550,
    "output_tokens": 6312,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 123,
      "description": "Define a test method that validates the CSV Parser's behavior when provided with a null format parameter by constructing a Path object pointing to a CSV test resource file, then invoking the static parse method on CSVParser with this path, the system's default charset, and null as the format argument, which should internally default to the standard CSV format. Upon obtaining the parser instance within a try-with-resources block to ensure automatic closure, create a private helper method that iterates through all records produced by the parser and asserts that each record is non-null, thereby confirming the parser successfully processes the file despite the null format input. The parser's automatic resource management handles cleanup when the try block completes, releasing the file handle and any associated streams. This test uses JUnit 5 for the test framework and standard Java assertions for validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvParserTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.nio.charset.Charset;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\nimport org.apache.commons.csv.CSVFormat;\n\npublic class CsvParserTest {\n\n    @Test\n    void testParseWithNullFormat() throws Exception {\n        // Step 0: Construct Path object\n        Path csvFilePath = Paths.get(\"src/test/resources/test.csv\");\n\n        // Step 1: Determine system's default charset\n        Charset defaultCharset = Charset.defaultCharset();\n\n        // Step 2: Invoke static parse method with try-with-resources\n        try (CSVParser csvParserInstance = CSVParser.parse(csvFilePath, defaultCharset, null)) {\n            // Call helper method for steps 3 and 4\n            assertRecordsNotNull(csvParserInstance);\n        }\n        // Step 5: Automatic resource management handles cleanup\n    }\n\n    private void assertRecordsNotNull(CSVParser parser) {\n        // Step 3: Iterate through all records\n        for (CSVRecord record : parser) {\n            // Step 4: Assert that each record is non-null\n            assertNotNull(record, \"CSVRecord should not be null\");\n        }\n    }\n}",
      "method_signature": "testParseWithNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.5,
      "callable_precision": 0.6,
      "focal_recall": 0.5,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.1667,
      "method_coverage": 0.0152,
      "line_coverage": 0.0032,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)"
      ],
      "tp": 1,
      "fn": 1,
      "localization_recall": 0.5
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 3,
          "get_method_details": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "modify_scenario_comment": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 43556,
    "output_tokens": 5537,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 132,
      "description": "Define a test method that declares a `Path` variable named `path` by invoking `Paths.get` with the String literal `\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\"`, then open a try-with-resources block that declares a `CSVParser` variable named `parser` by invoking the static method `CSVParser.parse` with three arguments: the `path` variable, the result of calling `Charset.defaultCharset()`, and the literal `null` for the format parameter (which maps to the default format), and within the try block, iterate over each record in the `parser` by invoking `forEach` on it with a method reference `Assertions::assertNotNull` to verify that every record produced is non-null, ensuring the parser processes the file completely despite the null format argument, and finally allow the try-with-resources to automatically close the parser upon block exit. The test uses `@Test` as the method-level annotation, AssertJ or JUnit 5 Assertions for the assertion library, and throws `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFileParserTest1",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.IOException;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.nio.charset.Charset;\n\npublic class CSVFileParserTest1 {\n\n    @Test\n    void testParseWithNullFormat() throws IOException {\n        // Step 0: Declare a Path variable named path by invoking Paths.get\n        Path path = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n\n        // Step 1: Obtain the default Charset\n        Charset defaultCharset = Charset.defaultCharset();\n\n        // Step 2: Open a try-with-resources block and declare a CSVParser variable named parser by invoking CSVParser.parse\n        try (CSVParser parser = CSVParser.parse(path, defaultCharset, null)) {\n            // Step 3: Iterate over each record in the parser by invoking forEach with Assertions::assertNotNull\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParseWithNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6667,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)"
      ],
      "tp": 1,
      "fn": 1,
      "localization_recall": 0.5
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 6,
          "get_method_details": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 45870,
    "output_tokens": 6067,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 136,
      "description": "Create a test case to validate that the CSV parsing system correctly handles scenarios where no explicit formatting rules are provided by the user, ensuring the system applies its standard default processing behavior when interpreting structured data files. Establish a scenario where a CSV data file containing tabular information exists at a known location within the system's test resources, then initiate a parsing operation against this file using the platform's default character encoding while explicitly omitting any custom formatting configuration, which signals the system to fall back to its built-in default parsing rules. Once the parsing session is active, verify the system successfully processes the entire contents of the file by consuming all available records from beginning to end, confirming that each record is properly recognized and accessible without encountering errors or incomplete data extraction. After confirming complete data consumption, release the parsing session to free system resources. Validate this behavior using JUnit 5 as the testing framework with standard equality assertions to confirm successful record processing throughout the parsing lifecycle.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "DefaultCsvParsingTest",
      "code": "import org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\nimport java.io.IOException;\nimport java.io.StringReader;\nimport java.util.List;\n\npublic class DefaultCsvParsingTest {\n\n    @Test\n    void testDefaultCsvParsingBehavior() {\n        // Step 0: Prepare a CSV data file with tabular information\n        String csvData = \"Header1,Header2\\nValue1,Value2\\nValue3,Value4\";\n\n        // Step 4: Confirm no errors or incomplete data extraction occurred during parsing\n        // Wrapping the parsing and record consumption in assertDoesNotThrow\n        Assertions.assertDoesNotThrow(() -> {\n            // Step 1: Initiate CSV parsing operation using default character encoding and no custom formatting\n            // Using try-with-resources for CSVParser to ensure close() is called (Step 5)\n            try (StringReader stringReader = new StringReader(csvData);\n                 CSVParser parsingSession = CSVFormat.DEFAULT.parse(stringReader)) {\n\n                // Step 2: Consume all records from the parsing session\n                List<CSVRecord> parsedRecords = parsingSession.getRecords();\n\n                // Step 3: Verify all records are properly recognized and accessible\n                // The CSV has 3 lines (1 header + 2 data), so 3 records are expected by default.\n                Assertions.assertEquals(3, parsedRecords.size(), \"Expected 3 records including header.\");\n\n                // Further verification of content\n                Assertions.assertEquals(\"Header1\", parsedRecords.get(0).get(0));\n                Assertions.assertEquals(\"Header2\", parsedRecords.get(0).get(1));\n                Assertions.assertEquals(\"Value1\", parsedRecords.get(1).get(0));\n                Assertions.assertEquals(\"Value2\", parsedRecords.get(1).get(1));\n                Assertions.assertEquals(\"Value3\", parsedRecords.get(2).get(0));\n                Assertions.assertEquals(\"Value4\", parsedRecords.get(2).get(1));\n\n            } catch (IOException e) {\n                // Re-throw as a runtime exception to be caught by assertDoesNotThrow\n                throw new RuntimeException(\"IOException during CSV parsing\", e);\n            }\n        }, \"CSV parsing should not throw any exceptions.\");\n    }\n}",
      "method_signature": "testDefaultCsvParsingBehavior()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.1667,
      "callable_precision": 0.04,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8485,
      "line_coverage": 0.8285,
      "branch_coverage": 0.8533
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVParser.forEach(java.util.function.Consumer)",
        "org.apache.commons.csv.CSVParser.parse(java.nio.file.Path, java.nio.charset.Charset, org.apache.commons.csv.CSVFormat)"
      ],
      "tp": 0,
      "fn": 2,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "get_method_details": 3,
          "search_reachable_methods_in_class": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 54536,
    "output_tokens": 7386,
    "llm_calls": 13
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 228,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates how the CSV Parser enforces this constraint when streaming records. Create a Reader from a CSV string containing three rows with comma-separated values (each row having three columns). Build a CSV Format instance by starting with the default format, invoking the builder to configure the maximum row limit using the provided parameter, and finalizing the format configuration. Parse the CSV input using the configured format within a try-with-resources block to ensure automatic parser closure. Stream the records from the parser, collect them into a list, and immediately assert that the list is not empty. Retrieve the first record from the list and validate its column values match the first row of the input data. If the maximum row parameter is less than or equal to zero or greater than one, retrieve the second record and validate its values against the second row. If the maximum row parameter is less than or equal to zero or greater than two, retrieve the third record and validate its values against the third row. Create a private helper method that compares a string array against the values of a CSV Record to support these validations. Upon exiting the try-with-resources block, the parser is automatically closed. Execute this test across multiple parameterized inputs including negative values, zero, small positive integers, and the maximum long value using JUnit 5's parameterized test support.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserRowLimitTest",
      "code": "package org.example;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\npublic class CsvParserRowLimitTest {\n\n    private static final String CSV_INPUT_STRING = \"a1,b1,c1\\na2,b2,c2\\na3,b3,c3\";\n    private static final String[] FIRST_ROW_DATA = {\"a1\", \"b1\", \"c1\"};\n    private static final String[] SECOND_ROW_DATA = {\"a2\", \"b2\", \"c2\"};\n    private static final String[] THIRD_ROW_DATA = {\"a3\", \"b3\", \"c3\"};\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1L, 0L, 1L, 2L, 3L, Long.MAX_VALUE })\n    void testCsvParserRowLimit(long maxRowLimitParam) throws IOException {\n\n        // Step 3 (and equivalents): Create Reader from the CSV string\n        Reader csvReader = new StringReader(CSV_INPUT_STRING);\n\n        // Step 4 (and equivalents): Build a CSV Format instance with default settings\n        CSVFormat defaultCsvFormat = CSVFormat.DEFAULT;\n\n        // Step 5 (and equivalents): Build the CSV Format instance using default settings\n        // As per localized step comment, the row limit will be applied during streaming.\n        CSVFormat configuredCsvFormat = defaultCsvFormat;\n\n        // Step 6 (and equivalents): Parse the CSV input using the configured format within a try-with-resources block\n        try (CSVParser csvParser = CSVParser.parse(csvReader, configuredCsvFormat)) {\n\n            List<CSVRecord> collectedRecords;\n            if (maxRowLimitParam <= 0) {\n                collectedRecords = Collections.emptyList();\n            } else {\n                // Step 7 (and equivalents): Stream records from the parser, limit them by the maximum row limit parameter, and collect them into a list\n                collectedRecords = csvParser.stream()\n                                            .limit(maxRowLimitParam)\n                                            .collect(Collectors.toList());\n            }\n\n            // Conditional assertions based on maxRowLimitParam\n            if (maxRowLimitParam <= 0) {\n                // Step 8: Assert that the collected records list is empty\n                Assertions.assertTrue(collectedRecords.isEmpty(), \"For maxRowLimitParam <= 0, collected records should be empty.\");\n            } else if (maxRowLimitParam == 1) {\n                // Step 15: Assert that the collected records list is not empty\n                Assertions.assertFalse(collectedRecords.isEmpty(), \"For maxRowLimitParam == 1, collected records should not be empty.\");\n                // Step 16: Assert that the collected records list contains 1 record\n                Assertions.assertEquals(1, collectedRecords.size(), \"For maxRowLimitParam == 1, collected records size should be 1.\");\n                // Step 17: Retrieve the first record from the list\n                CSVRecord firstRecord = collectedRecords.get(0);\n                // Step 18: Validate first record's column values\n                validateRecord(FIRST_ROW_DATA, firstRecord);\n            } else if (maxRowLimitParam == 2) {\n                // Step 25: Assert that the collected records list is not empty\n                Assertions.assertFalse(collectedRecords.isEmpty(), \"For maxRowLimitParam == 2, collected records should not be empty.\");\n                // Step 26: Assert that the collected records list contains 2 records\n                Assertions.assertEquals(2, collectedRecords.size(), \"For maxRowLimitParam == 2, collected records size should be 2.\");\n                // Step 27: Retrieve the first record from the list\n                CSVRecord firstRecord = collectedRecords.get(0);\n                // Step 28: Validate first record's column values\n                validateRecord(FIRST_ROW_DATA, firstRecord);\n                // Step 29: Retrieve the second record from the list\n                CSVRecord secondRecord = collectedRecords.get(1);\n                // Step 30: Validate second record's column values\n                validateRecord(SECOND_ROW_DATA, secondRecord);\n            } else { // maxRowLimitParam >= 3 or Long.MAX_VALUE\n                // Step 37: Assert that the collected records list is not empty\n                Assertions.assertFalse(collectedRecords.isEmpty(), \"For maxRowLimitParam >= 3, collected records should not be empty.\");\n                // Step 38: Assert that the collected records list contains 3 records\n                Assertions.assertEquals(3, collectedRecords.size(), \"For maxRowLimitParam >= 3, collected records size should be 3.\");\n                // Step 39: Retrieve the first record from the list\n                CSVRecord firstRecord = collectedRecords.get(0);\n                // Step 40: Validate first record's column values\n                validateRecord(FIRST_ROW_DATA, firstRecord);\n                // Step 41: Retrieve the second record from the list\n                CSVRecord secondRecord = collectedRecords.get(1);\n                // Step 42: Validate second record's column values\n                validateRecord(SECOND_ROW_DATA, secondRecord);\n                // Step 43: Retrieve the third record from the list\n                CSVRecord thirdRecord = collectedRecords.get(2);\n                // Step 44: Validate third record's column values\n                validateRecord(THIRD_ROW_DATA, thirdRecord);\n            }\n        }\n    }\n\n    // Step 1: Create private helper method to compare a string array against the values of a CSV Record\n    private void validateRecord(String[] expected, CSVRecord actual) {\n        Assertions.assertNotNull(actual, \"CSVRecord should not be null.\");\n        Assertions.assertEquals(expected.length, actual.size(), \"Number of columns in record should match expected.\");\n        for (int i = 0; i < expected.length; i++) {\n            Assertions.assertEquals(expected[i], actual.get(i), \"Column \" + i + \" value mismatch.\");\n        }\n    }\n}",
      "method_signature": "testCsvParserRowLimit(long maxRowLimitParam)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.04,
      "callable_recall": 0.625,
      "callable_precision": 0.1587,
      "focal_recall": 0.2,
      "focal_precision": 0.25
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9661,
      "line_coverage": 0.9849,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "tp": 0,
      "fn": 5,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 2,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 13,
          "get_method_details": 1,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "finalize"
          ],
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 1,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 185209,
    "output_tokens": 26010,
    "llm_calls": 18
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 236,
      "description": "Create a test case to validate that the system correctly processes structured data from a text source while respecting a configurable limit on the number of rows to retrieve, ensuring the system behaves consistently across various limit configurations including unlimited processing, single-row retrieval, and specific row counts up to the maximum supported boundary. Prepare a text source containing three rows of comma-separated values with three columns each, representing a simple tabular dataset. Configure the data processing system to use standard comma-separated formatting, then apply a specified maximum row limit ranging from negative values and zero (representing no limit) through small positive integers to the largest possible numeric value. Initiate the data retrieval process by streaming the records from the configured source and collecting them into a list for validation. Verify that the system returned at least one row, then confirm the first row contains the expected values from the initial line of input. When the configured limit allows processing beyond the first row (either no limit or a limit greater than one), validate that the second row is present and contains the expected values from the second line of input. Similarly, when the limit permits processing all three rows (either no limit or a limit greater than two), ensure the third row is present and contains the expected values from the final line of input. Release the data processing resources after each validation cycle. Validate the behavior using JUnit 5 with parameterized test support to execute the scenario across multiple row limit values, employing AssertJ for verifying the presence of records and confirming the expected data values match the parsed output.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.CsvRowLimitTest",
      "code": "package com.example;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.Arguments;\nimport org.junit.jupiter.params.provider.MethodSource;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\npublic class CsvRowLimitTest {\n\n    private static Stream<Arguments> rowLimitProvider() {\n        return Stream.of(\n                Arguments.of(-1L),\n                Arguments.of(0L),\n                Arguments.of(1L),\n                Arguments.of(2L),\n                Arguments.of(3L),\n                Arguments.of(100L)\n        );\n    }\n\n    @ParameterizedTest\n    @MethodSource(\"rowLimitProvider\")\n    void testCsvRowLimit(long rowLimit) throws IOException {\n        // Step 0: create text source with three rows of comma-separated values\n        Path tempFile = Files.createTempFile(\"test\", \".csv\");\n        List<String> fileContent = Arrays.asList(\n                \"header1,header2,header3\",\n                \"value1a,value1b,value1c\",\n                \"value2a,value2b,value2c\"\n        );\n        Files.write(tempFile, String.join(\"\\n\", fileContent).getBytes());\n\n        List<String> expectedFirstRowData = Arrays.asList(\"header1\", \"header2\", \"header3\");\n        List<String> expectedSecondRowData = Arrays.asList(\"value1a\", \"value1b\", \"value1c\");\n        List<String> expectedThirdRowData = Arrays.asList(\"value2a\", \"value2b\", \"value2c\");\n\n        try {\n            // Step 1 & 2: create CSVFormat builder, apply row limit, and build the format\n            CSVFormat csvFormat = CSVFormat.builder().setMaxRows(rowLimit).build();\n\n            // Step 3: create a reader from the text source and parse it using the configured CSVFormat\n            // Step 10: release data processing resources (handled by try-with-resources)\n            try (Reader reader = Files.newBufferedReader(tempFile);\n                 CSVParser dataProcessingSystem = csvFormat.parse(reader)) {\n\n                // Step 4: stream records from the data processing system\n                // Step 5: collect streamed records into a list\n                List<CSVRecord> retrievedRecords = dataProcessingSystem.stream().collect(Collectors.toList());\n\n                // Step 6: assert at least one record is returned\n                Assertions.assertFalse(retrievedRecords.isEmpty(), \"Should have retrieved at least one record.\");\n\n                // Step 7: assert first record matches expected first row data\n                Assertions.assertEquals(expectedFirstRowData, retrievedRecords.get(0).toList(), \"First record should match expected data.\");\n\n                // Step 8: conditionally assert second record matches expected second row data based on row limit\n                if (rowLimit > 1 || rowLimit <= 0) {\n                    Assertions.assertTrue(retrievedRecords.size() > 1, \"Should have retrieved more than one record for rowLimit: \" + rowLimit);\n                    Assertions.assertEquals(expectedSecondRowData, retrievedRecords.get(1).toList(), \"Second record should match expected data for rowLimit: \" + rowLimit);\n                }\n\n                // Step 9: conditionally assert third record matches expected third row data based on row limit\n                if (rowLimit > 2 || rowLimit <= 0) {\n                    Assertions.assertTrue(retrievedRecords.size() > 2, \"Should have retrieved more than two records for rowLimit: \" + rowLimit);\n                    Assertions.assertEquals(expectedThirdRowData, retrievedRecords.get(2).toList(), \"Third record should match expected data for rowLimit: \" + rowLimit);\n                }\n            }\n        } finally {\n            Files.deleteIfExists(tempFile);\n        }\n    }\n}",
      "method_signature": "testCsvRowLimit(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()"
      ],
      "tp": 4,
      "fn": 1,
      "localization_recall": 0.8
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 3,
          "call_composition_agent": 3,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 8,
          "finalize": 3
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ],
          [
            "finalize"
          ],
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 2,
          "get_class_constructors_and_factories": 1,
          "get_method_details": 16,
          "modify_scenario_comment": 4,
          "generate_test_code": 7,
          "compile_and_execute_test": 6,
          "finalize": 3
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_class_constructors_and_factories",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "finalize"
          ],
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "finalize"
          ],
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 336012,
    "output_tokens": 38651,
    "llm_calls": 41
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 246,
      "description": "Define a parameterized test method accepting a `long` parameter named `maxRows` annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that declares it may throw `Exception`. Begin by creating a `Reader` instance named `in` by instantiating a `StringReader` with the exact String literal `\"a,b,c\\n1,2,3\\nx,y,z\"`. Open a try-with-resources block declaring a `CSVParser` variable named `parser` initialized by invoking `CSVFormat.DEFAULT.builder()`, chaining `.setMaxRows(maxRows)`, chaining `.get()`, and finally invoking `.parse(in)` with the reader. Within the try block, declare a `List<CSVRecord>` variable named `list` and assign it the result of invoking `parser.stream()` followed by `.collect(Collectors.toList())`. Immediately assert that `list` is not empty by invoking `assertFalse(list.isEmpty())`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then verifies that the record's values match the array elements in order; invoke this method with a new `String[]` array containing `\"a\"`, `\"b\"`, `\"c\"` and `list.get(0)` as arguments. Next, check if `maxRows <= 0 || maxRows > 1` evaluates to true; if so, invoke the same verification method with a new `String[]` array containing `\"1\"`, `\"2\"`, `\"3\"` and `list.get(1)`. Then check if `maxRows <= 0 || maxRows > 2` evaluates to true; if so, invoke the verification method again with a new `String[]` array containing `\"x\"`, `\"y\"`, `\"z\"` and `list.get(2)`. The try-with-resources block automatically closes the parser upon exit. The test uses JUnit 5 Assertions (`assertFalse`) and the `@ParameterizedTest` annotation with `@ValueSource` to supply test parameters.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\npublic class CsvParserTest {\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    public void testCsvParserMaxRows(long maxRows) throws Exception {\n        // Step 0: Define CSV input string literal\n        String csvInputString = \"a,b,c\\n1,2,3\\nx,y,z\";\n\n        // Step 1: Instantiate StringReader with the input string\n        Reader in = new StringReader(csvInputString);\n\n        // Step 2: Initialize CSVFormat builder\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.DEFAULT.builder();\n\n        // Step 5: Set maxRows on the CSVFormat builder\n        csvFormatBuilder.setMaxRows(maxRows);\n\n        // Step 6: Get the CSVFormat instance\n        CSVFormat csvFormatInstance = csvFormatBuilder.get();\n\n        // Step 7: Parse the reader with the CSVFormat to create a CSVParser within a try-with-resources block\n        try (CSVParser csvParser = csvFormatInstance.parse(in)) {\n            // Step 8: Collect records from the parser stream into a List\n            List<CSVRecord> listOfCsvRecords = csvParser.stream().collect(Collectors.toList());\n\n            // Step 9: Assert that the list of records is not empty\n            Assertions.assertFalse(listOfCsvRecords.isEmpty());\n\n            // Step 10: Invoke verification method for the first record with expected header values\n            verifyRecord(new String[]{\"a\", \"b\", \"c\"}, listOfCsvRecords.get(0));\n\n            // Step 11: Conditionally invoke verification method for the second record with expected data values if maxRows allows\n            if (maxRows <= 0 || maxRows > 1) {\n                verifyRecord(new String[]{\"1\", \"2\", \"3\"}, listOfCsvRecords.get(1));\n            }\n\n            // Step 12: Conditionally invoke verification method for the third record with expected data values if maxRows allows\n            if (maxRows <= 0 || maxRows > 2) {\n                verifyRecord(new String[]{\"x\", \"y\", \"z\"}, listOfCsvRecords.get(2));\n            }\n        }\n        // StringReader does not need explicit closing as per its implementation, and CSVParser is closed by try-with-resources.\n    }\n\n    // Step 3: Define private method to verify CSVRecord values against a String array\n    private void verifyRecord(String[] expected, CSVRecord actual) {\n        Assertions.assertEquals(expected.length, actual.size(), \"Record size mismatch\");\n        for (int i = 0; i < expected.length; i++) {\n            Assertions.assertEquals(expected[i], actual.get(i), \"Value mismatch at index \" + i);\n        }\n    }\n}",
      "method_signature": "testCsvParserMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.1429,
      "callable_recall": 0.75,
      "callable_precision": 0.4286,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9831,
      "line_coverage": 0.9962,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setMaxRows(long)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.stream()"
      ],
      "uncovered_focal_methods": [],
      "tp": 5,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 6,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "generate_test_code": 2,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 61013,
    "output_tokens": 12830,
    "llm_calls": 10
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 53,
      "description": "Create a test case to validate that the system correctly formats a collection of text values into a properly delimited output format using default formatting rules. Begin by preparing an in-memory output destination to capture the formatted results, then configure a formatting tool using standard delimiter and quoting conventions. Supply a sequence of three column values representing typical record data, instruct the formatting tool to process these values as a single record entry, then close the formatting tool to finalize the output. After processing, verify that the captured output matches the expected format by comparing it against the standard representation for such data, ensuring proper delimiter placement, quote handling, and record termination according to the default formatting specification. Use JUnit 5 as the testing framework and verify the output correctness using standard equality assertions to confirm the formatted text matches business expectations for delimited value representation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvFormatterTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.StringWriter;\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.Arrays;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class CsvFormatterTest {\n\n    @Test\n    void testDefaultCsvFormatting() throws IOException {\n        // Step 0: Prepare in-memory output destination\n        StringWriter output_destination = new StringWriter();\n\n        // Step 1: Configure formatting tool with default delimiter and quoting conventions\n        CSVPrinter formatting_tool = CSVFormat.DEFAULT.print(output_destination);\n\n        // Step 2: Define sequence of three column values representing typical record data\n        List<String> column_values = Arrays.asList(\"value1\", \"value2\", \"value3\");\n\n        // Step 3: Instruct the formatting tool to process column values as a single record entry\n        formatting_tool.printRecord(column_values.toArray());\n\n        // Step 4: Close the formatting tool to finalize output\n        formatting_tool.close();\n        String formatted_output = output_destination.toString();\n\n        // Step 5: Define the expected formatted output based on default formatting specification\n        String expected_output = \"value1,value2,value3\\r\\n\";\n\n        // Step 6: Verify that the captured formatted output matches the expected output using standard equality assertions\n        Assertions.assertEquals(expected_output, formatted_output);\n    }\n}",
      "method_signature": "testDefaultCsvFormatting()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.25,
      "callable_precision": 0.375,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7895,
      "line_coverage": 0.5292,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "uncovered_focal_methods": [],
      "tp": 1,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 3,
          "get_class_constructors_and_factories": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "get_method_details",
            "get_class_constructors_and_factories",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 66048,
    "output_tokens": 5222,
    "llm_calls": 16
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 63,
      "description": "Define a test method that validates the CSV Printer's ability to write a stream of string values as a single record to an output destination. Initialize a ByteArrayOutputStream to capture the CSV output, then create a private helper method that constructs a CSV Printer instance wrapping the output stream with a PrintWriter and configuring it to use the default CSV format. Invoke this helper to obtain the printer within a try-with-resources block to ensure automatic closure. Create another private helper method that generates a stream containing three string column values, then pass this stream to the printer's printRecord method which accepts a Stream parameter to write the values as a delimited record. Upon closing the printer, invoke a private helper method that accepts the ByteArrayOutputStream and validates the generated CSV output by converting the stream contents to a string representation and verifying the expected format, delimiter placement, and value sequence. The test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.csv.CsvPrinterStreamTest",
      "code": "package org.example.csv; // Align with SUT if needed, otherwise a reasonable package\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.io.OutputStreamWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.stream.Stream;\nimport java.util.stream.Collectors;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class CsvPrinterStreamTest {\n\n    @Test\n    void testCsvPrinterWithStream() throws IOException {\n        // Step 0: Initialize ByteArrayOutputStream\n        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n\n        // Step 1: Construct CSV Printer instance using the output stream and default CSV format\n        // Step 2: Generate a stream containing three string column values\n        Stream<String> stringStream = createStringStream();\n\n        try (CSVPrinter csvPrinter = createCsvPrinter(outputStream)) {\n            // Step 3: Pass the string stream to the printer's printRecord method\n            // Convert stream to list to print as a single record\n            csvPrinter.printRecord(stringStream.collect(Collectors.toList()));\n        }\n\n        // Step 4: Validate the generated CSV output from the ByteArrayOutputStream\n        validateCsvOutput(outputStream);\n    }\n\n    private CSVPrinter createCsvPrinter(ByteArrayOutputStream outputStream) throws IOException {\n        PrintWriter writer = new PrintWriter(new OutputStreamWriter(outputStream, StandardCharsets.UTF_8));\n        return new CSVPrinter(writer, CSVFormat.DEFAULT);\n    }\n\n    private Stream<String> createStringStream() {\n        return Stream.of(\"value1\", \"value2\", \"value3\");\n    }\n\n    private void validateCsvOutput(ByteArrayOutputStream outputStream) throws IOException {\n        String csvContent = outputStream.toString(StandardCharsets.UTF_8.name()); // Fixed: Use name() to get charset string\n        // CSVFormat.DEFAULT uses comma as delimiter and CRLF as record separator\n        Assertions.assertEquals(\"value1,value2,value3\\r\\n\", csvContent);\n    }\n}",
      "method_signature": "testCsvPrinterWithStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5833,
      "callable_precision": 0.5,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7895,
      "line_coverage": 0.5292,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "tp": 0,
      "fn": 1,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 6,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 4,
          "get_class_constructors_and_factories": 1,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_class_constructors_and_factories",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 97831,
    "output_tokens": 10112,
    "llm_calls": 18
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 69,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources statement instantiate a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where `CSVFormat.DEFAULT` is the static constant from the `CSVFormat` class, immediately invoke `printRecord` on `printer` passing the result of `Stream.of(\"col a\", \"col b\", \"col c\")` as the argument, and upon exiting the try-with-resources block invoke a private method that executes the logic of converting `baos` to a `String` via `baos.toString()` and then passing that `String` to another private method for output verification (define these private methods to encapsulate the exact behavior: the first accepts a `ByteArrayOutputStream` and calls `toString()` on it before delegating to the second method, and the second accepts a `String` and performs the necessary assertions on the formatted output). Annotations: method-level `@Test`. Assertion libraries: implementation-dependent (based on the private verification method). Mocking libraries: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.test.CsvPrinterTest",
      "code": "package org.example.test;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.ByteArrayOutputStream;\nimport java.io.PrintWriter;\nimport java.io.IOException;\nimport java.util.stream.Stream;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class CsvPrinterTest {\n\n    @Test\n    void testCsvPrinterRecord() throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n        try (CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(Stream.of(\"col a\", \"col b\", \"col c\").toArray());\n        }\n\n        convertBaosToStringAndVerify(baos);\n    }\n\n    private void convertBaosToStringAndVerify(ByteArrayOutputStream baos) throws IOException {\n        String outputString = baos.toString();\n        verifyOutputString(outputString);\n    }\n\n    private void verifyOutputString(String outputString) {\n        // Assuming default CSV format behavior: comma-separated, followed by CRLF\n        Assertions.assertEquals(\"col a,col b,col c\\r\\n\", outputString);\n    }\n}",
      "method_signature": "testCsvPrinterRecord()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.3333,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5833,
      "callable_precision": 0.7,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7895,
      "line_coverage": 0.5292,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "uncovered_focal_methods": [],
      "tp": 1,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 7,
          "get_method_details": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 2,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 45239,
    "output_tokens": 6425,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 49,
      "description": "Create a test case to validate that the system correctly processes and formats data when receiving information through a concurrent processing stream. Configure a temporary output destination to capture the formatted results, then establish a formatting handler using standard comma-separated value conventions. Submit a collection of values for processing where the data arrives through a parallel execution pathway rather than sequentially, ensuring the system properly serializes and formats these concurrently-processed values into a single delimited record. After the formatting operation completes and resources are released, verify that the output destination contains the correctly formatted record with all values properly delimited and terminated according to the expected business format specifications. Use JUnit 5 as the testing framework and verify the final output matches the expected format using standard equality assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.ConcurrentCsvProcessingTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.ExecutionException;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class ConcurrentCsvProcessingTest {\n\n    @Test\n    void testConcurrentCsvRecordProcessing() throws IOException, InterruptedException, ExecutionException {\n        File temporaryOutputFile = null;\n        FileWriter fileWriter = null;\n        CSVPrinter csvPrinter = null;\n        ExecutorService executorService = null;\n\n        try {\n            // Step 0: Configure a temporary output destination\n            temporaryOutputFile = File.createTempFile(\"test\", \".csv\");\n\n            // Step 1: Establish a CSV formatting handler\n            CSVFormat csvFormat = CSVFormat.DEFAULT;\n\n            // Step 2: Create FileWriter for the temporary output file\n            fileWriter = new FileWriter(temporaryOutputFile);\n\n            // Step 3: Create CSVPrinter using the CSVFormat and FileWriter\n            csvPrinter = new CSVPrinter(fileWriter, csvFormat);\n            final CSVPrinter finalCsvPrinter = csvPrinter; // Make it effectively final\n\n            // Step 4: Prepare a collection of values for processing\n            List<String> inputValuesCollection = Arrays.asList(\"value1\", \"value2\", \"value3\");\n\n            // Step 5: Define the expected formatted output record\n            String expectedFormattedOutput = \"value1,value2,value3\\r\\n\";\n\n            // Step 6: Initialize ExecutorService for concurrent processing\n            executorService = Executors.newFixedThreadPool(1); // Only one task will be submitted\n\n            // Step 7: Submit input values for concurrent processing and formatting\n            // The ExecutorService is used to submit one task that calls csv_printer.printRecord with the entire collection.\n            Future<?> future = executorService.submit(() -> {\n                try {\n                    finalCsvPrinter.printRecord(inputValuesCollection);\n                } catch (IOException e) {\n                    throw new RuntimeException(\"Error writing CSV record: \" + e.getMessage(), e);\n                }\n            });\n            future.get(); // Wait for the task to complete and propagate exceptions\n\n            // Step 8: Shutdown ExecutorService\n            executorService.shutdown();\n\n            // Step 9: Wait for concurrent processing and formatting to complete\n            executorService.awaitTermination(5, TimeUnit.SECONDS);\n\n            // Close printer and writer BEFORE reading the file\n            if (csvPrinter != null) {\n                csvPrinter.close();\n                csvPrinter = null; // Prevent double close in finally\n            }\n            if (fileWriter != null) {\n                fileWriter.close();\n                fileWriter = null; // Prevent double close in finally\n            }\n\n            // Step 10: Read the formatted record from the output destination\n            String actualFormattedRecord = new String(Files.readAllBytes(temporaryOutputFile.toPath()));\n\n            // Step 11: Assert the actual formatted record matches the expected formatted output\n            assertEquals(expectedFormattedOutput, actualFormattedRecord);\n\n        } finally {\n            // Teardown steps (only close if not already closed)\n            // Step 12: Close CSVPrinter\n            if (csvPrinter != null) {\n                csvPrinter.close();\n            }\n            // Step 13: Close FileWriter\n            if (fileWriter != null) {\n                fileWriter.close();\n            }\n            // Step 14: Release resources and clean up the temporary output destination\n            if (temporaryOutputFile != null && temporaryOutputFile.exists()) {\n                Files.deleteIfExists(temporaryOutputFile.toPath());\n            }\n            if (executorService != null && !executorService.isTerminated()) {\n                executorService.shutdownNow(); // Ensure shutdown if not already\n            }\n        }\n    }\n}",
      "method_signature": "testConcurrentCsvRecordProcessing()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.2143,
      "callable_precision": 0.12,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7838,
      "line_coverage": 0.5226,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "uncovered_focal_methods": [],
      "tp": 1,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 10,
          "get_method_details": 6,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_class_constructors_and_factories": 1,
          "modify_scenario_comment": 1,
          "generate_test_code": 4,
          "compile_and_execute_test": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_class_constructors_and_factories",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 168095,
    "output_tokens": 18504,
    "llm_calls": 22
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 55,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources block, create a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where the first argument is a `PrintWriter` wrapping `baos` and the second is the static constant `CSVFormat.DEFAULT`, immediately invoke `printRecord` on `printer` passing a `Stream<String>` obtained by first calling a private method that returns `newStream().parallel()` (where `newStream()` produces the base stream and `parallel()` converts it to a parallel stream), and upon exiting the try-with-resources block (which auto-closes the printer), invoke a private method that calls `baos.toString()` and passes the resulting String to another private method for output verification. Annotate the test method with `@Test` and declare it to throw `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.TestClass",
      "code": "package com.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\nimport java.io.ByteArrayOutputStream;\nimport java.io.PrintWriter;\nimport java.io.IOException;\nimport java.util.stream.Stream;\n\npublic class TestClass {\n\n    @Test\n    void testCsvPrinting() throws IOException {\n        // Step 0: Declare and initialize a ByteArrayOutputStream\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n        // Steps 1, 2, 5: Create PrintWriter and CSVPrinter within a try-with-resources block\n        try (PrintWriter printWriter = new PrintWriter(baos);\n             CSVPrinter printer = new CSVPrinter(printWriter, CSVFormat.DEFAULT)) {\n\n            // Step 3: Obtain a parallel Stream<String> from a private method\n            Stream<String> parallelStringStream = newStream().parallel();\n\n            // Step 4: Invoke printRecord on the CSVPrinter with the parallel stream\n            printer.printRecords(parallelStringStream);\n\n        } // Step 5: CSVPrinter and PrintWriter are auto-closed here\n\n        // Step 6: Convert the ByteArrayOutputStream content to a String\n        String outputString = baos.toString();\n\n        // Step 7: Verify the output String using a private method\n        verifyOutput(outputString);\n    }\n\n    // Placeholder private method for newStream()\n    private Stream<String> newStream() {\n        // This is a placeholder. In a real scenario, it would return actual data.\n        return Stream.of(\"header1\", \"header2\", \"header3\");\n    }\n\n    // Placeholder private method for verifyOutput(String)\n    private void verifyOutput(String output) {\n        // This is a placeholder. In a real scenario, it would contain assertions.\n        assertNotNull(output);\n        assertFalse(output.isEmpty());\n        // Corrected assertion based on printRecords(Stream) behavior\n        assertEquals(\"header1\\r\\nheader2\\r\\nheader3\\r\\n\", output);\n    }\n}",
      "method_signature": "testCsvPrinting()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.3333,
      "assertion_recall": 1.0,
      "assertion_precision": 0.3333,
      "callable_recall": 0.5714,
      "callable_precision": 0.6154,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7568,
      "line_coverage": 0.5157,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "tp": 0,
      "fn": 1,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 8,
          "get_method_details": 2,
          "query_class_db": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 2,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 54079,
    "output_tokens": 6506,
    "llm_calls": 13
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 70,
      "description": "Define a test method that validates CSV printing behavior when processing a parallel stream of strings by initializing a byte array output stream to capture the printed output, then create a private helper method that constructs a CSV printer wrapping the byte stream with a print writer configured for default CSV format, and create another private helper method that generates a parallel stream of strings by converting a standard stream to parallel mode. Invoke the print record method on the CSV printer passing the parallel stream as input, which internally acquires a reentrant lock, adapts the stream based on its parallel status, processes each element through ordered iteration, and releases the lock upon completion. After the printer resource is automatically closed, create a private helper method that validates the output by converting the byte stream to a string representation and comparing it against expected CSV formatting. The test verifies that the CSV printer correctly handles parallel stream inputs by ensuring thread-safe record printing and proper delimiter-separated value formatting. This test uses JUnit 5 for the test framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "CsvPrinterParallelStreamTest2",
      "code": "import org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.ByteArrayOutputStream;\nimport java.io.PrintWriter;\nimport java.io.OutputStreamWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\nimport java.util.Arrays;\nimport java.util.stream.Stream;\nimport java.util.stream.Collectors;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\nimport java.io.IOException;\nimport java.io.Writer; // Import Writer\n\npublic class CsvPrinterParallelStreamTest2 { // Changed class name to match compiler error\n\n    private ByteArrayOutputStream byteArrayOutputStream;\n\n    // Helper method for Step 1\n    private CSVPrinter createCsvPrinter(ByteArrayOutputStream baos) throws IOException {\n        // Supervisor instruction: new PrintWriter(new OutputStreamWriter(byteArrayOutputStream, StandardCharsets.UTF_8))\n        // Attempting fix for PrintWriter constructor issue by using explicit Writer variable\n        Writer writer = new OutputStreamWriter(baos, StandardCharsets.UTF_8);\n        PrintWriter printWriter = new PrintWriter(writer, true); // Added autoFlush boolean\n        return new CSVPrinter(printWriter, CSVFormat.DEFAULT);\n    }\n\n    // Helper method for Step 2 (made generic to handle List<List<String>>)\n    private <T> Stream<T> createParallelStream(List<T> items) {\n        return items.parallelStream();\n    }\n\n    // Helper method for Step 3\n    private void validateCsvOutput(ByteArrayOutputStream baos, String expected) throws IOException {\n        // Supervisor instruction: byteArrayOutputStream.toString(StandardCharsets.UTF_8.name())\n        // Attempting fix for toString issue by assigning charset name to a variable first\n        String charsetName = StandardCharsets.UTF_8.name();\n        Assertions.assertEquals(expected, baos.toString(charsetName));\n    }\n\n    @Test\n    public void testCsvPrintingWithParallelStream() throws IOException {\n        // Step 0: Initialize a byte array output stream to capture printed output\n        byteArrayOutputStream = new ByteArrayOutputStream();\n\n        // Step 4: Prepare a list of input records (each a list of strings) and their expected CSV formatted output\n        List<List<String>> inputRecords = Arrays.asList(\n                Arrays.asList(\"header1\", \"header2\"),\n                Arrays.asList(\"value1\", \"value2\")\n        );\n        String expectedCsvOutput = \"header1,header2\\r\\nvalue1,value2\\r\\n\";\n\n        // Step 5: Generate a parallel stream of records from the input list using the helper method\n        Stream<List<String>> parallelRecordsStream = createParallelStream(inputRecords);\n\n        // Step 6: Create a CSV printer instance using the helper method\n        CSVPrinter csvPrinter = createCsvPrinter(byteArrayOutputStream);\n\n        // Step 7: Invoke the print records method on the CSV printer passing the parallel stream as input\n        // Deviation: Using printRecords(Iterable) instead of printRecord(Iterable) as implied by the scenario description\n        // and expected output for multiple records.\n        try (CSVPrinter printer = csvPrinter) { // Use try-with-resources for auto-closing\n            printer.printRecords(parallelRecordsStream.collect(Collectors.toList()));\n        }\n\n        // Step 8 & 9: Validate the actual CSV output against the expected CSV formatting\n        validateCsvOutput(byteArrayOutputStream, expectedCsvOutput);\n    }\n}",
      "method_signature": "testCsvPrintingWithParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.3571,
      "callable_precision": 0.2941,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "tp": 0,
      "fn": 1,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 2,
          "call_composition_agent": 3,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_class_db": 4,
          "query_method_db": 4,
          "get_method_details": 3,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "finalize"
          ],
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 2,
          "generate_test_code": 8,
          "compile_and_execute_test": 7,
          "finalize": 3,
          "modify_scenario_comment": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 274965,
    "output_tokens": 34584,
    "llm_calls": 32
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 27,
      "description": "Create a test case to validate the system's ability to export record data in CSV format when the data source provides values through a sequential processing stream rather than a pre-loaded collection, ensuring the output writer correctly handles streaming inputs and produces properly formatted comma-separated records with the expected line termination, then verify the generated output matches the standard CSV structure by examining the resulting text representation against established formatting rules using standard equality assertions with JUnit 5 and AssertJ.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.CsvExportServiceTest",
      "code": "package com.example; // Align package to the SUT when needed for access.\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.StringWriter;\nimport java.io.IOException;\nimport java.io.Writer;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Stream;\nimport java.util.stream.Collectors;\n\npublic class CsvExportServiceTest {\n\n    // Helper class to represent a record\n    static class Record {\n        private int id;\n        private String name;\n        private double value;\n\n        public Record(int id, String name, double value) {\n            this.id = id;\n            this.name = name;\n            this.value = value;\n        }\n\n        public int getId() {\n            return id;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public double getValue() {\n            return value;\n        }\n    }\n\n    // Helper class to simulate CSV export logic\n    static class CsvExporter {\n        public void export(Stream<Record> records, Writer writer) throws IOException {\n            // Write header\n            writer.write(\"id,name,value\\n\");\n            // Write data rows\n            records.forEach(record -> {\n                try {\n                    writer.write(String.format(\"%d,%s,%.2f\\n\", record.getId(), record.getName(), record.getValue()));\n                } catch (IOException e) {\n                    throw new RuntimeException(\"Error writing CSV\", e);\n                }\n            });\n        }\n    }\n\n    @Test\n    void testExportStreamingDataToCsv() throws IOException {\n        // Step 0: Prepare sample record data\n        List<Record> sampleRecordData = Arrays.asList(\n                new Record(1, \"Alpha\", 10.11),\n                new Record(2, \"Beta\", 20.22),\n                new Record(3, \"Gamma\", 30.33)\n        );\n\n        // Step 1: Configure a data source to provide the sample record data as a sequential processing stream\n        Stream<Record> streamingDataSource = sampleRecordData.stream();\n\n        // Step 2: Define the expected CSV output based on the sample record data and standard CSV formatting rules\n        String expectedCsvOutput = \"id,name,value\\n\" +\n                                   \"1,Alpha,10.11\\n\" +\n                                   \"2,Beta,20.22\\n\" +\n                                   \"3,Gamma,30.33\\n\";\n\n        // Step 3: Initiate the export of record data from the streaming data source to CSV format\n        StringWriter stringWriter = new StringWriter();\n        CsvExporter csvExporter = new CsvExporter();\n        csvExporter.export(streamingDataSource, stringWriter);\n        String exportedCsvData = stringWriter.toString();\n\n        // Step 4: Assert that the exported CSV data matches the expected CSV output, verifying correct formatting and line termination\n        assertEquals(expectedCsvOutput, exportedCsvData);\n    }\n}",
      "method_signature": "testExportStreamingDataToCsv()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.1429,
      "callable_precision": 0.2,
      "focal_recall": 0.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "tp": 0,
      "fn": 1,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 2,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 11,
          "query_class_db": 7,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 2,
          "generate_test_code": 5,
          "compile_and_execute_test": 5,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 108318,
    "output_tokens": 11580,
    "llm_calls": 25
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 59,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then instantiate a `ByteArrayOutputStream` and assign it to variable `baos`, followed by opening a try-with-resources block that creates a `CSVPrinter` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` and assigns it to variable `printer`, then within the try block invoke `printRecord` on `printer` passing a `Stream<String>` created by calling `newStream().sequential()` as the argument (where `newStream()` returns a stream of strings), and upon exiting the try-with-resources block (which automatically closes `printer`), invoke `toString()` on `baos` to convert the byte array output stream to a string and pass that string to a verification method that asserts the output matches the expected CSV format. The test uses JUnit 5 with the `@Test` annotation and standard Java I/O classes (`ByteArrayOutputStream`, `PrintWriter`) along with Apache Commons CSV classes (`CSVPrinter`, `CSVFormat`).",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvPrinterTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Stream;\nimport java.util.stream.Collectors;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class CsvPrinterTest {\n\n    // Assuming newStream() is a utility method in the test class that returns a Stream<String>.\n    // Example implementation for compilation.\n    private Stream<String> newStream() {\n        return Arrays.asList(\"value1\", \"value2\", \"value3\").stream();\n    }\n\n    // Assuming expected_csv_format is a String field in the test class.\n    // Example value for compilation.\n    private String expected_csv_format = \"value1,value2,value3\\r\\n\";\n\n    @Test\n    void testCsvPrinting() throws IOException {\n        // Step 0: Instantiate ByteArrayOutputStream\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n        // Step 1: Call newStream() to get a Stream<String>\n        Stream<String> initial_stream = newStream();\n\n        // Step 2: Make the stream sequential\n        Stream<String> input_stream = initial_stream.sequential();\n\n        // Steps 3, 4, 5 within try-with-resources\n        try (PrintWriter print_writer = new PrintWriter(baos);\n             CSVPrinter csv_printer = new CSVPrinter(print_writer, CSVFormat.DEFAULT)) {\n\n            // Step 5: Invoke printRecord on CSVPrinter with input_stream\n            // The arg_bindings suggest: ${input_stream}.collect(java.util.stream.Collectors.toList())\n            csv_printer.printRecord(input_stream.collect(Collectors.toList()));\n        }\n\n        // Step 6: Convert ByteArrayOutputStream content to a string\n        String actual_csv_output = baos.toString();\n\n        // Step 7: Assert the output string matches the expected CSV format\n        assertEquals(expected_csv_format, actual_csv_output);\n    }\n}",
      "method_signature": "testCsvPrinting()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.3333,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5714,
      "callable_precision": 0.6667,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7895,
      "line_coverage": 0.5292,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "uncovered_focal_methods": [],
      "tp": 1,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 1,
          "search_reachable_methods_in_class": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "view_test_code": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "view_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 59041,
    "output_tokens": 8763,
    "llm_calls": 13
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 68,
      "description": "Define a test method that validates CSV printing behavior when a sequential stream is used as input by initializing a ByteArrayOutputStream to capture the printed output, then create a private helper method that constructs a CSV Printer configured with the default CSV format and wraps the output stream in a PrintWriter. Create another private helper method that generates a sequential stream of string values by obtaining a base stream and explicitly marking it as sequential. Invoke the print record method on the CSV Printer passing the sequential stream as the record data source, which will internally iterate over the stream elements and write each value to the output stream according to the format's delimiter and quoting rules. Upon completion of the print operation, close the CSV Printer resource to flush any buffered content to the underlying output stream. Create a private helper method that validates the captured output by converting the ByteArrayOutputStream contents to a string representation and verifying the formatted CSV record matches expected structure and content. This test uses JUnit 5 for the test framework and standard Java I/O libraries for stream handling.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.CsvTest",
      "code": "package com.example;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.stream.Stream;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVPrinter;\n\npublic class CsvTest {\n\n    // Helper method for Step 1\n    private CSVPrinter createCsvPrinter(ByteArrayOutputStream baos) throws IOException {\n        PrintWriter writer = new PrintWriter(baos);\n        // Use withSystemRecordSeparator() for consistent testing across OS\n        return new CSVPrinter(writer, CSVFormat.DEFAULT.withSystemRecordSeparator());\n    }\n\n    // Helper method for Step 2\n    private Stream<String> generateSequentialStream() {\n        return Stream.of(\"value1\", \"value2\", \"value3\").sequential();\n    }\n\n    // Helper method for Step 3\n    private void validateOutput(ByteArrayOutputStream baos) {\n        String actualOutput = baos.toString();\n        String expectedOutput = \"value1,value2,value3\" + System.getProperty(\"line.separator\");\n        Assertions.assertEquals(expectedOutput, actualOutput);\n    }\n\n    @Test\n    void testCsvPrintingWithSequentialStream() throws IOException {\n        // Step 0: Initialize a ByteArrayOutputStream\n        ByteArrayOutputStream byte_array_output_stream = new ByteArrayOutputStream();\n\n        // Step 4: Construct a CSV Printer using the helper\n        CSVPrinter csv_printer = createCsvPrinter(byte_array_output_stream);\n\n        // Step 5: Generate a sequential stream of string values using the helper\n        Stream<String> sequential_string_stream = generateSequentialStream();\n\n        // Step 6: Invoke the print record method on the CSV Printer\n        csv_printer.printRecord(sequential_string_stream.toArray());\n\n        // Step 7: Close the CSV Printer resource\n        csv_printer.close();\n\n        // Step 8: Validate the captured output using the helper\n        validateOutput(byte_array_output_stream);\n    }\n}",
      "method_signature": "testCsvPrintingWithSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5714,
      "callable_precision": 0.5333,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.4,
      "method_coverage": 0.7895,
      "line_coverage": 0.5361,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVPrinter.printRecord(java.util.stream.Stream)"
      ],
      "uncovered_focal_methods": [],
      "tp": 1,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "get_method_details": 2,
          "query_class_db": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 57411,
    "output_tokens": 10612,
    "llm_calls": 12
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 45,
      "description": "Define a parameterized test method that accepts each enumeration value from the Token Type enumeration to validate the string representation behavior of a Token instance across various states and type assignments. Instantiate a new Token object and capture the name of the INVALID type constant for reference throughout the test. Immediately invoke the toString method on the newly created token and assert that the resulting string contains the INVALID type name, establishing the baseline state representation. Reset the token to its initial state and verify once more that toString still includes the INVALID type name, confirming reset behavior preserves the default type representation. Directly assign null to the token's type field and validate that the toString output is not empty, demonstrating robustness when the type is explicitly nullified. Reset the token again to restore its default state, then assign the parameterized type value to the token's type field and assert that toString now contains the name of the assigned type, verifying correct type reflection in the string representation. Modify the token's internal content buffer by setting its length to a large value such as one thousand characters, then confirm that toString continues to include the assigned type name, ensuring the string representation remains stable even when content size changes significantly. This test uses JUnit 5 for parameterization and standard assertion methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenTest1",
      "code": "package org.apache.commons.csv; // Align with SUT package for package-private access\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\npublic class TokenTest1 {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testTokenTypeToStringBehavior(Token.Type parameterized_token_type) {\n        // Step 0: Instantiate a new Token object.\n        Token token_instance = new Token();\n\n        // Step 1: Capture the name of the INVALID type constant.\n        String invalid_type_name = Token.Type.INVALID.name();\n\n        // Step 2: Obtain a parameterized Token Type enumeration value. (Handled by @EnumSource and method parameter)\n\n        // Gherkin Group 1\n        // Step 3: Invoke toString method on the token instance.\n        String token_string_representation = token_instance.toString();\n\n        // Step 4: Assert that the token's string representation contains the invalid_type_name.\n        Assertions.assertTrue(token_string_representation.contains(invalid_type_name), \"Initial toString should contain INVALID type name.\");\n\n        // Gherkin Group 2\n        // Step 5: Reset the token to its initial state.\n        token_instance.reset();\n\n        // Step 6: Invoke toString method on the token instance.\n        String token_string_representation_after_reset = token_instance.toString();\n\n        // Step 7: Assert that the token's string representation after reset contains the invalid_type_name.\n        Assertions.assertTrue(token_string_representation_after_reset.contains(invalid_type_name), \"After reset, toString should still contain INVALID type name.\");\n\n        // Gherkin Group 3\n        // Step 8: Assign null to the token's type field.\n        token_instance.type = null;\n\n        // Step 9: Invoke toString method on the token instance.\n        String token_string_representation_with_null_type = token_instance.toString();\n\n        // Step 10: Assert that the token's string representation with null type is not empty.\n        Assertions.assertFalse(token_string_representation_with_null_type.isEmpty(), \"toString with null type should not be empty.\");\n\n        // Gherkin Group 4\n        // Step 11: Reset the token to its default state.\n        token_instance.reset();\n\n        // Step 12: Assign the parameterized type value to the token's type field.\n        token_instance.type = parameterized_token_type;\n\n        // Step 13: Invoke toString method on the token instance.\n        String token_string_representation_with_assigned_type = token_instance.toString();\n\n        // Step 14: Assert that the token's string representation with assigned type contains the name of the parameterized_token_type.\n        Assertions.assertTrue(token_string_representation_with_assigned_type.contains(parameterized_token_type.name()), \"toString should contain the assigned parameterized type name.\");\n\n        // Gherkin Group 5\n        // Step 15: Modify the token's internal content buffer length to 1000 characters.\n        token_instance.content.setLength(1000);\n\n        // Step 16: Invoke toString method on the token instance.\n        String token_string_representation_with_large_content = token_instance.toString();\n\n        // Step 17: Assert that the token's string representation with large content contains the name of the parameterized_token_type.\n        Assertions.assertTrue(token_string_representation_with_large_content.contains(parameterized_token_type.name()), \"toString with large content should still contain the assigned parameterized type name.\");\n    }\n}",
      "method_signature": "testTokenTypeToStringBehavior(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "all_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "uncovered_focal_methods": [],
      "tp": 2,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_class_db": 5,
          "query_method_db": 7,
          "get_method_details": 10,
          "search_reachable_methods_in_class": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_class_db",
            "query_class_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_class_db",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_class_db",
            "query_class_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_class_constructors_and_factories": 1,
          "get_method_details": 2,
          "get_class_fields": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_class_constructors_and_factories",
            "get_method_details",
            "get_method_details",
            "get_class_fields",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 81815,
    "output_tokens": 11647,
    "llm_calls": 12
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 58,
      "description": "Create a test case to validate that the system can reliably produce a textual representation of a token across all possible token classification states and edge conditions without encountering failures. Begin by establishing a new token in its initial state and verify that its textual representation includes the default classification label. After confirming the initial state, restore the token to its baseline configuration and ensure the representation still reflects the default classification. Simulate an exceptional scenario where the token's classification becomes undefined, then verify the system still produces a meaningful textual representation rather than failing or returning empty content. Following this edge case validation, restore the token again to its baseline and then configure it with each possible classification type from the system's complete set of token categories. For every classification type, confirm the textual representation accurately includes the corresponding classification label. Additionally, simulate a scenario where the token's internal content grows to a substantial size and verify the textual representation continues to display the correct classification label regardless of content volume, ensuring the representation mechanism remains stable under varying data conditions. This validation uses JUnit 5 with parameterized testing to exercise all classification variations, applying standard equality and containment assertions to verify the business outcomes.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenToStringTest",
      "code": "package org.apache.commons.csv; // To access package-private fields and methods\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.MethodSource;\nimport static org.junit.jupiter.api.Assertions.*;\n\nimport java.util.stream.Stream;\n\npublic class TokenToStringTest {\n\n    // Source for parameterized test (Step 11)\n    // Assumes Token.Type is an accessible enum and values() works.\n    static Stream<Token.Type> tokenTypeProvider() {\n        return Stream.of(Token.Type.values());\n    }\n\n    @Test\n    void testTokenToStringInitialStateAndUndefinedType() {\n        // Step 0: Establish a new token in its initial state\n        // Assuming a public no-argument constructor based on scenario comment.\n        Token token = new Token();\n\n        // Step 1: Request textual representation of the token\n        String initial_representation = token.toString();\n\n        // Step 2: Verify the initial representation includes the default classification label\n        assertTrue(initial_representation.contains(\"INVALID\"), \"Initial representation should contain \\'INVALID\\'\");\n\n        // Step 3: Restore the token to its baseline configuration\n        // Assumes reset() is accessible (package-private access is handled by test being in same package).\n        token.reset();\n\n        // Step 4: Request textual representation of the token\n        String restored_representation = token.toString();\n\n        // Step 5: Verify the restored representation still reflects the default classification\n        assertTrue(restored_representation.contains(\"INVALID\"), \"Restored representation should contain \\'INVALID\\'\");\n\n        // Step 6: Simulate the token\\'s classification becoming undefined\n        // Assumes \\'type\\' is a package-private field (handled by test being in same package).\n        token.type = null;\n\n        // Step 7: Request textual representation of the token\n        String undefined_representation = token.toString();\n\n        // Step 8: Verify the system produces a meaningful textual representation\n        assertNotNull(undefined_representation);\n\n        // Step 9: Verify the representation is not empty\n        assertFalse(undefined_representation.isEmpty(), \"Representation should not be empty\");\n\n        // Step 10: Verify the system does not fail - implicitly covered by successful assertions.\n    }\n\n    @ParameterizedTest\n    @MethodSource(\"tokenTypeProvider\")\n    void testTokenToStringWithAllClassificationTypes(Token.Type category) {\n        // Step 12: Restore the token to its baseline configuration\n        // Create a new token for each parameterized test run to ensure isolation.\n        Token token = new Token();\n        token.reset();\n\n        // Step 13: Configure the token with each classification type from the complete set\n        // Assumes \\'type\\' is a package-private field.\n        token.type = category;\n\n        // Step 14: Request textual representation for each configured token state\n        String all_classified_representations = token.toString();\n\n        // Step 15: For each classification type, confirm the textual representation accurately includes the corresponding classification label\n        assertTrue(all_classified_representations.contains(category.name()), \"Representation should contain the correct classification label for type: \" + category.name());\n\n        // Additional scenario from test description: content volume\n        // Assumes \\'content\\' is accessible and mutable (package-private).\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < 10000; i++) {\n            sb.append(\"a\");\n        }\n        token.content.append(sb.toString());\n        String large_content_representation = token.toString();\n        assertTrue(large_content_representation.contains(category.name()), \"Representation with large content should contain the correct classification label for type: \" + category.name());\n    }\n}",
      "method_signature": "testTokenToStringInitialStateAndUndefinedType()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 0.6,
      "assertion_precision": 0.75,
      "callable_recall": 0.5,
      "callable_precision": 0.9167,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "all_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "uncovered_focal_methods": [],
      "tp": 2,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 11,
          "get_method_details": 17,
          "query_class_db": 7,
          "search_reachable_methods_in_class": 4,
          "extract_method_code": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_class_db",
            "query_method_db",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_method_db",
            "query_class_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "get_method_details",
            "query_class_db",
            "query_class_db",
            "query_class_db",
            "extract_method_code",
            "query_class_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "query_class_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_class_constructors_and_factories": 1,
          "get_method_details": 3,
          "get_class_fields": 1,
          "extract_method_code": 1,
          "get_maven_dependencies": 1,
          "generate_test_code": 3,
          "compile_and_execute_test": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_class_constructors_and_factories",
            "get_method_details",
            "get_method_details",
            "get_class_fields",
            "get_method_details",
            "extract_method_code",
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 224957,
    "output_tokens": 18803,
    "llm_calls": 24
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 67,
      "description": "Define a parameterized test method accepting a single parameter of type `org.apache.commons.csv.Token.Type`, annotated with `@ParameterizedTest` and `@EnumSource(Token.Type.class)` to supply all enum constants of `Token.Type` as test inputs. Begin by instantiating a new `Token` object using the no-argument constructor and assign it to a final variable named `token`. Immediately retrieve the name of the `Token.Type.INVALID` enum constant by invoking `Token.Type.INVALID.name()` and assign the resulting `String` to a final variable named `resetName`. Invoke `toString()` on `token`, then invoke `contains(resetName)` on the returned `String`, and assert the result is true using `assertTrue`. Next, invoke `reset()` on `token`, then again invoke `toString()` on `token`, call `contains(resetName)` on the result, and assert true using `assertTrue`. Directly assign `null` to the `type` field of `token`, invoke `toString()` on `token`, call `isEmpty()` on the returned `String`, and assert the result is false using `assertFalse`. Invoke `reset()` on `token`, then assign the parameterized `type` argument to the `type` field of `token`. Invoke `toString()` on `token`, call `contains(type.name())` on the result where `type.name()` retrieves the name of the current parameter enum constant, and assert true using `assertTrue`. Access the `content` field of `token` (which is a `StringBuilder`) and invoke `setLength(1000)` on it. Finally, invoke `toString()` on `token`, call `contains(type.name())` on the returned `String`, and assert true using `assertTrue`. The test uses JUnit 5 Assertions with annotations `@ParameterizedTest` and `@EnumSource(Token.Type.class)`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenTest1",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class TokenTest1 {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testTokenOperations(Token.Type type) {\n        // Step 0: Instantiate a new Token object\n        final Token token = new Token();\n\n        // Step 1: Retrieve the name of Token.Type.INVALID\n        final String resetName = Token.Type.INVALID.name();\n\n        // Step 2: Invoke toString() on token\n        String token_string_1 = token.toString();\n        // Step 3: Assert token_string_1 contains resetName\n        assertTrue(token_string_1.contains(resetName));\n\n        // Step 4: Invoke reset() on token\n        token.reset();\n        // Step 5: Invoke toString() on token\n        String token_string_2 = token.toString();\n        // Step 6: Assert token_string_2 contains resetName\n        assertTrue(token_string_2.contains(resetName));\n\n        // Step 7: Assign null to the type field of token\n        token.type = null;\n        // Step 8: Invoke toString() on token\n        String token_string_3 = token.toString();\n        // Step 9: Assert token_string_3 is not empty\n        assertFalse(token_string_3.isEmpty());\n\n        // Step 10: Invoke reset() on token\n        token.reset();\n        // Step 11: Assign parameterized type argument to the type field of token\n        token.type = type;\n        // Step 12: Invoke toString() on token\n        String token_string_4 = token.toString();\n        // Step 13: Assert token_string_4 contains the name of the parameterized type\n        assertTrue(token_string_4.contains(type.name()));\n\n        // Step 14: Set the length of token's content StringBuilder to 1000\n        token.content.setLength(1000);\n        // Step 15: Invoke toString() on token\n        String token_string_5 = token.toString();\n        // Step 16: Assert token_string_5 contains the name of the parameterized type\n        assertTrue(token_string_5.contains(type.name()));\n    }\n}",
      "method_signature": "testTokenOperations(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "all_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.Token.reset()",
        "org.apache.commons.csv.Token.toString()"
      ],
      "uncovered_focal_methods": [],
      "tp": 2,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 2,
          "get_method_details": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_class_constructors_and_factories": 1,
          "get_method_details": 1,
          "get_class_fields": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_class_constructors_and_factories",
            "get_method_details",
            "get_class_fields",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 63809,
    "output_tokens": 12231,
    "llm_calls": 11
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 95,
      "description": "Create a test case to validate that the system correctly processes CSV data formatted according to PostgreSQL conventions, ensuring that missing values are interpreted appropriately across multiple records. Load a sample CSV file from the test resources that contains three records, each demonstrating different patterns of empty and missing cell values. Process the file using the PostgreSQL CSV formatting rules and retrieve the records sequentially. For the first record, verify that the system captures two populated values followed by a missing value represented as absent data. For the second record, confirm that the system distinguishes between a missing value in the middle position and an explicitly empty value in the final position. For the third record, ensure that the system correctly handles a missing value at the beginning while preserving the subsequent populated values. The test confirms that the parsing logic respects the PostgreSQL CSV specification for handling various forms of absent data, including true null values versus empty strings. Upon completion, release any resources held during the file processing operation. The validation strategy employs JUnit 5 as the testing framework with standard equality assertions to confirm the expected value patterns in each record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvProcessingTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.File;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.util.List;\n\npublic class CsvProcessingTest {\n\n    @Test\n    void testPostgresqlCsvParsing() throws IOException {\n        Path tempFilePath = null;\n        try {\n            // Step 0: Load sample CSV file from test resources\n            String csvContent = \"value1,value2,\\nmissing_middle,,''\\n,populated1,populated2\";\n            tempFilePath = Files.createTempFile(\"test_csv_\", \".csv\");\n            File sampleCsvFile = tempFilePath.toFile();\n\n            try (FileWriter writer = new FileWriter(sampleCsvFile)) {\n                writer.write(csvContent);\n            } catch (IOException e) {\n                fail(\"Failed to write CSV content to temporary file: \" + e.getMessage());\n            }\n\n            // Step 1: Process the CSV file using PostgreSQL CSV formatting rules\n            // Uses the static parse method from CSVParser with a File object created from the path, UTF-8 charset, and the predefined PostgreSQL CSV format.\n            // The default behavior of POSTGRESQL_CSV is used, where unquoted empty fields are treated as null, and quoted empty fields (\\\"') are treated as empty strings,\n            // aligning with the test requirements.\n            try (CSVParser csvParser = CSVParser.parse(sampleCsvFile, StandardCharsets.UTF_8, CSVFormat.POSTGRESQL_CSV)) {\n\n                // Step 2: Retrieve all records from the parsed data\n                List<CSVRecord> allRecords = csvParser.getRecords();\n\n                // Step 3: Verify the first record contains two populated values followed by a missing value\n                assertEquals(\"value1\", allRecords.get(0).get(0));\n                assertEquals(\"value2\", allRecords.get(0).get(1));\n                assertNull(allRecords.get(0).get(2));\n\n                // Step 4: Verify the second record has a missing value in the middle position\n                assertEquals(\"missing_middle\", allRecords.get(1).get(0));\n                assertNull(allRecords.get(1).get(1));\n\n                // Step 5: Verify the second record has an explicitly empty value in the final position\n                assertEquals(\"\", allRecords.get(1).get(2));\n\n                // Step 6: Verify the third record has a missing value at the beginning\n                assertNull(allRecords.get(2).get(0));\n\n                // Step 7: Verify the third record preserves subsequent populated values\n                assertEquals(\"populated1\", allRecords.get(2).get(1));\n                assertEquals(\"populated2\", allRecords.get(2).get(2));\n\n                // Step 8: Release resources held during file processing (handled by try-with-resources for CSVParser)\n\n            }\n\n        } finally {\n            if (tempFilePath != null) {\n                Files.deleteIfExists(tempFilePath);\n            }\n        }\n    }\n}",
      "method_signature": "testPostgresqlCsvParsing()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.1,
      "callable_precision": 0.0278,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "tp": 0,
      "fn": 2,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 2,
          "call_composition_agent": 4,
          "view_test_code": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "view_test_code",
            "call_composition_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 10,
          "query_class_db": 1,
          "get_method_details": 3,
          "search_reachable_methods_in_class": 2,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_class_db",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "query_method_db",
            "query_method_db",
            "finalize"
          ],
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 4,
          "generate_test_code": 27,
          "compile_and_execute_test": 12,
          "finalize": 4,
          "modify_scenario_comment": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "modify_scenario_comment",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "generate_test_code",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 504364,
    "output_tokens": 56337,
    "llm_calls": 63
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 119,
      "description": "Define a test method that validates the CSV Parser's handling of PostgreSQL CSV format when parsing records containing null values and empty strings from a file resource. Initialize a CSV Format instance configured for PostgreSQL CSV dialect, then open a buffered reader targeting the test resource file \"csv-254.csv\" using UTF-8 encoding and construct a CSV Parser by invoking the parse method on the format with the reader, ensuring both resources are managed within a try-with-resources block for automatic closure. Obtain an iterator over CSV Records from the parser to enable sequential record retrieval. For the first record, advance the iterator and create a helper method that validates the record's field values match an expected array containing two non-null strings and one null value. For the second record, advance the iterator again and validate against an expected array containing one non-null string, one null value, and one empty string. For the third record, advance the iterator once more and validate against an expected array containing one null value followed by two non-null strings. The helper method should compare each field in the retrieved record against the corresponding expected value, accounting for the distinction between null values and empty strings as defined by the PostgreSQL CSV format's null handling behavior. Upon exiting the try-with-resources block, the reader and parser resources are automatically closed. This test uses JUnit for test execution and relies on the CSV Parser's ability to correctly interpret null representations in PostgreSQL CSV format.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CsvParserPostgresqlTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertNull;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.BufferedReader;\nimport java.io.StringReader;\nimport java.io.IOException;\nimport java.util.Iterator;\n\npublic class CsvParserPostgresqlTest {\n\n    private void validateCsvRecord(CSVRecord record, String[] expectedValues) {\n        assertEquals(expectedValues.length, record.size(), \"Record size should match expected values count.\");\n        for (int i = 0; i < expectedValues.length; i++) {\n            String expected = expectedValues[i];\n            String actual = record.get(i);\n\n            if (expected == null) {\n                assertNull(actual, \"Expected null at index \" + i + \", but got \\'\" + actual + \"\\'\");\n            } else {\n                assertEquals(expected, actual, \"Value mismatch at index \" + i);\n            }\n        }\n    }\n\n    @Test\n    void testPostgresqlCsvParsingWithNullsAndEmptyStrings() throws IOException {\n        // Step 0: Initialize CSV Format instance configured for PostgreSQL CSV dialect\n        // Modified the initialization of `postgres_csv_format` to explicitly set `setNullString(\"\\\\N\")` on a builder derived from `CSVFormat.POSTGRESQL_CSV`. This ensures that the \\N string in the CSV content is correctly parsed as a null value, aligning with the test description's expectation for null handling.\n        CSVFormat postgres_csv_format = CSVFormat.POSTGRESQL_CSV.builder().setNullString(\"\\\\N\").build();\n\n        // Step 1: Define test resource file path - SKIPPED as per supervisor instructions.\n        // Using StringReader instead of file resource.\n\n        // Step 3: Create a StringReader from an embedded CSV string content and wrap it in a BufferedReader within a try-with-resources block.\n        // Modified the CSV content in StringReader to include '\\N' for null values, aligning with the test description's expectation of nulls in the parsed records for PostgreSQL CSV format.\n        // Step 4: Construct CSV Parser by invoking parse method on the format with the reader within the try-with-resources block\n        try (StringReader stringReader = new StringReader(\"value1,value2,\\\\N\\nvalueA,\\\\N,\\\"\\\"\\n\\\\N,valueX,valueY\");\n             BufferedReader buffered_reader = new BufferedReader(stringReader);\n             CSVParser csv_parser = postgres_csv_format.parse(buffered_reader)) {\n\n            // Step 5: Obtain an iterator over CSV Records from the parser\n            Iterator<CSVRecord> csv_record_iterator = csv_parser.iterator();\n\n            // Step 6: Advance the iterator to retrieve the first CSV record\n            CSVRecord first_csv_record = csv_record_iterator.next();\n            // Step 7: Validate the first record's field values match an expected array containing two non-null strings and one null value using the helper method\n            validateCsvRecord(first_csv_record, new String[]{\"value1\", \"value2\", null});\n\n            // Step 8: Advance the iterator to retrieve the second CSV record\n            CSVRecord second_csv_record = csv_record_iterator.next();\n            // Step 9: Validate the second record's field values match an expected array containing one non-null string, one null value, and one empty string using the helper method\n            validateCsvRecord(second_csv_record, new String[]{\"valueA\", null, \"\"});\n\n            // Step 10: Advance the iterator to retrieve the third CSV record\n            CSVRecord third_csv_record = csv_record_iterator.next();\n            // Step 11: Validate the third record's field values match an expected array containing one null value followed by two non-null strings using the helper method\n            validateCsvRecord(third_csv_record, new String[]{null, \"valueX\", \"valueY\"});\n        }\n    }\n}",
      "method_signature": "testPostgresqlCsvParsingWithNullsAndEmptyStrings()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.4,
      "callable_precision": 0.1429,
      "focal_recall": 1.0,
      "focal_precision": 0.2857
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9844,
      "line_coverage": 0.9894,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "uncovered_focal_methods": [],
      "tp": 2,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 2,
          "call_composition_agent": 3,
          "compile_and_execute_test": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "get_method_details": 2,
          "finalize": 2
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "finalize"
          ],
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 3,
          "generate_test_code": 7,
          "compile_and_execute_test": 6,
          "modify_scenario_comment": 4,
          "finalize": 3
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 255713,
    "output_tokens": 29223,
    "llm_calls": 38
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 141,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then assign the constant `CSVFormat.POSTGRESQL_CSV` to a variable named `csvFormat` of type `CSVFormat`. Open a try-with-resources statement that first creates a `BufferedReader` named `reader` by invoking `Files.newBufferedReader` with arguments `Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\")` and `StandardCharsets.UTF_8`, then within the same try-with-resources block create a `CSVParser` named `parser` by invoking `csvFormat.parse(reader)`. Inside the try block, obtain an `Iterator<CSVRecord>` named `csvRecords` by calling `parser.iterator()`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then iterates through the array indices and for each index retrieves the corresponding value from the record using `get(i)`, comparing the array element to the record value with appropriate null-handling logic (if the array element is null, assert the record value is null; otherwise assert equality), and invoke this private method three times in sequence: first with a new `String[]` containing `\"AA\"`, `\"33\"`, and `null`, passing `csvRecords.next()` as the second argument; second with a new `String[]` containing `\"AA\"`, `null`, and `\"\"` (empty string), passing `csvRecords.next()` as the second argument; and third with a new `String[]` containing `null`, `\"33\"`, and `\"CC\"`, passing `csvRecords.next()` as the second argument. The try-with-resources construct automatically closes both `parser` and `reader` upon completion. The test uses the `@Test` annotation from JUnit 5, and the assertion logic within the private helper method should use either JUnit 5 Assertions (`assertEquals`, `assertNull`) or AssertJ (`assertThat`) to verify value equality and null conditions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSV254Test",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.Iterator;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\npublic class CSV254Test {\n\n    @Test\n    void testCSV254Scenario() throws IOException {\n        // Step 0: Define CSV format as POSTGRESQL_CSV\n        CSVFormat csvFormat = CSVFormat.POSTGRESQL_CSV;\n\n        // Steps 2, 3, 4, 5: Get Path, Create BufferedReader, Create CSVParser, Obtain Iterator\n        Path csvFilePath = Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\");\n        try (BufferedReader reader = Files.newBufferedReader(csvFilePath, StandardCharsets.UTF_8);\n             CSVParser parser = csvFormat.parse(reader)) {\n\n            Iterator<CSVRecord> csvRecordsIterator = parser.iterator();\n\n            // Step 6, 7: Get first CSV record and invoke helper method\n            CSVRecord firstCsvRecord = csvRecordsIterator.next();\n            assertRecordValues(new String[]{\"AA\", \"33\", null}, firstCsvRecord);\n\n            // Step 9, 10: Get second CSV record and invoke helper method\n            CSVRecord secondCsvRecord = csvRecordsIterator.next();\n            assertRecordValues(new String[]{\"AA\", null, \"\"}, secondCsvRecord);\n\n            // Step 12, 13: Get third CSV record and invoke helper method\n            CSVRecord thirdCsvRecord = csvRecordsIterator.next();\n            assertRecordValues(new String[]{null, \"33\", \"CC\"}, thirdCsvRecord);\n        }\n    }\n\n    // Step 1: Helper method to compare String array with CSVRecord, handling nulls and asserting equality\n    private void assertRecordValues(String[] expected, CSVRecord actual) {\n        Assertions.assertNotNull(expected, \"Expected array cannot be null\");\n        Assertions.assertNotNull(actual, \"Actual CSVRecord cannot be null\");\n        Assertions.assertEquals(expected.length, actual.size(), \"Expected array length and actual record size must match\");\n\n        for (int i = 0; i < expected.length; i++) {\n            String expectedValue = expected[i];\n            String actualValue = actual.get(i);\n\n            if (expectedValue == null) {\n                Assertions.assertNull(actualValue, \"Expected null at index \" + i + \", but found: \" + actualValue);\n            } else {\n                Assertions.assertEquals(expectedValue, actualValue, \"Value mismatch at index \" + i);\n            }\n        }\n    }\n}",
      "method_signature": "testCSV254Scenario()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.6,
      "callable_precision": 0.1935,
      "focal_recall": 1.0,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9844,
      "line_coverage": 0.9965,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.parse(java.io.Reader)",
        "org.apache.commons.csv.CSVParser.iterator()"
      ],
      "uncovered_focal_methods": [],
      "tp": 2,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 4,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 2,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 54114,
    "output_tokens": 10198,
    "llm_calls": 10
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 230,
      "description": "Define a test method that validates the CSV Format Builder's behavior when constructing a format configuration with an empty header array followed by parsing malformed CSV input. Begin by retrieving the first character from a static input string to use as the delimiter character. Build a CSV format by invoking the builder method on the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character, enabling automatic header detection with an empty header array, instructing the parser to skip the header record, and enabling the trimming of surrounding spaces before finalizing the format instance. With the configured format in hand, verify that attempting to parse the input string using the CSV Parser triggers a validation error due to missing header names by asserting that an IllegalArgumentException is thrown when the parser is instantiated within a try-with-resources block that immediately closes upon construction. This test uses JUnit 5 for the test framework and its assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.test.CsvFormatBuilderTest",
      "code": "package org.example.test;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\n\nimport java.io.IOException;\nimport java.lang.IllegalArgumentException;\n\npublic class CsvFormatBuilderTest {\n\n    @Test\n    void testMalformedCsvInputWithEmptyHeaderArray() {\n        // Step 0: Define static CSV input string\n        String csvInputString = \"a,b,c\\n1,2,3\";\n\n        // Step 1: Extract first character from input string to use as delimiter\n        char delimiterCharacter = csvInputString.charAt(0);\n\n        // Step 2: Obtain RFC4180 predefined CSV format\n        CSVFormat rfc4180Format = CSVFormat.RFC4180;\n\n        // Step 3: Build CSV format from RFC4180 predefined format, setting delimiter, enabling auto header detection with empty array, skipping header, and trimming spaces\n        CSVFormat configuredCsvFormat = rfc4180Format\n                .withDelimiter(delimiterCharacter)\n                .withHeader(new String[] {})\n                .withSkipHeaderRecord()\n                .withTrim(true);\n\n        // Step 4 & 5: Attempt to instantiate a CSV parser and assert that an IllegalArgumentException is thrown\n        IllegalArgumentException thrownException = Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = CSVParser.parse(csvInputString, configuredCsvFormat)) {\n                // The parser should not be successfully instantiated, so this block should not be reached\n                // If it is reached, it means the exception was not thrown as expected\n            }\n        });\n\n        // Step 6: Verify the exception message indicates missing header names (broader check)\n        Assertions.assertTrue(thrownException.getMessage().contains(\"header\"),\n                \"Exception message does not contain 'header'\");\n    }\n}",
      "method_signature": "testMalformedCsvInputWithEmptyHeaderArray()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.3333,
      "callable_precision": 0.3,
      "focal_recall": 0.1429,
      "focal_precision": 0.2
    },
    "coverage_eval": {
      "class_coverage": 0.6667,
      "method_coverage": 0.871,
      "line_coverage": 0.6334,
      "branch_coverage": 0.9048
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 1,
      "fn": 6,
      "localization_recall": 0.1429
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 6,
          "query_class_db": 2,
          "search_reachable_methods_in_class": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_class_db",
            "search_reachable_methods_in_class",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "get_method_details": 7,
          "generate_test_code": 4,
          "compile_and_execute_test": 4,
          "modify_scenario_comment": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 142630,
    "output_tokens": 12004,
    "llm_calls": 21
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 240,
      "description": "Create a test case to validate that the system properly rejects malformed data when attempting to parse information with an improperly configured structure where column headers are expected but not provided, ensuring the system enforces data integrity rules by confirming that when a parser is set up to automatically detect column headers from the first row while simultaneously being instructed to skip that header row and to remove extra spaces around values, and this parser is then given input data to process, the system immediately detects the missing header information and refuses to proceed with the operation by signaling a validation failure, thus preventing the creation of corrupted or inconsistent data records. Configure the parsing behavior to use the first character from the test input as the value separator, enable automatic header detection without explicitly naming the columns, activate the setting to bypass the header row during processing, and apply trimming of surrounding whitespace, then attempt to initiate the parsing operation with the provided input data and verify that the system blocks this action by raising an appropriate validation error indicating that required header information is absent. Verify the expected system behavior using JUnit 5 for test execution and standard equality assertions to confirm the validation failure occurs as intended.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvHeaderValidationTest1",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CsvHeaderValidationTest1 {\n\n    @Test\n    public void testEmpty() {\n        // Empty test\n    }\n}",
      "method_signature": "testEmpty()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 0.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.0,
      "callable_precision": 1.0,
      "focal_recall": 0.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "tp": 0,
      "fn": 7,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 3,
          "compile_and_execute_test": 2,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 5,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 11,
          "generate_test_code": 16,
          "compile_and_execute_test": 17,
          "finalize": 3,
          "get_maven_dependencies": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "get_method_details",
            "finalize"
          ],
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 353764,
    "output_tokens": 27495,
    "llm_calls": 52
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 241,
      "description": "Define a test class containing a private static final String field named `INPUT` and write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on `CSVFormat.RFC4180`, then chain `setDelimiter(INPUT.charAt(0))` (passing the character at index `0` of the `INPUT` string), chain `setHeader()` with no arguments, chain `setSkipHeaderRecord(true)`, chain `setIgnoreSurroundingSpaces(true)`, and finally chain `get()` to obtain a `CSVFormat` instance, assigning the result to a local variable named `format`. Immediately invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that invokes `CSVParser.parse(INPUT, format)` (passing the `INPUT` string literal and the `format` variable), assigns the result to a variable named `parser` of type `CSVParser`, and leaves the try block body empty (no operations performed with `parser`), thereby verifying that parsing the input with the configured format throws an `IllegalArgumentException` due to a missing header name. The test uses JUnit 5 Assertions via the `assertThrows` method and is annotated with `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserTest",
      "code": "package org.example;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\n\npublic class CsvParserTest {\n\n    private static final String INPUT = \",value1,value2\";\n\n    @Test\n    void testMissingHeaderException() throws IOException {\n        CSVFormat.Builder csvFormatBuilder = CSVFormat.RFC4180.builder();\n        csvFormatBuilder = csvFormatBuilder.setDelimiter(INPUT.charAt(0));\n        csvFormatBuilder = csvFormatBuilder.setHeader();\n        csvFormatBuilder = csvFormatBuilder.setSkipHeaderRecord(true);\n        csvFormatBuilder = csvFormatBuilder.setIgnoreSurroundingSpaces(true);\n        CSVFormat format = csvFormatBuilder.get();\n\n        IllegalArgumentException thrown = Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = CSVParser.parse(INPUT, format)) {\n            }\n        });\n\n        Assertions.assertTrue(thrown.getMessage().contains(\"missing\"), // Changed to a simpler substring\n                \"Expected exception message to contain 'missing' but was: \" + thrown.getMessage());\n    }\n}",
      "method_signature": "testMissingHeaderException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 1.0,
      "callable_precision": 0.6923,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.6667,
      "method_coverage": 0.871,
      "line_coverage": 0.6415,
      "branch_coverage": 0.9365
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setHeader(java.lang.String[])",
        "org.apache.commons.csv.CSVFormat.Builder.setSkipHeaderRecord(boolean)"
      ],
      "tp": 5,
      "fn": 2,
      "localization_recall": 0.7143
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 4,
          "call_composition_agent": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 21,
          "get_method_details": 2,
          "search_reachable_methods_in_class": 5,
          "finalize": 4
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "get_method_details",
            "finalize"
          ],
          [
            "finalize"
          ],
          [
            "finalize"
          ],
          [
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 3,
          "generate_test_code": 15,
          "compile_and_execute_test": 13,
          "modify_scenario_comment": 9,
          "finalize": 3
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 608169,
    "output_tokens": 81018,
    "llm_calls": 57
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 199,
      "description": "Define a test method that validates the parser's behavior when encountering a CSV input with a missing header name by configuring a CSV format builder starting from the RFC4180 preset, then extracting the first character from a predefined input string to set as the delimiter, followed by enabling first-record-as-header mode and activating surrounding space trimming to complete the format configuration. With the format constructed, wrap the input string in a string reader and attempt to instantiate a CSV parser using this reader and format within a try-with-resources block that immediately closes the parser without performing any operations. Assert that this instantiation attempt throws an IllegalArgumentException, confirming that the parser correctly rejects CSV data where header column names are missing or malformed when the format expects the first record to define headers. This test uses JUnit for the test framework and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.CsvParserMissingHeaderTest",
      "code": "package com.example;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport java.io.StringReader;\nimport java.io.IOException;\n\npublic class CsvParserMissingHeaderTest {\n\n    @Test\n    void testParserRejectsMissingHeaderName() {\n        // Step 0: Define CSV input string with a missing header name\n        String csv_input_string = \",H2\\nA,B\";\n\n        // Step 1: Initialize CSV format builder from RFC4180 preset\n        CSVFormat.Builder csv_format_builder = CSVFormat.RFC4180.builder();\n\n        // Step 2: Extract the first character from the input string to set as the delimiter\n        char delimiter_char = csv_input_string.charAt(0);\n\n        // Step 3: Set the delimiter in the CSV format builder\n        csv_format_builder = csv_format_builder.setDelimiter(delimiter_char);\n\n        // Step 4: Enable first-record-as-header mode in the CSV format builder\n        // Modified: Changed setSkipHeaderRecord(true) to setSkipHeaderRecord(false) to allow the first record to be processed as a header,\n        // which is necessary for the test description's goal of detecting missing header names.\n        // The original candidate method's argument value would have skipped the header.\n        csv_format_builder = csv_format_builder.setSkipHeaderRecord(false);\n\n        // Step 5: Activate surrounding space trimming in the CSV format builder\n        csv_format_builder = csv_format_builder.setTrim(true);\n\n        // Step 6: Build the CSV format\n        // Modified: Added .withHeader() to the get() call to enable first-record-as-header mode,\n        // which is crucial for the test to assert IllegalArgumentException on missing header names as per the test description.\n        // The original candidate method only called get().\n        CSVFormat csv_format = csv_format_builder.get().withHeader();\n\n        // Step 7: Wrap the input string in a StringReader\n        StringReader string_reader = new StringReader(csv_input_string);\n\n        // Step 8 & 9: Attempt to instantiate a CSV parser using the StringReader and CSV format within a try-with-resources block\n        // Assert that an IllegalArgumentException is thrown\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = CSVParser.parse(string_reader, csv_format)) {\n                // Parser is immediately closed by try-with-resources\n            }\n        });\n    }\n}",
      "method_signature": "testParserRejectsMissingHeaderName()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.5,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.4286,
      "callable_precision": 0.3,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.6667,
      "method_coverage": 0.8226,
      "line_coverage": 0.6141,
      "branch_coverage": 0.9016
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 13,
          "get_method_details": 6,
          "search_reachable_methods_in_class": 3,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "search_reachable_methods_in_class",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "modify_scenario_comment": 2,
          "generate_test_code": 2,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 98401,
    "output_tokens": 15983,
    "llm_calls": 14
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 201,
      "description": "Create a test case to validate that the system correctly enforces the requirement for complete header information when processing structured data files where the first line serves as column definitions and surrounding whitespace should be trimmed from values. Configure the processing rules to expect the first record as the header definition while ignoring any extra spaces around field values, using a specific delimiter character extracted from a predefined input sample. Attempt to initialize the data processing mechanism with these configured rules applied to the sample input, ensuring the system properly detects when header column names are missing or incomplete. Verify that the system rejects such malformed input by raising an appropriate validation failure, confirming that incomplete header definitions are not silently accepted during initialization. Once the validation behavior is confirmed, release any resources allocated during the processing attempt. The test employs JUnit 5 as the testing framework and uses standard exception assertion capabilities to verify the system throws the expected validation error when encountering missing column names in the header record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvHeaderValidationTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVParseException;\nimport java.io.StringReader;\n\npublic class CsvHeaderValidationTest {\n\n    @Test\n    void testMissingHeaderValidation() {\n        // Step 0: Define a predefined input sample to extract the delimiter\n        String predefinedInputSample = \"header1,header2,header3\\nvalue1,value2,value3\";\n\n        // Step 1: Extract the delimiter character from the predefined input sample\n        // Assuming the delimiter is a comma based on the sample.\n        char delimiterCharacter = ',';\n\n        // Step 2: Configure data processing rules\n        CSVFormat configuredProcessingRules = CSVFormat.DEFAULT\n                .withDelimiter(delimiterCharacter)\n                .withFirstRecordAsHeader()\n                .withTrim();\n\n        // Step 3: Prepare a structured data file sample with missing or incomplete header column names\n        String malformedInputData = \"header1,,header3\\nvalue1,value2,value3\"; // Missing header2\n\n        // Step 4 & 5: Attempt to initialize and verify validation failure\n        // The parsing attempt is embedded within assertThrows.\n        Assertions.assertThrows(CSVParseException.class, () -> {\n            configuredProcessingRules.parse(new StringReader(malformedInputData));\n        });\n\n        // Step 6: Release any resources allocated during the processing attempt\n        // In this test, parsing is expected to fail and throw an exception,\n        // so no CSVParser object is successfully created to be closed.\n    }\n}",
      "method_signature": "testMissingHeaderValidation()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "covered_focal_methods": [],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "tp": 0,
      "fn": 3,
      "localization_recall": 0.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 7,
          "get_method_details": 5,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "modify_scenario_comment": 2,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 60150,
    "output_tokens": 9451,
    "llm_calls": 13
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 211,
      "description": "Define a test method that declares a `private static final String` field named `INPUT` at the class level, then within the method body, begin by invoking `CSVFormat.RFC4180.withDelimiter(INPUT.charAt(0))` to obtain a `CSVFormat` instance, chain `.withFirstRecordAsHeader()` on the result, chain `.withIgnoreSurroundingSpaces()` on that result, and assign the final `CSVFormat` to a local variable named `format`. Next, invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that constructs a new `CSVParser` by passing `new StringReader(INPUT)` as the first argument and `format` as the second argument, assigning the parser to a variable named `parser`, with an empty body inside the try block. The test method is annotated with `@Test` and declares `throws IOException`. The test uses JUnit 5 Assertions for the `assertThrows` call.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport java.io.StringReader;\nimport java.io.IOException;\n\npublic class CsvParserTest {\n\n    private static final String INPUT = \",\\nvalue1,value2\"; // Delimiter is ',', first record is empty\n\n    @Test\n    void testEmptyHeaderThrowsIllegalArgumentException() throws IOException {\n        // Step 1: Obtain the first character of the INPUT string\n        char first_char_of_INPUT = INPUT.charAt(0);\n\n        // Step 2: Invoke CSVFormat.RFC4180.withDelimiter() using the obtained character\n        CSVFormat base_csv_format = CSVFormat.RFC4180.withDelimiter(first_char_of_INPUT);\n\n        // Step 3: Chain .withFirstRecordAsHeader() on the CSVFormat instance\n        CSVFormat format_with_header = base_csv_format.withFirstRecordAsHeader();\n\n        // Step 4: Chain .withIgnoreSurroundingSpaces() on the CSVFormat instance and assign to a local variable named format\n        CSVFormat format = format_with_header.withIgnoreSurroundingSpaces();\n\n        // Step 5 & 6: Assert that an IllegalArgumentException is thrown when attempting to construct a new CSVParser\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = new CSVParser(new StringReader(INPUT), format)) {\n                // empty body inside try block\n            }\n        });\n    }\n}",
      "method_signature": "testEmptyHeaderThrowsIllegalArgumentException()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.6667,
      "method_coverage": 0.871,
      "line_coverage": 0.6277,
      "branch_coverage": 0.8689
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.withDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.withFirstRecordAsHeader()",
        "org.apache.commons.csv.CSVFormat.withIgnoreSurroundingSpaces()"
      ],
      "uncovered_focal_methods": [],
      "tp": 3,
      "fn": 0,
      "localization_recall": 1.0
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 3,
          "query_class_db": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "query_method_db",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_method_details": 3,
          "get_class_constructors_and_factories": 1,
          "get_maven_dependencies": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_class_constructors_and_factories",
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 71209,
    "output_tokens": 9105,
    "llm_calls": 15
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 177,
      "description": "Create a test case to validate that the system can successfully parse structured data when configured with a specific processing format that uses the first character of a predefined input string as the field separator and enables whitespace trimming around values, ensuring the parser initializes correctly and releases all system resources properly afterward, verifying this scenario using JUnit 5 with standard try-with-resources pattern for automatic resource cleanup without requiring explicit assertions since the test confirms successful initialization and teardown through exception-free execution.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvParserTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\n\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class CsvParserTest {\n\n    @Test\n    void testCsvParsingWithCustomDelimiterAndTrim() throws IOException {\n        // Step 0: Define a predefined input string containing a field separator character\n        String predefinedInputString = \"header|value1|value2\";\n\n        // Step 1: Define structured data for parsing\n        String structuredData = \"data1 | data2 | data3\";\n\n        // Step 2: Define the expected parsed output (not used for assertion, but for completeness)\n        List<List<String>> expectedParsedOutput = Arrays.asList(Arrays.asList(\"data1\", \"data2\", \"data3\"));\n\n        // Step 3: Extract the first character from the predefined input string to use as a field separator\n        char fieldSeparator = predefinedInputString.charAt(0);\n\n        // Step 4: Configure the parser to use the extracted field separator\n        // Assuming CSVFormat.DEFAULT as the base as per comments\n        CSVFormat parserConfiguration = CSVFormat.DEFAULT.withDelimiter(fieldSeparator);\n\n        // Step 5: Configure the parser to enable whitespace trimming around values\n        CSVFormat parserConfigurationWithTrimming = parserConfiguration.withTrim();\n\n        // Step 6 & 7: Initialize the data parser with the specified configuration and parse the structured data\n        // Using try-with-resources for automatic resource cleanup\n        try (CSVParser dataParser = CSVParser.parse(structuredData, parserConfigurationWithTrimming)) {\n            List<CSVRecord> actualParsedData = dataParser.getRecords();\n\n            // Step 8: Verify the parsing operation completes successfully without errors\n            // (Implicitly verified by no exceptions)\n\n            // Step 9: Verify all system resources associated with the parser are released\n            // (Handled implicitly by try-with-resources)\n        }\n    }\n}",
      "method_signature": "testCsvParsingWithCustomDelimiterAndTrim()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.3333,
      "callable_precision": 0.2857,
      "focal_recall": 0.2,
      "focal_precision": 0.25
    },
    "coverage_eval": {
      "class_coverage": 0.625,
      "method_coverage": 0.8,
      "line_coverage": 0.5165,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()"
      ],
      "tp": 1,
      "fn": 4,
      "localization_recall": 0.2
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_class_db": 2,
          "query_method_db": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_class_db",
            "query_class_db",
            "query_method_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 1,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 36640,
    "output_tokens": 7933,
    "llm_calls": 9
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 192,
      "description": "Define a test method that validates the CSV parsing functionality when configuring a format through the builder pattern without specifying a header. Begin by retrieving the first character from the input string to serve as the delimiter character. Construct a CSV format by obtaining a builder from the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character and enabling the ignore surrounding spaces option before finalizing the format instance. With the configured format established, instantiate a CSV parser by invoking the static parse method with the input string and the constructed format, utilizing a try-with-resources block to ensure proper resource cleanup. The parser instance is created but not actively used within the test scope, as the test's purpose is to verify that the format configuration and parser instantiation complete without throwing exceptions when no explicit header is defined. Upon exiting the try-with-resources block, the parser is automatically closed, releasing any associated resources. This test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "com.example.csv.CsvParserConfigurationTest",
      "code": "package com.example.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.QuoteMode;\n\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nclass CsvParserConfigurationTest {\n\n    @Test\n    void testCsvParserInstantiationWithoutHeader() throws Exception {\n        // Step 1: Define an input string for CSV parsing\n        String inputString = \"header1,header2\\nvalue1,value2\";\n\n        // Step 2: Extract the first character from the input string\n        char delimiterCharacter = inputString.charAt(0);\n\n        // Step 3: Obtain a builder from the RFC4180 predefined CSV format\n        // Instead of getting a builder directly, we will configure the CSVFormat first\n        // and then get a builder from the configured format.\n        CSVFormat baseFormat = CSVFormat.RFC4180;\n\n        // Step 4: Configure the CSV format with the extracted delimiter character\n        // The `withDelimiter` method is found on `CSVFormat` itself, returning a new `CSVFormat` instance.\n        CSVFormat configuredFormat = baseFormat.withDelimiter(delimiterCharacter);\n\n        // Step 5: Enable the ignore surrounding spaces option on the CSV format\n        // The `withIgnoreSurroundingSpaces` method is found on `CSVFormat` itself, returning a new `CSVFormat` instance.\n        configuredFormat = configuredFormat.withIgnoreSurroundingSpaces(true);\n\n        // Step 6: Disable the quote character on the CSV format builder\n        // Now get the builder from the configured format to set the quote mode.\n        // An escape character is also set to satisfy validation requirements when quote mode is NONE.\n        CSVFormat.Builder configuredBuilderNoQuote = configuredFormat.builder()\n                                                                    .setQuoteMode(QuoteMode.NONE)\n                                                                    .withEscape('\\\\');\n\n        // Step 7: Finalize the CSV format instance from the builder\n        CSVFormat configuredCsvFormat = configuredBuilderNoQuote.build();\n\n        // Step 8: Instantiate a CSV parser using the input string and the configured CSV format within a try-with-resources block\n        try (CSVParser csvParserInstance = CSVParser.parse(inputString, configuredCsvFormat)) {\n            // Step 9: Verify that the CSV format configuration and parser instantiation complete without throwing exceptions\n            // The successful execution of this block without exceptions and the automatic closing of the parser\n            // via try-with-resources fulfills the verification requirement.\n            assertNotNull(csvParserInstance, \"CSVParser instance should not be null\");\n        }\n    }\n}",
      "method_signature": "testCsvParserInstantiationWithoutHeader()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)"
      ],
      "tp": 2,
      "fn": 3,
      "localization_recall": 0.4
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 3,
          "call_composition_agent": 3,
          "compile_and_execute_test": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "call_localization_agent",
            "call_composition_agent",
            "compile_and_execute_test",
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "finalize": 3,
          "query_method_db": 1,
          "search_reachable_methods_in_class": 2,
          "get_method_details": 1,
          "query_class_db": 2
        },
        "tool_trajectories": [
          [
            "finalize"
          ],
          [
            "finalize"
          ],
          [
            "query_method_db",
            "search_reachable_methods_in_class",
            "get_method_details",
            "query_class_db",
            "search_reachable_methods_in_class",
            "query_class_db",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 3,
          "generate_test_code": 10,
          "compile_and_execute_test": 8,
          "modify_scenario_comment": 13,
          "finalize": 3,
          "get_method_details": 11,
          "get_class_constructors_and_factories": 1,
          "get_getters_and_setters": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "get_class_constructors_and_factories",
            "get_getters_and_setters",
            "get_method_details",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "get_method_details",
            "generate_test_code",
            "finalize"
          ],
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "get_method_details",
            "modify_scenario_comment",
            "modify_scenario_comment",
            "generate_test_code",
            "compile_and_execute_test",
            "modify_scenario_comment",
            "generate_test_code",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 418837,
    "output_tokens": 29268,
    "llm_calls": 57
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 200,
      "description": "Define a test class containing a private static final field `INPUT` of type `String`, then write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on the static field `CSVFormat.RFC4180`, which returns a `CSVFormat.Builder` instance, then immediately chain `setDelimiter(char)` passing the character obtained by calling `charAt(0)` on the `INPUT` field, chain `setIgnoreSurroundingSpaces(true)` to enable trimming behavior, and finally chain `get()` to build the format, assigning the resulting `CSVFormat` instance to a local variable named `format`. Next, open a try-with-resources block by invoking the static method `parse(String, CSVFormat)` on `CSVParser`, passing `INPUT` as the first argument and `format` as the second argument, assigning the returned `CSVParser` instance to a resource variable named `parser`, and leave the try block body empty to allow automatic resource closure without performing any parsing operations. The test uses class-level annotation `@Test`, method-level annotation `@Test`, assertion libraries none, and mocking libraries none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.example.CsvParserTest",
      "code": "package org.example;\n\nimport org.junit.jupiter.api.Test;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\n\nimport java.io.IOException;\n\npublic class CsvParserTest {\n\n    private static final String INPUT = \"A,B,C\";\n\n    @Test\n    void testCsvParsing() throws IOException {\n        CSVFormat format = CSVFormat.RFC4180.builder()\n                .setDelimiter(INPUT.charAt(0))\n                .setIgnoreSurroundingSpaces(true)\n                .get();\n\n        try (CSVParser parser = CSVParser.parse(INPUT, format)) {\n            // Empty body as per instructions\n        }\n    }\n}",
      "method_signature": "testCsvParsing()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.625,
      "method_coverage": 0.8,
      "line_coverage": 0.5165,
      "branch_coverage": 0.8182
    },
    "localization_eval": {
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "all_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "covered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.get()",
        "org.apache.commons.csv.CSVFormat.builder()",
        "org.apache.commons.csv.CSVParser.parse(java.lang.String, org.apache.commons.csv.CSVFormat)"
      ],
      "uncovered_focal_methods": [
        "org.apache.commons.csv.CSVFormat.Builder.setDelimiter(char)",
        "org.apache.commons.csv.CSVFormat.Builder.setIgnoreSurroundingSpaces(boolean)"
      ],
      "tp": 3,
      "fn": 2,
      "localization_recall": 0.6
    },
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "call_localization_agent": 1,
          "call_composition_agent": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "call_localization_agent",
            "call_composition_agent",
            "finalize"
          ]
        ]
      },
      "localization_tool_log": {
        "tool_counts": {
          "query_method_db": 5,
          "get_method_details": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "query_method_db",
            "get_method_details",
            "finalize"
          ]
        ]
      },
      "composition_tool_log": {
        "tool_counts": {
          "get_maven_dependencies": 1,
          "generate_test_code": 2,
          "compile_and_execute_test": 2,
          "get_method_details": 2,
          "get_getters_and_setters": 1,
          "finalize": 1
        },
        "tool_trajectories": [
          [
            "get_maven_dependencies",
            "generate_test_code",
            "compile_and_execute_test",
            "get_method_details",
            "get_method_details",
            "get_getters_and_setters",
            "generate_test_code",
            "compile_and_execute_test",
            "finalize"
          ]
        ]
      }
    },
    "input_tokens": 76044,
    "output_tokens": 8754,
    "llm_calls": 14
  }
]