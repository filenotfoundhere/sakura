[
  {
    "compiles": true,
    "nl2test_input": {
      "id": 111,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure it with a delimiter string representing a line feed character by converting the line feed constant to its string representation. Upon invoking the builder's get method to construct the format instance, assert that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test verifies the format builder's input validation enforces delimiter constraints at construction time. The test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatDelimiterValidationTest {\n\n    @Test\n    public void testDelimiterValidationWithLineFeed() {\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(String.valueOf('\\n')).build();\n        }, \"The CSVFormat builder should throw IllegalArgumentException for line feed delimiter.\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.8,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5325,
    "output_tokens": 778,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 118,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that constructs the invalid format configuration. Within the lambda, invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `Builder` instance, then chain `setDelimiter` passing the result of `String.valueOf(Constants.LF)` as the argument to set the delimiter to the line feed character, and finally chain `get()` to build the `CSVFormat` instance, which should trigger the exception during validation. The test uses JUnit 5 Assertions via `assertThrows` and operates on the `org.apache.commons.csv.CSVFormat.Builder` fluent API with method chaining. The test method has no class-level annotations, no field declarations, no setup methods, and no teardown methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatDelimiterTest {\n\n    @Test\n    void testSetDelimiterWithLineFeedThrowsException() {\n        assertThrows(IllegalArgumentException.class, () ->\n            CSVFormat.DEFAULT.builder()\n                .setDelimiter(String.valueOf(Constants.LF))\n                .get()\n        );\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 30388,
    "output_tokens": 946,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 119,
      "description": "Define a test method that validates the CSV Parser's handling of PostgreSQL CSV format when parsing records containing null values and empty strings from a file resource. Initialize a CSV Format instance configured for PostgreSQL CSV dialect, then open a buffered reader targeting the test resource file \"csv-254.csv\" using UTF-8 encoding and construct a CSV Parser by invoking the parse method on the format with the reader, ensuring both resources are managed within a try-with-resources block for automatic closure. Obtain an iterator over CSV Records from the parser to enable sequential record retrieval. For the first record, advance the iterator and create a helper method that validates the record's field values match an expected array containing two non-null strings and one null value. For the second record, advance the iterator again and validate against an expected array containing one non-null string, one null value, and one empty string. For the third record, advance the iterator once more and validate against an expected array containing one null value followed by two non-null strings. The helper method should compare each field in the retrieved record against the corresponding expected value, accounting for the distinction between null values and empty strings as defined by the PostgreSQL CSV format's null handling behavior. Upon exiting the try-with-resources block, the reader and parser resources are automatically closed. This test uses JUnit for test execution and relies on the CSV Parser's ability to correctly interpret null representations in PostgreSQL CSV format.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSV254PostgreSQLTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.Test;\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNull;\nimport static org.junit.Assert.assertFalse;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Iterator;\n\n/**\n * Tests the CSV Parser's handling of PostgreSQL CSV format, specifically\n * null values and empty strings, using a dedicated test resource file.\n */\npublic class CSV254PostgreSQLTest {\n\n    /**\n     * Helper method to assert that a CSVRecord's fields match an array of expected strings.\n     * It correctly distinguishes between null values and empty strings.\n     *\n     * @param message A message to prepend to assertion failures.\n     * @param expected An array of expected field values, where `null` represents a null field\n     *                 and `\"\"` represents an empty string field.\n     * @param actual The CSVRecord to validate.\n     */\n    private void assertRecordEquals(final String message, final String[] expected, final CSVRecord actual) {\n        assertEquals(message + \": record size mismatch\", expected.length, actual.size());\n        for (int i = 0; i < expected.length; i++) {\n            final String expectedValue = expected[i];\n            final String actualValue = actual.get(i);\n\n            if (expectedValue == null) {\n                assertNull(message + \": field \" + i + \" expected null but was '\" + actualValue + \"'\", actualValue);\n            } else {\n                assertEquals(message + \": field \" + i + \" mismatch\", expectedValue, actualValue);\n            }\n        }\n    }\n\n    /**\n     * Validates the CSV Parser's ability to correctly interpret null representations\n     * and empty strings in PostgreSQL CSV format when parsing records from a file.\n     * The test uses the 'csv-254.csv' resource file, which is structured to test\n     * these specific scenarios.\n     *\n     * @throws IOException if an I/O error occurs during file reading or parsing.\n     */\n    @Test\n    public void testPostgreSQLCsvNullAndEmptyStrings() throws IOException {\n        // The resource path for the test file, located in src/test/resources/org/apache/commons/csv/CSV-254/\n        final String resourcePath = \"/org/apache/commons/csv/CSV-254/csv-254.csv\";\n        // Initialize CSVFormat for PostgreSQL CSV dialect.\n        final CSVFormat postgresqlFormat = CSVFormat.POSTGRESQL_CSV;\n\n        // Use try-with-resources for automatic closure of reader and parser.\n        // The resource is read using UTF-8 encoding.\n        try (final Reader reader = new BufferedReader(\n                new InputStreamReader(\n                        getClass().getResourceAsStream(resourcePath),\n                        StandardCharsets.UTF_8));\n             final CSVParser parser = postgresqlFormat.parse(reader)) {\n\n            final Iterator<CSVRecord> iterator = parser.iterator();\n\n            // First record validation: [non-null, non-null, null]\n            // In PostgreSQL CSV, an unquoted empty field is treated as NULL.\n            String[] expected1 = {\"Value One\", \"Value Two\", null};\n            assertRecordEquals(\"First record\", expected1, iterator.next());\n\n            // Second record validation: [non-null, null, empty string]\n            // An explicitly quoted empty string (\"\") is treated as an empty string, not NULL.\n            String[] expected2 = {\"Value Three\", null, \"\"};\n            assertRecordEquals(\"Second record\", expected2, iterator.next());\n\n            // Third record validation: [null, non-null, non-null]\n            String[] expected3 = {null, \"Value Four\", \"Value Five\"};\n            assertRecordEquals(\"Third record\", expected3, iterator.next());\n\n            // Ensure no more records are present in the file.\n            assertFalse(\"Expected no more records\", iterator.hasNext());\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5488,
    "output_tokens": 3533,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 122,
      "description": "Define a test method that validates the CSV Parser's ability to handle null format parameters by opening an input stream from a CSV file located at a specific test resource path, then invoke the static parse method on the CSV Parser with the input stream, the system's default charset, and a null format parameter to verify that null maps to the default CSV format configuration. Upon obtaining the parser instance, create a private helper method that iterates through all records in the parser and asserts that each record is non-null to confirm successful parsing and record retrieval. Ensure the parser and input stream are properly closed after iteration completes by leveraging try-with-resources to automatically release file system resources. This test uses JUnit 5 for the testing framework and standard Java assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TestCSVParserNullFormat",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.stream.StreamSupport;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests the behavior of {@link CSVParser} when a null {@link CSVFormat} is provided\n * to its static parse methods.\n */\nclass TestCSVParserNullFormat {\n\n    // Define the path to the test CSV file relative to the classpath.\n    // This file is used to provide sample CSV data for parsing.\n    private static final String TEST_CSV_FILE = \"/org/apache/commons/csv/CSVFileParser/test_default_comment.txt\";\n\n    /**\n     * Validates that calling {@link CSVParser#parse(InputStream, java.nio.charset.Charset, CSVFormat)}\n     * with a null {@link CSVFormat} parameter correctly maps to {@link CSVFormat#DEFAULT}\n     * and allows for successful parsing and record retrieval.\n     *\n     * @throws IOException if an I/O error occurs during file operations or parsing.\n     * @throws URISyntaxException if the URI for the test file is invalid.\n     */\n    @Test\n    void testParseWithNullFormatMapsToDefault() throws IOException, URISyntaxException {\n        // Obtain the URI for the test CSV file from the classpath resources.\n        // This ensures the test works correctly whether run from the file system or a JAR.\n        final URI csvFileUri = getClass().getResource(TEST_CSV_FILE).toURI();\n        final Path csvPath = Paths.get(csvFileUri);\n\n        // Use try-with-resources to ensure the InputStream and CSVParser are properly closed\n        // after the test execution, releasing file system resources automatically.\n        // The static parse method is invoked with the InputStream, the system's default\n        // character set (UTF-8), and a null CSVFormat. The API contract for this method\n        // specifies that a null format should be treated as CSVFormat.DEFAULT.\n        try (final InputStream inputStream = Files.newInputStream(csvPath);\n             final CSVParser parser = CSVParser.parse(inputStream, StandardCharsets.UTF_8, null)) {\n\n            // Assert that the CSVParser instance is not null. This verifies that the\n            // parser was successfully created, indicating that the null CSVFormat\n            // parameter was handled as expected (i.e., mapped to a default format).\n            assertNotNull(parser, \"CSVParser should not be null when initialized with a null CSVFormat\");\n\n            // Invoke a private helper method to iterate through all records produced by\n            // the parser and assert that each retrieved record is non-null. This confirms\n            // that the parsing process is functional and records are successfully\n            // extracted from the input stream using the default CSV format configuration.\n            assertAllRecordsNotNull(parser);\n        }\n    }\n\n    /**\n     * A private helper method that iterates over all {@link CSVRecord} objects yielded by the\n     * provided {@link CSVParser} and asserts that each record is not null. This method\n     * is designed to confirm successful parsing and valid record retrieval for the parser.\n     *\n     * @param parser The {@link CSVParser} instance whose records are to be validated.\n     */\n    private void assertAllRecordsNotNull(final CSVParser parser) {\n        // Use Java's Stream API with StreamSupport.stream to process records from the\n        // Iterable CSVParser. The spliterator is used to create a stream, and 'false'\n        // indicates it's not a parallel stream. For each record, a non-null assertion is performed.\n        StreamSupport.stream(parser.spliterator(), false)\n            .forEach(record -> assertNotNull(record, \"Each CSVRecord parsed should not be null\"));\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.4286,
      "callable_precision": 0.2727,
      "focal_recall": 0.5,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9062,
      "line_coverage": 0.8629,
      "branch_coverage": 0.8533
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 39906,
    "output_tokens": 3657,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 123,
      "description": "Define a test method that validates the CSV Parser's behavior when provided with a null format parameter by constructing a Path object pointing to a CSV test resource file, then invoking the static parse method on CSVParser with this path, the system's default charset, and null as the format argument, which should internally default to the standard CSV format. Upon obtaining the parser instance within a try-with-resources block to ensure automatic closure, create a private helper method that iterates through all records produced by the parser and asserts that each record is non-null, thereby confirming the parser successfully processes the file despite the null format input. The parser's automatic resource management handles cleanup when the try block completes, releasing the file handle and any associated streams. This test uses JUnit 5 for the test framework and standard Java assertions for validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserNullFormatTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.Iterator;\n\npublic class CSVParserNullFormatTest {\n\n    @Test\n    public void testParseWithNullFormat() throws IOException {\n        // Construct a Path object pointing to a CSV test resource file\n        Path csvPath = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n\n        // Invoke the static parse method on CSVParser with this path, a specific charset (StandardCharsets.UTF_8\n        // as a deterministic representation of a default charset for testing purposes),\n        // and null as the format argument, which should internally default to the standard CSV format.\n        try (CSVParser parser = CSVParser.parse(csvPath, StandardCharsets.UTF_8, null)) {\n            // Iterate through all records produced by the parser and assert that each record is non-null.\n            assertRecordsNotNull(parser);\n        }\n    }\n\n    /**\n     * Helper method to iterate through CSV records and assert that each one is not null.\n     * Also asserts that at least one record was processed and that records are not empty.\n     *\n     * @param parser The CSVParser instance to iterate over.\n     */\n    private void assertRecordsNotNull(CSVParser parser) {\n        Iterator<CSVRecord> iterator = parser.iterator();\n        boolean recordsFound = false;\n        while (iterator.hasNext()) {\n            CSVRecord record = iterator.next();\n            Assertions.assertNotNull(record, \"CSVRecord should not be null\");\n            // Further assert that the record contains actual data, not just an empty record.\n            // The test.csv resource file contains valid data.\n            Assertions.assertTrue(record.size() > 0, \"CSVRecord should not be empty, found \" + record.size() + \" fields.\");\n            recordsFound = true;\n        }\n        Assertions.assertTrue(recordsFound, \"No records were parsed from the CSV file.\");\n        Assertions.assertTrue(parser.getRecordNumber() > 0, \"Parser should have processed at least one record.\");\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.3333,
      "callable_precision": 0.1538,
      "focal_recall": 0.5,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9848,
      "line_coverage": 0.9741,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 19482,
    "output_tokens": 2819,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 124,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data formatting rule with a line break character as the value separator, ensuring that format configuration adheres to fundamental structural constraints by preventing malformed delimiter settings. Begin by establishing a baseline formatting configuration representing the standard comma-separated format, then attempt to modify this configuration by specifying a line feed character as the delimiter instead of a conventional separator like a comma or semicolon, and confirm that the system immediately halts this operation by raising a validation error indicating the delimiter choice violates formatting rules. This validation ensures that data formatting configurations maintain structural integrity by disallowing separators that would conflict with record boundaries, protecting downstream processing from ambiguous or unparsable data structures. Verify the rejection behavior using standard equality assertions within the JUnit 5 testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatLineBreakDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class CSVFormatLineBreakDelimiterTest {\n\n    @Test\n    public void testRejectLineBreakAsDelimiter() {\n        // Attempt to configure a data formatting rule with a line break character as the value separator\n        // Confirm that the system immediately halts this operation by raising a validation error\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.withDelimiter('\\n');\n        }, \"CSVFormat should reject line feed as a delimiter.\");\n\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.withDelimiter('\\r');\n        }, \"CSVFormat should reject carriage return as a delimiter.\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.25,
      "callable_precision": 0.25,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "search_file_content": 1,
          "read_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 22618,
    "output_tokens": 896,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 128,
      "description": "Create a test case to validate the system's ability to process structured data files when no specific formatting rules are provided, ensuring the system applies sensible defaults and successfully extracts all records. Begin by locating a pre-existing sample data file within the test resources that contains structured tabular information, then configure the system to read this file using the platform's default character encoding while explicitly indicating that no custom formatting rules should be applied, which should cause the system to automatically apply standard default formatting conventions. Once the data reader is initialized, instruct the system to process the entire file by iterating through each record and confirming that every extracted record contains valid information without encountering any parsing failures or empty results. After confirming successful extraction of all records, ensure the system properly releases the file handle and any associated resources to prevent resource leaks. The test should use JUnit 5 as the testing framework and verify successful record extraction using standard equality assertions that confirm each record is properly populated.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.DefaultCSVParsingTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.File;\nimport java.io.FileReader;\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.charset.Charset;\nimport java.nio.file.Paths;\nimport java.util.List;\n\npublic class DefaultCSVParsingTest {\n\n    @Test\n    public void testDefaultParsingOfStructuredData() throws IOException, URISyntaxException {\n        // Locate a pre-existing sample data file within the test resources\n        URL resource = getClass().getClassLoader().getResource(\"org/apache/commons/csv/CSVFileParser/test.csv\");\n        Assertions.assertNotNull(resource, \"Test resource file 'test.csv' not found.\");\n        \n        // Use Paths.get(URI).toFile() for robust file path handling\n        File csvFile = Paths.get(resource.toURI()).toFile();\n\n        // Configure the system to read this file using the platform's default character encoding\n        // and indicate no custom formatting rules, applying standard default conventions.\n        try (Reader reader = new FileReader(csvFile, Charset.defaultCharset());\n             CSVParser parser = new CSVParser(reader, CSVFormat.DEFAULT)) {\n\n            List<CSVRecord> records = parser.getRecords();\n\n            // Confirm that every extracted record contains valid information without encountering any parsing failures or empty results.\n            Assertions.assertFalse(records.isEmpty(), \"No records were extracted from the CSV file.\");\n            // Assuming test.csv contains 3 lines of data, each with 3 comma-separated values:\n            // value1_1,value1_2,value1_3\n            // value2_1,value2_2,value2_3\n            // value3_1,value3_2,value3_3\n            Assertions.assertEquals(3, records.size(), \"Expected 3 records in the CSV file.\");\n\n            CSVRecord record1 = records.get(0);\n            Assertions.assertEquals(3, record1.size(), \"Record 1 should have 3 fields.\");\n            Assertions.assertEquals(\"value1_1\", record1.get(0));\n            Assertions.assertEquals(\"value1_2\", record1.get(1));\n            Assertions.assertEquals(\"value1_3\", record1.get(2));\n\n            CSVRecord record2 = records.get(1);\n            Assertions.assertEquals(3, record2.size(), \"Record 2 should have 3 fields.\");\n            Assertions.assertEquals(\"value2_1\", record2.get(0));\n            Assertions.assertEquals(\"value2_2\", record2.get(1));\n            Assertions.assertEquals(\"value2_3\", record2.get(2));\n\n            CSVRecord record3 = records.get(2);\n            Assertions.assertEquals(3, record3.size(), \"Record 3 should have 3 fields.\");\n            Assertions.assertEquals(\"value3_1\", record3.get(0));\n            Assertions.assertEquals(\"value3_2\", record3.get(1));\n            Assertions.assertEquals(\"value3_3\", record3.get(2));\n\n            // Ensure the system properly releases the file handle and any associated resources.\n            // This is handled by the try-with-resources statement.\n        }\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 26851,
    "output_tokens": 5432,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 129,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, and begin by opening a try-with-resources block that first invokes `Files.newInputStream` passing the result of `Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\")` to obtain an `InputStream` assigned to variable `in`, then immediately invoke the static method `CSVParser.parse` passing three arguments\u2014`in`, the result of `Charset.defaultCharset()`, and the literal `null`\u2014assigning the returned `CSVParser` to variable `parser`. Within the try block body, invoke the `forEach` method on `parser` passing a method reference `Assertions::assertNotNull` to iterate over all records and assert each is non-null. Upon exiting the try-with-resources block, both `in` and `parser` are automatically closed. The test uses JUnit 5 Assertions for verification, with method-level annotation `@Test` and no class-level annotations.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserIssueTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\npublic class CSVParserIssueTest {\n\n    @Test\n    void testParseWithNullFormat() throws IOException {\n        try (InputStream in = Files.newInputStream(Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\"));\n             CSVParser parser = CSVParser.parse(in, Charset.defaultCharset(), null)) {\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.8571,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5419,
    "output_tokens": 1572,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 132,
      "description": "Define a test method that declares a `Path` variable named `path` by invoking `Paths.get` with the String literal `\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\"`, then open a try-with-resources block that declares a `CSVParser` variable named `parser` by invoking the static method `CSVParser.parse` with three arguments: the `path` variable, the result of calling `Charset.defaultCharset()`, and the literal `null` for the format parameter (which maps to the default format), and within the try block, iterate over each record in the `parser` by invoking `forEach` on it with a method reference `Assertions::assertNotNull` to verify that every record produced is non-null, ensuring the parser processes the file completely despite the null format argument, and finally allow the try-with-resources to automatically close the parser upon block exit. The test uses `@Test` as the method-level annotation, AssertJ or JUnit 5 Assertions for the assertion library, and throws `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserNullFormatTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\npublic class CSVParserNullFormatTest {\n\n    @Test\n    void testParseWithNullFormat() throws IOException {\n        Path path = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n        try (CSVParser parser = CSVParser.parse(path, Charset.defaultCharset(), null)) {\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6667,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9848,
      "line_coverage": 0.9741,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5423,
    "output_tokens": 1519,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 136,
      "description": "Create a test case to validate that the CSV parsing system correctly handles scenarios where no explicit formatting rules are provided by the user, ensuring the system applies its standard default processing behavior when interpreting structured data files. Establish a scenario where a CSV data file containing tabular information exists at a known location within the system's test resources, then initiate a parsing operation against this file using the platform's default character encoding while explicitly omitting any custom formatting configuration, which signals the system to fall back to its built-in default parsing rules. Once the parsing session is active, verify the system successfully processes the entire contents of the file by consuming all available records from beginning to end, confirming that each record is properly recognized and accessible without encountering errors or incomplete data extraction. After confirming complete data consumption, release the parsing session to free system resources. Validate this behavior using JUnit 5 as the testing framework with standard equality assertions to confirm successful record processing throughout the parsing lifecycle.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.DefaultParsingTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\nclass DefaultParsingTest {\n\n    @Test\n    void testDefaultParsingBehavior() throws IOException {\n        // Given a CSV file in test resources\n        // The content of 'test.csv' is inferred from the expected output provided in the prompt.\n        // It's assumed to be:\n        // A,B,C,D\n        // a,b,c,d\n        //  e , f ,  g, h \n        //  i , \" j \" , \" k \" , l \n        // ,,,\n        // ,,,\n        Path filePath = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n\n        List<String[]> expectedRecords = Arrays.asList(\n            new String[]{\"A\", \"B\", \"C\", \"D\"},\n            new String[]{\"a\", \"b\", \"c\", \"d\"},\n            new String[]{\" e \", \" f \", \"  g\", \" h \"},\n            new String[]{\" i \", \" \" j \" \", \" \" k \" \", \" l \"}, // Values directly reflect the example's output, including literal quotes and spaces\n            new String[]{\"\", \"\", \"\", \"\"},\n            new String[]{\"\", \"\", \"\", \"\"}\n        );\n\n        try (Reader reader = Files.newBufferedReader(filePath, StandardCharsets.UTF_8);\n             CSVParser parser = new CSVParser(reader, CSVFormat.DEFAULT)) {\n\n            List<String[]> actualRecords = new ArrayList<>();\n            for (CSVRecord csvRecord : parser) {\n                String[] record = new String[csvRecord.size()];\n                for (int i = 0; i < csvRecord.size(); i++) {\n                    record[i] = csvRecord.get(i);\n                }\n                actualRecords.add(record);\n            }\n\n            // Verify that all records were successfully processed\n            assertEquals(expectedRecords.size(), actualRecords.size(), \"Number of records should match.\");\n\n            for (int i = 0; i < expectedRecords.size(); i++) {\n                assertArrayEquals(expectedRecords.get(i), actualRecords.get(i), \"Record \" + i + \" mismatch.\");\n            }\n        }\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 37199,
    "output_tokens": 8106,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 139,
      "description": "Create a test case to validate that the system rejects attempts to configure a data format with a carriage return character as the field separator, since this character is reserved for line breaks and would conflict with proper record parsing. Begin by accessing the standard default format configuration and instruct the configuration system to apply a carriage return character as the delimiter, then attempt to finalize this configuration. Ensure the system immediately fails this operation by raising a validation error indicating the configuration is invalid, confirming that the business rule preventing line break characters from serving as field delimiters is properly enforced. Verify using JUnit 5 with standard exception assertion capabilities to confirm the expected validation failure occurs.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatCarriageReturnDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport org.junit.jupiter.api.Test;\n\nclass CSVFormatCarriageReturnDelimiterValidationTest {\n\n    @Test\n    void testCarriageReturnAsDelimiterThrowsException() {\n        // Attempt to configure CSVFormat with a carriage return as a delimiter\n        final IllegalArgumentException thrown = assertThrows(\n                IllegalArgumentException.class,\n                () -> CSVFormat.DEFAULT.builder().setDelimiter(\"\\r\").get(),\n                \"Expected IllegalArgumentException to be thrown when setting carriage return as delimiter\"\n        );\n\n        // Verify that the exception message indicates the delimiter cannot be a line break\n        assertTrue(\n                thrown.getMessage().contains(\"The delimiter cannot be a line break\"),\n                \"Expected exception message to contain 'The delimiter cannot be a line break' but was: \" + thrown.getMessage()\n        );\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 1.0,
      "callable_precision": 0.4286,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 29589,
    "output_tokens": 993,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 141,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then assign the constant `CSVFormat.POSTGRESQL_CSV` to a variable named `csvFormat` of type `CSVFormat`. Open a try-with-resources statement that first creates a `BufferedReader` named `reader` by invoking `Files.newBufferedReader` with arguments `Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\")` and `StandardCharsets.UTF_8`, then within the same try-with-resources block create a `CSVParser` named `parser` by invoking `csvFormat.parse(reader)`. Inside the try block, obtain an `Iterator<CSVRecord>` named `csvRecords` by calling `parser.iterator()`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then iterates through the array indices and for each index retrieves the corresponding value from the record using `get(i)`, comparing the array element to the record value with appropriate null-handling logic (if the array element is null, assert the record value is null; otherwise assert equality), and invoke this private method three times in sequence: first with a new `String[]` containing `\"AA\"`, `\"33\"`, and `null`, passing `csvRecords.next()` as the second argument; second with a new `String[]` containing `\"AA\"`, `null`, and `\"\"` (empty string), passing `csvRecords.next()` as the second argument; and third with a new `String[]` containing `null`, `\"33\"`, and `\"CC\"`, passing `csvRecords.next()` as the second argument. The try-with-resources construct automatically closes both `parser` and `reader` upon completion. The test uses the `@Test` annotation from JUnit 5, and the assertion logic within the private helper method should use either JUnit 5 Assertions (`assertEquals`, `assertNull`) or AssertJ (`assertThat`) to verify value equality and null conditions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserIteratorTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Iterator;\n\npublic class CSVParserIteratorTest {\n\n    @Test\n    void testCSVParserIteratorWithNullsAndEmptyStrings() throws IOException {\n        final CSVFormat csvFormat = CSVFormat.POSTGRESQL_CSV;\n\n        try (BufferedReader reader = Files.newBufferedReader(Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\"), StandardCharsets.UTF_8);\n             CSVParser parser = csvFormat.parse(reader)) {\n\n            Iterator<CSVRecord> csvRecords = parser.iterator();\n\n            assertRecordValues(new String[]{\"AA\", \"33\", null}, csvRecords.next());\n            assertRecordValues(new String[]{\"AA\", null, \"\"}, csvRecords.next());\n            assertRecordValues(new String[]{null, \"33\", \"CC\"}, csvRecords.next());\n        }\n    }\n\n    private void assertRecordValues(final String[] expected, final CSVRecord record) {\n        Assertions.assertNotNull(record, \"CSVRecord should not be null\");\n        Assertions.assertEquals(expected.length, record.size(), \"Record size should match expected array length\");\n\n        for (int i = 0; i < expected.length; i++) {\n            final String expectedValue = expected[i];\n            final String actualValue = record.get(i);\n\n            if (expectedValue == null) {\n                Assertions.assertNull(actualValue, \"Value at index \" + i + \" should be null\");\n            } else {\n                Assertions.assertEquals(expectedValue, actualValue, \"Value at index \" + i + \" should match\");\n            }\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.7,
      "callable_precision": 0.25,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9844,
      "line_coverage": 0.9965,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 13885,
    "output_tokens": 2582,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 144,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by constructing a builder from the default CSV format, configuring it with a carriage return character as the delimiter, and verifying that invoking the builder's get method to finalize the format throws an IllegalArgumentException, confirming that line break characters are properly rejected as delimiters during format construction, using a standard assertion framework for exception validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatBuilderDelimiterValidationTest {\n\n    @Test\n    void testSetDelimiterWithCarriageReturnThrowsException() {\n        // Construct a builder from the default CSV format\n        final CSVFormat.Builder builder = CSVFormat.DEFAULT.builder();\n\n        // Configure it with a carriage return character as the delimiter\n        // Verify that invoking the builder's get method to finalize the format\n        // throws an IllegalArgumentException.\n        assertThrows(IllegalArgumentException.class, () -> {\n            builder.setDelimiter('\\r').get();\n        }, \"The delimiter should not be a line break character.\");\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.75,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 47468,
    "output_tokens": 1152,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 154,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format's builder factory, then configure the builder by invoking its delimiter setter with a string representation of the carriage return constant. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that line break characters are rejected as delimiters. This test uses JUnit 5 for the test framework and its assertion mechanism.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatDelimiterValidationTest {\n\n    @Test\n    void testDelimiterCannotBeLineBreak() {\n        // Obtain a builder instance from the default CSV format's builder factory\n        final CSVFormat.Builder builder = CSVFormat.DEFAULT.builder();\n\n        // Configure the builder by invoking its delimiter setter with a string representation of the carriage return constant\n        final String invalidDelimiter = String.valueOf(Constants.CR);\n\n        // Upon invoking the builder's get method to construct the format instance,\n        // verify that an IllegalArgumentException is thrown, confirming that line break characters are rejected as delimiters.\n        assertThrows(IllegalArgumentException.class, () -> builder.setDelimiter(invalidDelimiter).get(),\n                     \"Delimiter should not allow line break characters like carriage return.\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 54432,
    "output_tokens": 1827,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 158,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure the builder to use a line feed character as the delimiter. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class CSVFormatDelimiterValidationTest {\n\n    @Test\n    void testInvalidDelimiterThrowsIllegalArgumentException() {\n        // Obtain a builder instance from the default CSV format\n        CSVFormat.Builder builder = CSVFormat.DEFAULT.builder();\n\n        // Configure the builder to use a line feed character as the delimiter\n        // Upon invoking the builder's build method to construct the format instance,\n        // verify that an IllegalArgumentException is thrown, confirming that the builder\n        // rejects line break characters as delimiters.\n        assertThrows(IllegalArgumentException.class, () -> builder.withDelimiter('\\n').build(),\n                \"Expected IllegalArgumentException when configuring a line feed as a delimiter\");\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5294,
    "output_tokens": 1115,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 162,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data format with a line feed character as the value separator by confirming the operation fails due to invalid configuration, starting from the standard comma-separated format configuration, then attempting to reconfigure it with a line feed character as the delimiter, and verifying the system raises an error indicating the configuration is not permitted since line breaks cannot serve as field separators, using JUnit 5 for test execution and standard assertion capabilities to confirm the expected failure occurs when finalizing the invalid configuration.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatLineFeedDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\n/**\n * Tests for {@link CSVFormat} to ensure that line feed characters cannot be used as delimiters.\n */\nclass CSVFormatLineFeedDelimiterTest {\n\n    /**\n     * Tests that attempting to configure a CSVFormat with a line feed character as the delimiter\n     * results in an IllegalArgumentException.\n     */\n    @Test\n    void testLineFeedAsDelimiterRejection() {\n        // Attempt to create a CSVFormat with a line feed as the delimiter\n        // and verify that an IllegalArgumentException is thrown.\n        final IllegalArgumentException thrown = assertThrows(IllegalArgumentException.class, () ->\n            CSVFormat.DEFAULT.builder().setDelimiter('\\n').get(),\n            \"Expected IllegalArgumentException when setting line feed as delimiter\"\n        );\n\n        // Verify the error message\n        // Note: The setDelimiter(char) method delegates to setDelimiter(String) which has the check.\n        // The error message from setDelimiter(String) is \"The delimiter cannot be a line break\".\n        // The setDelimiter(char) method does not have its own specific message for this case in the current snippet,\n        // but the underlying String-based method does. Given the requirement to be robust,\n        // we'll assert against the message from the String version, which is what would ultimately be thrown.\n        // Upon closer inspection of the setDelimiter(char) and setDelimiter(String) methods in the provided code:\n        // public Builder setDelimiter(final char delimiter) {\n        //     return setDelimiter(String.valueOf(delimiter));\n        // }\n        // The char version calls the String version. So the exception message comes from the String version.\n        // The message is \"The delimiter cannot be a line break\".\n        Assertions.assertEquals(\"The delimiter cannot be a line break\", thrown.getMessage(),\n            \"Expected specific error message for invalid delimiter\"\n        );\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 29559,
    "output_tokens": 1389,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 165,
      "description": "Create a test to validate that the system properly rejects an attempt to configure a format specification with a carriage return character as the delimiter, which is a business rule violation since line-breaking characters are not permitted as value separators to ensure proper record parsing. Begin by establishing a baseline format configuration using the standard default settings, then attempt to modify this configuration by specifying a carriage return character as the delimiter through the configuration builder, and verify that the system immediately prevents the finalization of this invalid configuration by raising a validation error indicating an illegal argument, thereby ensuring data integrity and preventing malformed output files. The test uses JUnit 5 as the testing framework and verifies the expected failure condition using standard exception assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatInvalidDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatInvalidDelimiterTest {\n\n    @Test\n    public void testWithCarriageReturnAsDelimiterRejects() {\n        final char invalidDelimiter = '\\r';\n        final String expectedErrorMessage = \"The delimiter cannot be a line break\";\n\n        IllegalArgumentException thrown = assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(invalidDelimiter).get();\n        }, \"Expected IllegalArgumentException to be thrown for invalid delimiter\");\n\n        // Verify the error message\n        assert(thrown.getMessage().contains(expectedErrorMessage));\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.75,
      "callable_precision": 0.4286,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 47648,
    "output_tokens": 901,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 166,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a carriage return character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument. Within the lambda, access the static field `DEFAULT` on `CSVFormat`, then chain a call to `builder()` which returns a `CSVFormat.Builder` instance. On this builder, chain `setDelimiter` passing the constant `Constants.CR` (representing the carriage return character `'\\r'`) as the argument, which returns the same builder instance. Finally, chain `get()` on the builder to construct the `CSVFormat` instance, which should trigger the exception due to the invalid delimiter. The test uses JUnit 5 Assertions via `assertThrows`, and the method-level annotation is `@Test` with no class-level annotations present.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatBuilderDelimiterTest {\n\n    @Test\n    public void testCarriageReturnDelimiterThrowsException() {\n        assertThrows(IllegalArgumentException.class, () ->\n            CSVFormat.DEFAULT.builder().setDelimiter(Constants.CR).get()\n        );\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5393,
    "output_tokens": 843,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 176,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a delimiter string containing a carriage return line break character, beginning by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument, where the lambda executes the following chain: invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `CSVFormat.Builder` instance, then chain `setDelimiter` on that builder passing the result of `String.valueOf(Constants.CR)` as the argument (where `Constants.CR` represents the carriage return character `'\\r'`), and finally chain `get()` on the builder to trigger the format construction and validation, with the entire lambda expression serving as the executable that `assertThrows` will invoke to confirm the exception is raised during the `get()` call when the delimiter validation detects the line break character. The test uses JUnit 5 Assertions with method-level annotation `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDelimiterValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatDelimiterValidationTest {\n\n    @Test\n    void testSetDelimiterWithCarriageReturnThrowsException() {\n        assertThrows(IllegalArgumentException.class, () ->\n            CSVFormat.DEFAULT.builder().setDelimiter(String.valueOf(Constants.CR)).get()\n        );\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "list_directory": 1,
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 42245,
    "output_tokens": 947,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 177,
      "description": "Create a test case to validate that the system can successfully parse structured data when configured with a specific processing format that uses the first character of a predefined input string as the field separator and enables whitespace trimming around values, ensuring the parser initializes correctly and releases all system resources properly afterward, verifying this scenario using JUnit 5 with standard try-with-resources pattern for automatic resource cleanup without requiring explicit assertions since the test confirms successful initialization and teardown through exception-free execution.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserCustomFormatTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport java.io.IOException;\n\n/**\n * Test case to validate that the system can successfully parse structured data when configured with a specific\n * processing format that uses the first character of a predefined input string as the field separator and enables\n * whitespace trimming around values.\n *\n * This test ensures the parser initializes correctly and releases all system resources properly afterward,\n * verifying this scenario using JUnit 5 with a standard try-with-resources pattern for automatic resource cleanup.\n * No explicit assertions are required, as the test confirms successful initialization and teardown\n * through exception-free execution.\n */\nclass CSVParserCustomFormatTest {\n\n    @Test\n    void testParserInitializationAndCleanupWithCustomFormat() throws IOException {\n        // Define a source string from which the custom delimiter will be taken.\n        // The first character of this string will be used as the field separator.\n        final String delimiterSourceString = \";\";\n        final char customDelimiter = delimiterSourceString.charAt(0);\n\n        // Sample CSV data string.\n        // It includes headers, multiple records, and values with leading/trailing whitespace\n        // to verify that trimming is applied correctly.\n        final String csvData =\n                \" header1 ; header2 ; header3 \\n\" +\n                \" value1  ;   value2;value3  \\n\" +\n                \"  a      ;b     ; c  \";\n\n        // Configure the CSVFormat:\n        // 1. Start with a basic builder configuration.\n        // 2. Set the custom delimiter obtained from the delimiterSourceString.\n        // 3. Enable ignoring surrounding spaces to ensure values are trimmed.\n        // 4. Set setHeader() to instruct the parser to read the first line as headers.\n        final CSVFormat format = CSVFormat.Builder.create()\n                .setDelimiter(customDelimiter)\n                .setIgnoreSurroundingSpaces(true)\n                .setHeader()\n                .build();\n\n        // Use a try-with-resources statement for CSVParser to guarantee that\n        // system resources are properly managed and released upon completion or error.\n        // The success criteria for this test is the absence of any exceptions during\n        // parser initialization and record iteration.\n        try (final CSVParser parser = CSVParser.parse(csvData, format)) {\n            // Iterate through all records provided in the csvData.\n            // This action will trigger the parsing logic.\n            // If any issues arise during parsing (e.g., malformed data based on the format,\n            // or resource handling problems), an IOException or a runtime exception\n            // will be thrown, causing the test to fail.\n            for (@SuppressWarnings(\"unused\") final CSVRecord record : parser) {\n                // No explicit assertions are placed here, adhering to the requirement\n                // that successful execution (i.e., no exceptions) is the validation.\n            }\n        }\n        // If the execution flow reaches this point, it implies that:\n        // - The CSVParser was successfully initialized with the custom format.\n        // - All records were processed without parsing errors.\n        // - The CSVParser (and underlying resources) were properly closed due to try-with-resources.\n        // Thus, the test passes without needing a dedicated assertion statement.\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6667,
      "callable_precision": 0.5714,
      "focal_recall": 0.6,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 0.625,
      "method_coverage": 0.8571,
      "line_coverage": 0.5788,
      "branch_coverage": 0.9545
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 3
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 101863,
    "output_tokens": 3777,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 181,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that executes the following sequence: access the static field `CSVFormat.DEFAULT`, invoke `builder()` on it to obtain a `CSVFormat.Builder` instance, chain `setDelimiter(Constants.LF)` on that builder (where `Constants.LF` is a character constant representing the line feed character `'\\n'`), and finally chain `get()` to trigger the builder's validation logic that should throw the exception due to the invalid delimiter. The test uses JUnit 5's `assertThrows` assertion method to verify that the exact exception type is thrown during the builder's `get()` invocation. Class-level annotations: none. Method-level annotations: `@Test`. Assertion library: JUnit 5 Assertions. Mocking library: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatBuilderTest {\n\n    @Test\n    void testSetDelimiterWithLFThrowsException() {\n        assertThrows(IllegalArgumentException.class, () ->\n            CSVFormat.DEFAULT.builder().setDelimiter(Constants.LF).get()\n        );\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5415,
    "output_tokens": 770,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 192,
      "description": "Define a test method that validates the CSV parsing functionality when configuring a format through the builder pattern without specifying a header. Begin by retrieving the first character from the input string to serve as the delimiter character. Construct a CSV format by obtaining a builder from the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character and enabling the ignore surrounding spaces option before finalizing the format instance. With the configured format established, instantiate a CSV parser by invoking the static parse method with the input string and the constructed format, utilizing a try-with-resources block to ensure proper resource cleanup. The parser instance is created but not actively used within the test scope, as the test's purpose is to verify that the format configuration and parser instantiation complete without throwing exceptions when no explicit header is defined. Upon exiting the try-with-resources block, the parser is automatically closed, releasing any associated resources. This test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\n\npublic class CSVParserBuilderTest {\n\n    @Test\n    void testRfc4180BuilderWithoutHeaderAndNoException() throws IOException {\n        // Define an input string where the first character will be used as the delimiter.\n        // For example, if the input is \",value1,value2\", the delimiter will be ','.\n        String input = \",header1,header2\\n,value1,value2\";\n\n        // Retrieve the first character from the input string to serve as the delimiter character.\n        char delimiter = input.charAt(0);\n\n        // Construct a CSV format by obtaining a builder from the RFC4180 predefined format.\n        CSVFormat.Builder builder = CSVFormat.RFC4180.builder();\n\n        // Configure it by setting the delimiter to the extracted character.\n        builder.setDelimiter(delimiter);\n\n        // Enable the ignore surrounding spaces option.\n        builder.setIgnoreSurroundingSpaces(true);\n\n        // Finalize the format instance.\n        CSVFormat format = builder.build();\n\n        // Instantiate a CSV parser by invoking the static parse method with the input string and the constructed format,\n        // utilizing a try-with-resources block to ensure proper resource cleanup.\n        // The test's purpose is to verify that the format configuration and parser instantiation\n        // complete without throwing exceptions when no explicit header is defined.\n        try (CSVParser parser = CSVParser.parse(input, format)) {\n            // The parser instance is created but not actively used within the test scope.\n            // If instantiation or execution within this block causes an exception, the test will fail.\n        }\n        // Upon exiting the try-with-resources block, the parser is automatically closed,\n        // releasing any associated resources.\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.8333,
      "callable_precision": 0.8333,
      "focal_recall": 0.8,
      "focal_precision": 0.8
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5389,
    "output_tokens": 2654,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 199,
      "description": "Define a test method that validates the parser's behavior when encountering a CSV input with a missing header name by configuring a CSV format builder starting from the RFC4180 preset, then extracting the first character from a predefined input string to set as the delimiter, followed by enabling first-record-as-header mode and activating surrounding space trimming to complete the format configuration. With the format constructed, wrap the input string in a string reader and attempt to instantiate a CSV parser using this reader and format within a try-with-resources block that immediately closes the parser without performing any operations. Assert that this instantiation attempt throws an IllegalArgumentException, confirming that the parser correctly rejects CSV data where header column names are missing or malformed when the format expects the first record to define headers. This test uses JUnit for the test framework and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMissingHeaderTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\nimport java.io.StringReader;\n\npublic class CSVParserMissingHeaderTest {\n\n    @Test\n    void testParserThrowsExceptionForMissingHeader() throws IOException {\n        // Predefined input string for delimiter\n        String delimiterSource = \",\";\n        \n        // Configure CSV format builder:\n        // - Start from RFC4180 preset\n        // - Set delimiter by extracting the first character from delimiterSource\n        // - Enable first-record-as-header mode\n        // - Activate surrounding space trimming\n        CSVFormat format = CSVFormat.RFC4180.builder()\n                .setDelimiter(delimiterSource.charAt(0))\n                .setFirstRecordAsHeader()\n                .setTrim(true)\n                .build();\n\n        // CSV input with a missing header name (the first column header is empty)\n        String csvInput = \",b,c\n1,2,3\";\n\n        // Assert that instantiating CSVParser with this format and input throws an IllegalArgumentException.\n        // The exception is expected during the header processing phase of the parser's construction.\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = new CSVParser(new StringReader(csvInput), format)) {\n                // The parser is immediately closed without performing any read operations.\n                // The exception should occur when the parser attempts to process headers.\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 13587,
    "output_tokens": 2866,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 200,
      "description": "Define a test class containing a private static final field `INPUT` of type `String`, then write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on the static field `CSVFormat.RFC4180`, which returns a `CSVFormat.Builder` instance, then immediately chain `setDelimiter(char)` passing the character obtained by calling `charAt(0)` on the `INPUT` field, chain `setIgnoreSurroundingSpaces(true)` to enable trimming behavior, and finally chain `get()` to build the format, assigning the resulting `CSVFormat` instance to a local variable named `format`. Next, open a try-with-resources block by invoking the static method `parse(String, CSVFormat)` on `CSVParser`, passing `INPUT` as the first argument and `format` as the second argument, assigning the returned `CSVParser` instance to a resource variable named `parser`, and leave the try block body empty to allow automatic resource closure without performing any parsing operations. The test uses class-level annotation `@Test`, method-level annotation `@Test`, assertion libraries none, and mocking libraries none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserBuilderFunctionalTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.Test;\nimport java.io.IOException;\n\npublic class CSVParserBuilderFunctionalTest {\n\n    private static final String INPUT = \",header1,header2\\n,value1, value2\";\n\n    @Test\n    public void testBuilderConfigurationAndParserCreation() throws IOException {\n        CSVFormat format = CSVFormat.RFC4180.builder()\n                .setDelimiter(INPUT.charAt(0))\n                .setIgnoreSurroundingSpaces(true)\n                .get();\n\n        try (CSVParser parser = CSVParser.parse(INPUT, format)) {\n            // Body intentionally left empty as per description to allow automatic resource closure\n        }\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 201,
      "description": "Create a test case to validate that the system correctly enforces the requirement for complete header information when processing structured data files where the first line serves as column definitions and surrounding whitespace should be trimmed from values. Configure the processing rules to expect the first record as the header definition while ignoring any extra spaces around field values, using a specific delimiter character extracted from a predefined input sample. Attempt to initialize the data processing mechanism with these configured rules applied to the sample input, ensuring the system properly detects when header column names are missing or incomplete. Verify that the system rejects such malformed input by raising an appropriate validation failure, confirming that incomplete header definitions are not silently accepted during initialization. Once the validation behavior is confirmed, release any resources allocated during the processing attempt. The test employs JUnit 5 as the testing framework and uses standard exception assertion capabilities to verify the system throws the expected validation error when encountering missing column names in the header record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatHeaderValidationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.Test;\n\nclass CSVFormatHeaderValidationTest {\n\n    private StringReader reader;\n    private CSVParser parser;\n\n    @Test\n    void testIncompleteHeaderRejection() {\n        // Sample input with malformed header: empty column names after trimming that result in duplicates.\n        // For example, \",,\" will be parsed as [\"\", \"\", \"\"] after trimming and using ',' as delimiter.\n        // With DuplicateHeaderMode.FAIL, this should trigger an IllegalArgumentException.\n        final String malformedInput = \",,\";\n\n        // Configure CSVFormat to:\n        // 1. Use the first record as the header definition.\n        // 2. Trim surrounding whitespace from field values.\n        // 3. Use a comma as the delimiter.\n        // 4. Set DuplicateHeaderMode to FAIL, ensuring that duplicate header names (including empty strings after trimming)\n        //    are detected and rejected during initialization.\n        final CSVFormat format = CSVFormat.DEFAULT\n            .withFirstRecordAsHeader()\n            .withTrim()\n            .withDelimiter(',')\n            .withDuplicateHeaderMode(DuplicateHeaderMode.FAIL);\n\n        // Attempt to initialize CSVParser with the malformed input and configured format.\n        // Expect an IllegalArgumentException to be thrown due to duplicate empty header names.\n        final IllegalArgumentException thrown = assertThrows(IllegalArgumentException.class, () -> {\n            reader = new StringReader(malformedInput);\n            parser = new CSVParser(reader, format);\n        }, \"Expected IllegalArgumentException for incomplete/duplicate header names during initialization.\");\n\n        // Verify that the exception message indicates a duplicate header entry.\n        assertNotNull(thrown.getMessage(), \"Exception message should not be null.\");\n        assertTrue(thrown.getMessage().contains(\"The header contains a duplicate entry: ''\"),\n            \"Exception message should mention duplicate empty header entry.\");\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        // Release resources allocated during the test.\n        if (parser != null) {\n            parser.close();\n        }\n        if (reader != null) {\n            reader.close();\n        }\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5382,
    "output_tokens": 6014,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 211,
      "description": "Define a test method that declares a `private static final String` field named `INPUT` at the class level, then within the method body, begin by invoking `CSVFormat.RFC4180.withDelimiter(INPUT.charAt(0))` to obtain a `CSVFormat` instance, chain `.withFirstRecordAsHeader()` on the result, chain `.withIgnoreSurroundingSpaces()` on that result, and assign the final `CSVFormat` to a local variable named `format`. Next, invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that constructs a new `CSVParser` by passing `new StringReader(INPUT)` as the first argument and `format` as the second argument, assigning the parser to a variable named `parser`, with an empty body inside the try block. The test method is annotated with `@Test` and declares `throws IOException`. The test uses JUnit 5 Assertions for the `assertThrows` call.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatIllegalArgumentTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\nimport java.io.StringReader;\n\npublic class CSVFormatIllegalArgumentTest {\n\n    private static final String INPUT = \"\\nheader1,header2\\nvalue1,value2\";\n\n    @Test\n    public void testWithDelimiterFirstCharOfInputThrowsIllegalArgumentException() throws IOException {\n        // Obtain CSVFormat instance by invoking withDelimiter with the first character of INPUT,\n        // chaining withFirstRecordAsHeader and withIgnoreSurroundingSpaces.\n        CSVFormat format = CSVFormat.RFC4180\n                .withDelimiter(INPUT.charAt(0))\n                .withFirstRecordAsHeader()\n                .withIgnoreSurroundingSpaces();\n\n        // Assert that IllegalArgumentException is thrown when constructing CSVParser\n        assertThrows(IllegalArgumentException.class, () -> {\n            // Try-with-resources statement for CSVParser construction with an empty body\n            try (CSVParser parser = new CSVParser(new StringReader(INPUT), format)) {\n                // Empty body as required by the description\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.1111,
      "method_coverage": 0.0484,
      "line_coverage": 0.0788,
      "branch_coverage": 0.0492
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 228,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates how the CSV Parser enforces this constraint when streaming records. Create a Reader from a CSV string containing three rows with comma-separated values (each row having three columns). Build a CSV Format instance by starting with the default format, invoking the builder to configure the maximum row limit using the provided parameter, and finalizing the format configuration. Parse the CSV input using the configured format within a try-with-resources block to ensure automatic parser closure. Stream the records from the parser, collect them into a list, and immediately assert that the list is not empty. Retrieve the first record from the list and validate its column values match the first row of the input data. If the maximum row parameter is less than or equal to zero or greater than one, retrieve the second record and validate its values against the second row. If the maximum row parameter is less than or equal to zero or greater than two, retrieve the third record and validate its values against the third row. Create a private helper method that compares a string array against the values of a CSV Record to support these validations. Upon exiting the try-with-resources block, the parser is automatically closed. Execute this test across multiple parameterized inputs including negative values, zero, small positive integers, and the maximum long value using JUnit 5's parameterized test support.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRecordLengthTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\npublic class CSVParserMaxRecordLengthTest {\n\n    private static final String CSV_INPUT = \"A,B,C\\nD,E,F\\nG,H,I\";\n    private static final String[] ROW_1 = {\"A\", \"B\", \"C\"};\n    private static final String[] ROW_2 = {\"D\", \"E\", \"F\"};\n    private static final String[] ROW_3 = {\"G\", \"H\", \"I\"};\n\n    @ParameterizedTest\n    @ValueSource(longs = {-1L, 0L, 1L, 2L, 3L, Long.MAX_VALUE})\n    void testMaxRecordLengthEnforcement(final long maxRecordLength) throws IOException {\n        final Reader reader = new StringReader(CSV_INPUT);\n\n        final CSVFormat format = CSVFormat.DEFAULT.builder()\n                .withMaxRecordLength(maxRecordLength)\n                .build();\n\n        try (final CSVParser parser = new CSVParser(reader, format)) {\n            final List<CSVRecord> records = parser.stream().collect(Collectors.toList());\n\n            assertNotNull(records);\n            assertFalse(records.isEmpty(), \"Records list should not be empty\");\n\n            // Validate first record\n            assertTrue(records.size() >= 1, \"Expected at least one record\");\n            assertRecordValues(ROW_1, records.get(0));\n\n            // Conditionally validate second record\n            if (maxRecordLength <= 0 || maxRecordLength > 1) {\n                assertTrue(records.size() >= 2, \"Expected at least two records for maxRecordLength \" + maxRecordLength);\n                assertRecordValues(ROW_2, records.get(1));\n            } else {\n                assertEquals(1, records.size(), \"Expected only one record for maxRecordLength \" + maxRecordLength);\n            }\n\n            // Conditionally validate third record\n            if (maxRecordLength <= 0 || maxRecordLength > 2) {\n                assertTrue(records.size() >= 3, \"Expected at least three records for maxRecordLength \" + maxRecordLength);\n                assertRecordValues(ROW_3, records.get(2));\n            } else if (maxRecordLength > 0 && maxRecordLength <= 2) {\n                assertEquals(maxRecordLength, records.size(), \"Expected \" + maxRecordLength + \" records for maxRecordLength \" + maxRecordLength);\n            }\n        }\n    }\n\n    private void assertRecordValues(final String[] expected, final CSVRecord record) {\n        assertNotNull(record, \"CSVRecord should not be null\");\n        assertEquals(expected.length, record.size(), \"Record size mismatch\");\n        for (int i = 0; i < expected.length; i++) {\n            assertEquals(expected[i], record.get(i), \"Value mismatch at index \" + i);\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5479,
    "output_tokens": 2570,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 230,
      "description": "Define a test method that validates the CSV Format Builder's behavior when constructing a format configuration with an empty header array followed by parsing malformed CSV input. Begin by retrieving the first character from a static input string to use as the delimiter character. Build a CSV format by invoking the builder method on the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character, enabling automatic header detection with an empty header array, instructing the parser to skip the header record, and enabling the trimming of surrounding spaces before finalizing the format instance. With the configured format in hand, verify that attempting to parse the input string using the CSV Parser triggers a validation error due to missing header names by asserting that an IllegalArgumentException is thrown when the parser is instantiated within a try-with-resources block that immediately closes upon construction. This test uses JUnit 5 for the test framework and its assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderMalformedHeaderTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\npublic class CSVFormatBuilderMalformedHeaderTest {\n\n    @Test\n    void testMalformedHeaderDetectionThrowsIllegalArgumentException() {\n        // Define a static input string that represents malformed CSV input.\n        // The first record has an empty column, followed by a valid column, making automatic header detection\n        // with an empty header array problematic when combined with skipping the header record.\n        // This specific malformed input aims to trigger the validation error during parser instantiation.\n        final String malformedCsvInput = \",\\nval1,val2\";\n\n        // Retrieve the first character from the input string to use as the delimiter.\n        // This will be the comma character in this case.\n        final char delimiter = malformedCsvInput.charAt(0);\n\n        // Build a CSV format configuration:\n        // 1. Start with the RFC4180 predefined format.\n        // 2. Set the delimiter to the extracted character.\n        // 3. Enable automatic header detection (`withHeader()`).\n        // 4. Critically, we interpret \"with an empty header array\" in the prompt\n        //    to mean that `withHeader(new String[0])` is explicitly called.\n        //    This tells the format that no header names are defined.\n        //    The combination of `withHeader()` followed by `withHeader(new String[0])`\n        //    sets the explicit header names to an empty array.\n        // 5. Instruct the parser to skip the header record (`withSkipHeaderRecord(true)`).\n        // 6. Enable trimming of surrounding spaces (`withTrim()`).\n        final CSVFormat format = CSVFormat.RFC4180.builder()\n            .withDelimiter(delimiter)\n            .withHeader() // Enable automatic header detection\n            .withHeader(new String[0]) // Explicitly set header to an empty array after auto-detection is enabled\n            .withSkipHeaderRecord(true) // Instruct to skip the header record\n            .withTrim() // Enable trimming of spaces\n            .build();\n\n        // Verify that attempting to parse the input string using the CSV Parser\n        // triggers a validation error due to missing header names.\n        // This is asserted by checking that an IllegalArgumentException is thrown\n        // when the parser is instantiated within a try-with-resources block that\n        // immediately closes upon construction.\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (final CSVParser parser = CSVParser.parse(malformedCsvInput, format)) {\n                // The exception is expected during the construction of CSVParser.\n                // If it reaches here, the test would fail, but it should not.\n            }\n        }, \"Parsing with an empty header array and skipped record should throw IllegalArgumentException.\");\n    }\n}",
      "method_signature": "testHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5383,
    "output_tokens": 8849,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 236,
      "description": "Create a test case to validate that the system correctly processes structured data from a text source while respecting a configurable limit on the number of rows to retrieve, ensuring the system behaves consistently across various limit configurations including unlimited processing, single-row retrieval, and specific row counts up to the maximum supported boundary. Prepare a text source containing three rows of comma-separated values with three columns each, representing a simple tabular dataset. Configure the data processing system to use standard comma-separated formatting, then apply a specified maximum row limit ranging from negative values and zero (representing no limit) through small positive integers to the largest possible numeric value. Initiate the data retrieval process by streaming the records from the configured source and collecting them into a list for validation. Verify that the system returned at least one row, then confirm the first row contains the expected values from the initial line of input. When the configured limit allows processing beyond the first row (either no limit or a limit greater than one), validate that the second row is present and contains the expected values from the second line of input. Similarly, when the limit permits processing all three rows (either no limit or a limit greater than two), ensure the third row is present and contains the expected values from the final line of input. Release the data processing resources after each validation cycle. Validate the behavior using JUnit 5 with parameterized test support to execute the scenario across multiple row limit values, employing AssertJ for verifying the presence of records and confirming the expected data values match the parsed output.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CsvParserRecordLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\npublic class CsvParserRecordLimitTest {\n\n    @ParameterizedTest\n    @ValueSource(ints = {Integer.MIN_VALUE, -1, 0, 1, 2, 3, 4, Integer.MAX_VALUE})\n    void testRecordLimit(final int limit) throws IOException {\n        final String csvData = \"H1,H2,H3\\n\" +\n                               \"R1C1,R1C2,R1C3\\n\" +\n                               \"R2C1,R2C2,R2C3\\n\" +\n                               \"R3C1,R3C2,R3C3\";\n        final CSVFormat format = CSVFormat.DEFAULT.builder()\n                .setFirstRecordAsHeader()\n                .build();\n\n        try (final CSVParser parser = CSVParser.parse(csvData, format)) {\n            final List<CSVRecord> records;\n            if (limit <= 0) { // Interpret negative values and zero as no limit (read all)\n                records = parser.stream().collect(Collectors.toList());\n            } else { // Positive limit\n                records = parser.stream().limit(limit).collect(Collectors.toList());\n            }\n\n            final int expectedTotalRecordsInSource = 3; // Total data rows in csvData after header\n            final int expectedRecordCount = (limit <= 0) ? expectedTotalRecordsInSource : Math.min(limit, expectedTotalRecordsInSource);\n            assertThat(records).as(\"Total records count for limit \" + limit).hasSize(expectedRecordCount);\n\n            if (expectedRecordCount >= 1) {\n                final CSVRecord firstRecord = records.get(0);\n                assertThat(firstRecord.get(\"H1\")).as(\"First record H1\").isEqualTo(\"R1C1\");\n                assertThat(firstRecord.get(\"H2\")).as(\"First record H2\").isEqualTo(\"R1C2\");\n                assertThat(firstRecord.get(\"H3\")).as(\"First record H3\").isEqualTo(\"R1C3\");\n            }\n\n            if (expectedRecordCount >= 2) {\n                final CSVRecord secondRecord = records.get(1);\n                assertThat(secondRecord.get(\"H1\")).as(\"Second record H1\").isEqualTo(\"R2C1\");\n                assertThat(secondRecord.get(\"H2\")).as(\"Second record H2\").isEqualTo(\"R2C2\");\n                assertThat(secondRecord.get(\"H3\")).as(\"Second record H3\").isEqualTo(\"R2C3\");\n            }\n\n            if (expectedRecordCount >= 3) {\n                final CSVRecord thirdRecord = records.get(2);\n                assertThat(thirdRecord.get(\"H1\")).as(\"Third record H1\").isEqualTo(\"R3C1\");\n                assertThat(thirdRecord.get(\"H2\")).as(\"Third record H2\").isEqualTo(\"R3C2\");\n                assertThat(thirdRecord.get(\"H3\")).as(\"Third record H3\").isEqualTo(\"R3C3\");\n            }\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 240,
      "description": "Create a test case to validate that the system properly rejects malformed data when attempting to parse information with an improperly configured structure where column headers are expected but not provided, ensuring the system enforces data integrity rules by confirming that when a parser is set up to automatically detect column headers from the first row while simultaneously being instructed to skip that header row and to remove extra spaces around values, and this parser is then given input data to process, the system immediately detects the missing header information and refuses to proceed with the operation by signaling a validation failure, thus preventing the creation of corrupted or inconsistent data records. Configure the parsing behavior to use the first character from the test input as the value separator, enable automatic header detection without explicitly naming the columns, activate the setting to bypass the header row during processing, and apply trimming of surrounding whitespace, then attempt to initiate the parsing operation with the provided input data and verify that the system blocks this action by raising an appropriate validation error indicating that required header information is absent. Verify the expected system behavior using JUnit 5 for test execution and standard equality assertions to confirm the validation failure occurs as intended.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.issues.CSV240Test",
      "code": "package org.apache.commons.csv.issues;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Test case for validating that the system properly rejects malformed data when attempting to parse information\n * with an improperly configured structure where column headers are expected but not provided.\n */\nclass CSV240Test {\n\n    /**\n     * Tests that parsing fails with an IllegalArgumentException when a header is expected but a column name is missing.\n     * The parser is configured to use the first record as header, skip it, and trim values.\n     */\n    @Test\n    void testMalformedHeaderSkippingThrowsException() {\n        // Input data: The first line (intended as header) has a missing column name,\n        // followed by data that would normally be parsed.\n        // The first character (',') from the test input will be used as the value separator.\n        final String csvData = \",B,C\\nX,Y,Z\"; // First column header is empty\n\n        // Configure the CSV format:\n        // - Use ',' as the delimiter.\n        // - Expect the first record to be headers (withFirstRecordAsHeader).\n        // - Skip the header record (withSkipHeaderRecord).\n        // - Trim whitespace around values (withTrim).\n        final CSVFormat format = CSVFormat.Builder.create()\n            .setDelimiter(',')\n            .setFirstRecordAsHeader()\n            .setSkipHeaderRecord(true)\n            .setTrim(true)\n            .build();\n\n        // Attempt to parse the malformed data and assert that an IllegalArgumentException is thrown.\n        // The exception is expected because a header name is missing (the first column is empty)\n        // and allowMissingColumnNames is false by default.\n        assertThrows(IllegalArgumentException.class, () -> {\n            try (final CSVParser parser = new CSVParser(new StringReader(csvData), format)) {\n                // The exception should occur during parser initialization, so no need to iterate.\n                // If it doesn't throw during initialization, it means the validation failed.\n            }\n        }, \"Parsing should throw IllegalArgumentException for missing header name when headers are expected.\");\n    }\n}",
      "method_signature": "testHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5419,
    "output_tokens": 4325,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 241,
      "description": "Define a test class containing a private static final String field named `INPUT` and write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on `CSVFormat.RFC4180`, then chain `setDelimiter(INPUT.charAt(0))` (passing the character at index `0` of the `INPUT` string), chain `setHeader()` with no arguments, chain `setSkipHeaderRecord(true)`, chain `setIgnoreSurroundingSpaces(true)`, and finally chain `get()` to obtain a `CSVFormat` instance, assigning the result to a local variable named `format`. Immediately invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that invokes `CSVParser.parse(INPUT, format)` (passing the `INPUT` string literal and the `format` variable), assigns the result to a variable named `parser` of type `CSVParser`, and leaves the try block body empty (no operations performed with `parser`), thereby verifying that parsing the input with the configured format throws an `IllegalArgumentException` due to a missing header name. The test uses JUnit 5 Assertions via the `assertThrows` method and is annotated with `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatSetHeaderMissingHeaderTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.IOException;\nimport java.io.StringReader;\n\npublic class CSVFormatSetHeaderMissingHeaderTest {\n\n    private static final String INPUT = \",\"; // Provides a delimiter at charAt(0) and minimal content for parsing.\n\n    @Test\n    void testSetHeaderMissingHeaderNameThrowsException() throws IOException {\n        // Build the CSVFormat instance with contradictory header-handling settings\n        CSVFormat format = CSVFormat.RFC4180.builder()\n                .setDelimiter(INPUT.charAt(0)) // Set delimiter from the first char of INPUT\n                .setHeader() // Instruct to infer headers from the first record\n                .setSkipHeaderRecord(true) // Instruct to skip the first record\n                .setIgnoreSurroundingSpaces(true)\n                .get();\n\n        // Assert that parsing with this format and input throws IllegalArgumentException\n        // due to the conflict between inferring headers and skipping the header record.\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = CSVParser.parse(new StringReader(INPUT), format)) {\n                // No further operations with the parser are needed,\n                // the exception should occur during its construction or initial parsing.\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.9,
      "focal_recall": 0.8571,
      "focal_precision": 0.8571
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9818,
      "line_coverage": 0.9959,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5463,
    "output_tokens": 5549,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 246,
      "description": "Define a parameterized test method accepting a `long` parameter named `maxRows` annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that declares it may throw `Exception`. Begin by creating a `Reader` instance named `in` by instantiating a `StringReader` with the exact String literal `\"a,b,c\\n1,2,3\\nx,y,z\"`. Open a try-with-resources block declaring a `CSVParser` variable named `parser` initialized by invoking `CSVFormat.DEFAULT.builder()`, chaining `.setMaxRows(maxRows)`, chaining `.get()`, and finally invoking `.parse(in)` with the reader. Within the try block, declare a `List<CSVRecord>` variable named `list` and assign it the result of invoking `parser.stream()` followed by `.collect(Collectors.toList())`. Immediately assert that `list` is not empty by invoking `assertFalse(list.isEmpty())`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then verifies that the record's values match the array elements in order; invoke this method with a new `String[]` array containing `\"a\"`, `\"b\"`, `\"c\"` and `list.get(0)` as arguments. Next, check if `maxRows <= 0 || maxRows > 1` evaluates to true; if so, invoke the same verification method with a new `String[]` array containing `\"1\"`, `\"2\"`, `\"3\"` and `list.get(1)`. Then check if `maxRows <= 0 || maxRows > 2` evaluates to true; if so, invoke the verification method again with a new `String[]` array containing `\"x\"`, `\"y\"`, `\"z\"` and `list.get(2)`. The try-with-resources block automatically closes the parser upon exit. The test uses JUnit 5 Assertions (`assertFalse`) and the `@ParameterizedTest` annotation with `@ValueSource` to supply test parameters.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRowsTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\npublic class CSVParserMaxRowsTest {\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    void testMaxRows(long maxRows) throws Exception {\n        Reader in = new StringReader(\"a,b,c\\n1,2,3\\nx,y,z\");\n        try (CSVParser parser = CSVFormat.DEFAULT.builder().setMaxRows(maxRows).get().parse(in)) {\n            List<CSVRecord> list = parser.stream().collect(Collectors.toList());\n            assertFalse(list.isEmpty());\n\n            assertRecordValues(new String[]{\"a\", \"b\", \"c\"}, list.get(0));\n\n            if (maxRows <= 0 || maxRows > 1) {\n                assertRecordValues(new String[]{\"1\", \"2\", \"3\"}, list.get(1));\n            }\n            if (maxRows <= 0 || maxRows > 2) {\n                assertRecordValues(new String[]{\"x\", \"y\", \"z\"}, list.get(2));\n            }\n        }\n    }\n\n    private void assertRecordValues(String[] expected, CSVRecord record) {\n        assertEquals(expected.length, record.size(), \"Record size mismatch\");\n        Iterator<String> recordIterator = record.iterator();\n        for (int i = 0; i < expected.length; i++) {\n            assertEquals(expected[i], recordIterator.next(), \"Value mismatch at index \" + i);\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.1429,
      "callable_recall": 0.75,
      "callable_precision": 0.3871,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9831,
      "line_coverage": 0.9962,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5655,
    "output_tokens": 2993,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 256,
      "description": "Create a validation scenario to ensure the system correctly handles requests to process a specific maximum number of records from structured data input, testing the system's ability to respect configurable row limits across various threshold values including edge cases such as unlimited processing, single-record processing, and processing beyond the available data set. Begin by preparing a predefined set of structured records representing typical business data entries. For each tested row limit value (ranging from values indicating no limit, to processing one record, several records, or the maximum possible number), configure the data processing system to ignore surrounding whitespace and apply the specified row limit, then initiate processing of the structured input. After processing completes, verify that the system produced exactly the expected number of records based on the configured limit, ensuring that when the limit is set to zero or a negative value the system processes all available records, when the limit exceeds the available data the system processes only the existing records, and when a specific positive limit is provided the system processes exactly that many records without exceeding the threshold. For each processed record, confirm that the system correctly extracted and preserved the business values from the corresponding input row, ensuring data integrity across all scenarios. Once validation is complete, release the processing resources to maintain system efficiency. Validate the outcomes using JUnit 5 as the testing framework with AssertJ for fluent equality assertions to confirm record counts and data accuracy.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserRowLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class CSVParserRowLimitTest {\n\n    @Test\n    void testRowLimitHandling() throws IOException {\n        // Prepare predefined structured records with surrounding whitespace\n        final String csvData =\n                \"   A , B , C  \\n\" +\n                \" 1 , 2 , 3    \\n\" +\n                \"   4 , 5 ,  6 \\n\" +\n                \"  7  , 8 , 9  \"; // Total of 4 records\n\n        // Configure CSVFormat to ignore surrounding whitespace\n        final CSVFormat format = CSVFormat.DEFAULT\n                .withDelimiter(',')\n                .withIgnoreSurroundingSpaces(true);\n\n        // Define expected values after parsing and whitespace trimming\n        final List<List<String>> expectedFullRecords = Arrays.asList(\n            Arrays.asList(\"A\", \"B\", \"C\"),\n            Arrays.asList(\"1\", \"2\", \"3\"),\n            Arrays.asList(\"4\", \"5\", \"6\"),\n            Arrays.asList(\"7\", \"8\", \"9\")\n        );\n\n        // Scenario 1: Limit -1 (should process all available records)\n        testLimitScenario(csvData, format, -1, 4, expectedFullRecords);\n\n        // Scenario 2: Limit 0 (should process all available records as per description)\n        testLimitScenario(csvData, format, 0, 4, expectedFullRecords);\n\n        // Scenario 3: Limit 1 (single-record processing)\n        testLimitScenario(csvData, format, 1, 1, expectedFullRecords);\n\n        // Scenario 4: Limit 2 (processing several records)\n        testLimitScenario(csvData, format, 2, 2, expectedFullRecords);\n\n        // Scenario 5: Limit 5 (processing beyond the available data set, should process only existing records)\n        testLimitScenario(csvData, format, 5, 4, expectedFullRecords);\n    }\n\n    /**\n     * Helper method to test a specific row limit scenario.\n     * It configures the parser with the given format, iterates up to the specified limit,\n     * and then verifies the count and content of the processed records.\n     *\n     * @param csvData The CSV input string.\n     * @param format The CSVFormat to use for parsing.\n     * @param limit The maximum number of records to process. If <= 0, all available records are processed.\n     * @param expectedCount The expected number of records after applying the limit.\n     * @param fullExpectedValues The complete list of expected record values for data integrity checks.\n     * @throws IOException If an I/O error occurs during parsing.\n     */\n    private void testLimitScenario(\n            final String csvData,\n            final CSVFormat format,\n            final int limit,\n            final int expectedCount,\n            final List<List<String>> fullExpectedValues) throws IOException {\n\n        try (final CSVParser parser = new CSVParser(new StringReader(csvData), format)) {\n            final List<CSVRecord> processedRecords = new ArrayList<>();\n            int recordsCollected = 0;\n\n            // Process records based on the configured limit\n            for (final CSVRecord record : parser) {\n                // If limit is positive and has been reached, stop processing.\n                // Otherwise, continue collecting records.\n                if (limit > 0 && recordsCollected >= limit) {\n                    break;\n                }\n                processedRecords.add(record);\n                recordsCollected++;\n            }\n\n            // Verify that the system produced exactly the expected number of records\n            assertThat(processedRecords)\n                .as(\"Number of records processed for limit %d\", limit)\n                .hasSize(expectedCount);\n\n            // For each processed record, confirm data integrity and correct value extraction\n            for (int i = 0; i < processedRecords.size(); i++) {\n                final CSVRecord actualRecord = processedRecords.get(i);\n                final List<String> expectedRecordValues = fullExpectedValues.get(i);\n\n                assertThat(actualRecord.size())\n                    .as(\"Column count for record %d (limit %d)\", i, limit)\n                    .isEqualTo(expectedRecordValues.size());\n\n                for (int j = 0; j < actualRecord.size(); j++) {\n                    assertThat(actualRecord.get(j))\n                        .as(\"Record %d, Column %d value for limit %d\", i, j, limit)\n                        .isEqualTo(expectedRecordValues.get(j));\n                }\n            }\n        }\n        // Resources are implicitly released by the try-with-resources statement\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5473,
    "output_tokens": 6770,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 265,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates the CSV Parser's row-limiting behavior across boundary conditions including negative values, zero, positive integers, and maximum long values. Configure a CSV Format Builder starting from the DEFAULT format, chaining calls to enable surrounding space trimming and to set the maximum row limit using the provided parameter value, then build the format instance. Instantiate a CSV Parser by invoking the static parse method with a predefined CSV input string and the configured format, ensuring the parser is managed within a try-with-resources block for automatic closure. Upon parser creation, invoke the getRecords method to retrieve all parsed records as a list. Calculate the expected record count by comparing the maximum row parameter against the length of a predefined result array, where non-positive values or values exceeding the array length should yield the full array length, otherwise the limit itself. Assert that the retrieved records list size matches the calculated expected length, then verify the list is not empty. Iterate through the expected number of records, and for each iteration index, invoke a helper method that validates the values of the record at that index against the corresponding row in the result array, ensuring field-level correctness across all processed records. The parser resource is automatically closed upon exiting the try-with-resources block. This test uses JUnit 5 for parameterized testing.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRowLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport java.util.List;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\npublic class CSVParserMaxRowLimitTest {\n\n    // Predefined CSV input string with various data for comprehensive testing.\n    private static final String CSV_INPUT =\n            \"A,B,C,D\\n\" +\n            \"a,b,c,d\\n\" +\n            \" e , f ,  g, h \\n\" +\n            \" i ,  \\\" j \\\" ,  \\\" k \\\",  l \\n\" +\n            \",,,\\n\" +\n            \",,,\\n\";\n\n    // Expected records after parsing and trimming, matching the CSV_INPUT.\n    private static final String[][] EXPECTED_RECORDS = {\n            {\"A\", \"B\", \"C\", \"D\"},\n            {\"a\", \"b\", \"c\", \"d\"},\n            {\"e\", \"f\", \"g\", \"h\"},\n            {\"i\", \" j \", \" k \", \" l\"},\n            {\"\", \"\", \"\", \"\"},\n            {\"\", \"\", \"\", \"\"}\n    };\n\n    /**\n     * Defines a test method that accepts a long parameter representing the maximum row limit\n     * and validates the CSV Parser's row-limiting behavior across various boundary conditions.\n     *\n     * @param maxRowLimit The maximum number of rows the parser should process.\n     * @throws IOException if an I/O error occurs during parsing.\n     */\n    @ParameterizedTest\n    @ValueSource(longs = {\n            -5,             // Negative value: should not limit\n            -1,             // Negative value: should not limit\n            0,              // Zero: should not limit\n            1,              // Positive integer: should limit to 1 record\n            2,              // Positive integer: should limit to 2 records\n            3,              // Positive integer: should limit to 3 records\n            5,              // Positive integer: should limit to 5 records\n            6,              // Positive integer: should limit to all 6 records\n            7,              // Positive integer: greater than total, should limit to all 6 records\n            Long.MAX_VALUE  // Maximum long value: should not limit\n    })\n    void testCSVParserWithMaxRowLimit(long maxRowLimit) throws IOException {\n        // Configure a CSV Format Builder starting from the DEFAULT format,\n        // chaining calls to enable surrounding space trimming and to set the maximum row limit.\n        CSVFormat format = CSVFormat.DEFAULT.builder()\n                .setTrim(true) // Enable surrounding space trimming as per description\n                .setMaxRows(maxRowLimit)\n                .get(); // Build the format instance\n\n        // Calculate the expected record count based on the maximum row parameter.\n        // Non-positive values or values exceeding the total records should yield the full array length,\n        // otherwise, the limit itself.\n        final int totalExpectedRecords = EXPECTED_RECORDS.length;\n        int expectedRecordCount;\n        if (maxRowLimit <= 0 || maxRowLimit >= totalExpectedRecords) {\n            expectedRecordCount = totalExpectedRecords;\n        } else {\n            expectedRecordCount = (int) maxRowLimit;\n        }\n\n        // Instantiate a CSV Parser by invoking the static parse method with a predefined CSV input string\n        // and the configured format, ensuring the parser is managed within a try-with-resources block.\n        try (CSVParser parser = CSVParser.parse(new StringReader(CSV_INPUT), format)) {\n            // Upon parser creation, invoke the getRecords method to retrieve all parsed records as a list.\n            List<CSVRecord> records = parser.getRecords();\n\n            // Assert that the retrieved records list size matches the calculated expected length.\n            assertEquals(expectedRecordCount, records.size(),\n                    \"Expected record count for limit \" + maxRowLimit + \" should match.\");\n            \n            // Verify the list is not empty (unless expected count is 0, which is not the case for this test's data).\n            // For the given CSV_INPUT, expectedRecordCount will always be > 0.\n            assertFalse(records.isEmpty(), \"Records list should not be empty when records are expected.\");\n\n            // Iterate through the expected number of records and validate their content.\n            for (int i = 0; i < expectedRecordCount; i++) {\n                assertRecordEquals(EXPECTED_RECORDS[i], records.get(i), i, maxRowLimit);\n            }\n        }\n    }\n\n    /**\n     * Helper method to validate the content of a single CSVRecord against an expected String array.\n     *\n     * @param expected The expected array of strings for the record.\n     * @param actual The actual CSVRecord parsed.\n     * @param recordIndex The index of the current record being validated (for better error messages).\n     * @param maxRowLimit The maxRowLimit used for the test (for better error messages).\n     */\n    private void assertRecordEquals(String[] expected, CSVRecord actual, int recordIndex, long maxRowLimit) {\n        assertEquals(expected.length, actual.size(),\n                String.format(\"Record %d (limit %d): Expected %d fields, but got %d.\",\n                        recordIndex, maxRowLimit, expected.length, actual.size()));\n        for (int i = 0; i < expected.length; i++) {\n            assertEquals(expected[i], actual.get(i),\n                    String.format(\"Record %d, Field %d (limit %d): Mismatch in field value.\",\n                            recordIndex, i, maxRowLimit));\n        }\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.8333,
      "callable_precision": 0.5,
      "focal_recall": 0.6667,
      "focal_precision": 0.6667
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8824,
      "line_coverage": 0.8539,
      "branch_coverage": 0.8767
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 3
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 87596,
    "output_tokens": 4528,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 27,
      "description": "Create a test case to validate the system's ability to export record data in CSV format when the data source provides values through a sequential processing stream rather than a pre-loaded collection, ensuring the output writer correctly handles streaming inputs and produces properly formatted comma-separated records with the expected line termination, then verify the generated output matches the standard CSV structure by examining the resulting text representation against established formatting rules using standard equality assertions with JUnit 5 and AssertJ.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamingTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.Arrays;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\npublic class CSVPrinterStreamingTest {\n\n    @Test\n    void testStreamingExportOfRecords() throws IOException {\n        // Data source simulating a sequential processing stream of records\n        final Iterable<List<String>> streamingDataSource = () -> new Iterator<List<String>>() {\n            private int index = 0;\n            private final List<List<String>> records = Arrays.asList(\n                Arrays.asList(\"Header1\", \"Header2\", \"Header3\"),\n                Arrays.asList(\"ValueA1\", \"ValueB1\", \"ValueC1\"),\n                Arrays.asList(\"ValueA2\", \"ValueB2\", \"ValueC2\")\n            );\n\n            @Override\n            public boolean hasNext() {\n                return index < records.size();\n            }\n\n            @Override\n            public List<String> next() {\n                if (!hasNext()) {\n                    throw new java.util.NoSuchElementException();\n                }\n                return records.get(index++);\n            }\n        };\n\n        final StringWriter stringWriter = new StringWriter();\n        try (final CSVPrinter csvPrinter = new CSVPrinter(stringWriter, CSVFormat.DEFAULT)) {\n            csvPrinter.printRecords(streamingDataSource);\n        }\n\n        final String expectedOutput =\n            \"Header1,Header2,Header3\" + CSVFormat.DEFAULT.getRecordSeparator() +\n            \"ValueA1,ValueB1,ValueC1\" + CSVFormat.DEFAULT.getRecordSeparator() +\n            \"ValueA2,ValueB2,ValueC2\" + CSVFormat.DEFAULT.getRecordSeparator();\n\n        assertThat(stringWriter.toString())\n            .as(\"Verifying that the CSVPrinter correctly handles streaming input and produces formatted CSV.\")\n            .isEqualTo(expectedOutput);\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5292,
    "output_tokens": 2340,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 300,
      "description": "Define a test class containing a private static final field `EXCEL_WITH_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get()`, a private static final field `UTF_8` of type `Charset` initialized by calling `StandardCharsets.UTF_8`, a private static final field `UTF_8_NAME` of type `String` initialized by calling `UTF_8.name()`, a private static final field `CSV_INPUT` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_1` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_2` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `RESULT` of type `String[][]` initialized with the two-dimensional array `{{\"a\", \"b\", \"c\"}, {\"1\", \"2\", \"3\"}, {\"x\", \"y\", \"z\"}}`, a private static final field `CSV_INPUT_NO_COMMENT` of type `String` initialized with the literal `\"A,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n# trailer comment\\r\\n\"`, a private static final field `CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# multi-line\\r\\n# header comment\\r\\nA,B\\r\\n1,2\\r\\n# multi-line\\r\\n# trailer comment\\r\\n\"`, a private static final field `FORMAT_AUTO_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader().get()`, a private static final field `FORMAT_EXPLICIT_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get()`, and a private static field `FORMAT_EXPLICIT_HEADER_NOSKIP` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").get()`. Write a parameterized test method annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that accepts a single parameter `maxRows` of type `long`. Within a try-with-resources block, invoke `CSVParser.parse` with arguments `CSV_INPUT` and the result of calling `CSVFormat.DEFAULT.builder().setIgnoreSurroundingSpaces(true).setMaxRows(maxRows).get()`, assigning the returned `CSVParser` to variable `parser`. Invoke `getRecords()` on `parser` and assign the returned `List<CSVRecord>` to variable `records`. Compute `expectedLength` of type `long` by evaluating the ternary expression `maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows`. Assert that `expectedLength` equals `records.size()` using `assertEquals(expectedLength, records.size())`. Assert that `records.isEmpty()` returns `false` using `assertFalse(records.isEmpty())`. Iterate from `i = 0` to `i < expectedLength` with increment `i++`, and within each iteration, define a private method that accepts `RESULT[i]` and `records.get(i)` and executes the exact logic of `assertValuesEquals`, then invoke that method with arguments `RESULT[i]` and `records.get(i)`. The test method declares that it throws `IOException`. The test uses JUnit 5 Assertions (`assertEquals`, `assertFalse`) and the parameterized test annotation `@ParameterizedTest` with `@ValueSource`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRowsTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\npublic class CSVParserMaxRowsTest {\n\n    private static final CSVFormat EXCEL_WITH_HEADER = CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get();\n    private static final Charset UTF_8 = StandardCharsets.UTF_8;\n    private static final String UTF_8_NAME = UTF_8.name();\n    private static final String CSV_INPUT = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String CSV_INPUT_1 = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String CSV_INPUT_2 = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String[][] RESULT = {{\"a\", \"b\", \"c\"}, {\"1\", \"2\", \"3\"}, {\"x\", \"y\", \"z\"}};\n    private static final String CSV_INPUT_NO_COMMENT = \"A,B\\r\\n1,2\\r\\n\";\n    private static final String CSV_INPUT_HEADER_COMMENT = \"# header comment\\r\\nA,B\\r\\n1,2\\r\\n\";\n    private static final String CSV_INPUT_HEADER_TRAILER_COMMENT = \"# header comment\\r\\nA,B\\r\\n1,2\\r\\n# trailer comment\\r\\n\";\n    private static final String CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT = \"# multi-line\\r\\n# header comment\\r\\nA,B\\r\\n1,2\\r\\n# multi-line\\r\\n# trailer comment\\r\\n\";\n    private static final CSVFormat FORMAT_AUTO_HEADER = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader().get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER_NOSKIP = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").get();\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    void testMaxRows(final long maxRows) throws IOException {\n        try (final CSVParser parser = CSVParser.parse(CSV_INPUT, CSVFormat.DEFAULT.builder().setIgnoreSurroundingSpaces(true).setMaxRows(maxRows).get())) {\n            final List<CSVRecord> records = parser.getRecords();\n            final long expectedLength = maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows;\n            assertEquals(expectedLength, records.size());\n            assertFalse(records.isEmpty());\n            for (int i = 0; i < expectedLength; i++) {\n                assertValuesEquals(RESULT[i], records.get(i));\n            }\n        }\n    }\n\n    private void assertValuesEquals(final String[] expected, final CSVRecord record) {\n        assertEquals(expected.length, record.size());\n        for (int j = 0; j < expected.length; j++) {\n            assertEquals(expected[j], record.get(j));\n        }\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.9167,
      "callable_precision": 0.6875,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9265,
      "line_coverage": 0.9156,
      "branch_coverage": 0.9178
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 6190,
    "output_tokens": 2078,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 45,
      "description": "Define a parameterized test method that accepts each enumeration value from the Token Type enumeration to validate the string representation behavior of a Token instance across various states and type assignments. Instantiate a new Token object and capture the name of the INVALID type constant for reference throughout the test. Immediately invoke the toString method on the newly created token and assert that the resulting string contains the INVALID type name, establishing the baseline state representation. Reset the token to its initial state and verify once more that toString still includes the INVALID type name, confirming reset behavior preserves the default type representation. Directly assign null to the token's type field and validate that the toString output is not empty, demonstrating robustness when the type is explicitly nullified. Reset the token again to restore its default state, then assign the parameterized type value to the token's type field and assert that toString now contains the name of the assigned type, verifying correct type reflection in the string representation. Modify the token's internal content buffer by setting its length to a large value such as one thousand characters, then confirm that toString continues to include the assigned type name, ensuring the string representation remains stable even when content size changes significantly. This test uses JUnit 5 for parameterization and standard assertion methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenToStringParameterizedTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\nclass TokenToStringParameterizedTest {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testToStringWithVariousTypes(final Token.Type typeParameter) {\n        // Instantiate a new Token object\n        final Token token = new Token();\n\n        // Capture the name of the INVALID type constant for reference\n        final String invalidTypeName = Token.Type.INVALID.name();\n\n        // Immediately invoke the toString method and assert that the resulting string contains the INVALID type name\n        assertTrue(token.toString().contains(invalidTypeName), \"Initial token.toString() should contain INVALID type name.\");\n\n        // Reset the token to its initial state\n        token.reset();\n\n        // Verify once more that toString still includes the INVALID type name\n        assertTrue(token.toString().contains(invalidTypeName), \"After reset, token.toString() should still contain INVALID type name.\");\n\n        // Directly assign null to the token's type field\n        token.type = null;\n\n        // Validate that the toString output is not empty\n        assertFalse(token.toString().isEmpty(), \"token.toString() should not be empty when type is null.\");\n        // Additionally, verify it contains \"null\" as the type name part\n        assertTrue(token.toString().contains(\"null\"), \"token.toString() should contain 'null' as type name when type is null.\");\n\n\n        // Reset the token again to restore its default state\n        token.reset();\n\n        // Assign the parameterized type value to the token's type field\n        token.type = typeParameter;\n\n        // Assert that toString now contains the name of the assigned type\n        assertTrue(token.toString().contains(typeParameter.name()),\n            \"token.toString() should contain the assigned parameterized type name: \" + typeParameter.name());\n\n        // Modify the token's internal content buffer by setting its length to a large value\n        final int largeLength = 1000;\n        token.content.setLength(largeLength);\n        // Ensure some content exists to make the buffer truly large, otherwise setLength on empty buffer might not reflect intent fully\n        for (int i = 0; i < largeLength; i++) {\n            token.content.append('a');\n        }\n\n\n        // Confirm that toString continues to include the assigned type name\n        assertTrue(token.toString().contains(typeParameter.name()),\n            \"After content length change, token.toString() should still contain the assigned parameterized type name: \" + typeParameter.name());\n    }\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.8333,
      "callable_recall": 1.0,
      "callable_precision": 0.7857,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 18558,
    "output_tokens": 2383,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 49,
      "description": "Create a test case to validate that the system correctly processes and formats data when receiving information through a concurrent processing stream. Configure a temporary output destination to capture the formatted results, then establish a formatting handler using standard comma-separated value conventions. Submit a collection of values for processing where the data arrives through a parallel execution pathway rather than sequentially, ensuring the system properly serializes and formats these concurrently-processed values into a single delimited record. After the formatting operation completes and resources are released, verify that the output destination contains the correctly formatted record with all values properly delimited and terminated according to the expected business format specifications. Use JUnit 5 as the testing framework and verify the final output matches the expected format using standard equality assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.ConcurrentCSVPrinterTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.TimeUnit;\n\npublic class ConcurrentCSVPrinterTest {\n\n    @Test\n    void testConcurrentValueFormattingIntoSingleRecord() throws IOException, InterruptedException, ExecutionException {\n        // Configure a temporary output destination\n        StringWriter sw = new StringWriter();\n\n        // Establish a formatting handler using standard comma-separated value conventions\n        CSVFormat format = CSVFormat.DEFAULT;\n        try (CSVPrinter printer = new CSVPrinter(sw, format)) {\n\n            int numValues = 5;\n            ExecutorService executor = Executors.newFixedThreadPool(numValues);\n            List<Callable<String>> tasks = new ArrayList<>();\n\n            // Submit a collection of values for processing where the data arrives through a parallel execution pathway\n            for (int i = 0; i < numValues; i++) {\n                final int index = i;\n                tasks.add(() -> \"Value\" + index); // Each task generates a unique string value\n            }\n\n            // Execute tasks concurrently and collect futures\n            List<Future<String>> futures = executor.invokeAll(tasks);\n\n            // Collect the concurrently-processed values in order\n            List<String> values = new ArrayList<>();\n            for (Future<String> future : futures) {\n                // future.get() blocks until the corresponding task completes, ensuring all values are collected\n                // and added to the list in the order of task submission (due to invokeAll preserving order).\n                values.add(future.get());\n            }\n\n            executor.shutdown();\n            // Wait for all tasks to terminate to ensure resources are released.\n            // This is crucial for deterministic tests using executors.\n            if (!executor.awaitTermination(60, TimeUnit.SECONDS)) {\n                // Log or handle if the executor does not terminate in a reasonable time.\n                // For a simple test, this might indicate an issue, though not directly a test failure in this context.\n            }\n\n            // Ensure the system properly serializes and formats these concurrently-processed values into a single delimited record\n            printer.printRecord(values);\n        }\n\n        // Verify that the output destination contains the correctly formatted record\n        String expectedOutput = \"Value0,Value1,Value2,Value3,Value4\\r\\n\";\n        assertEquals(expectedOutput, sw.toString(), \"The CSV record should be correctly formatted from concurrently generated values.\");\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.2857,
      "callable_precision": 0.2857,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9667,
      "line_coverage": 0.9677,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5334,
    "output_tokens": 4917,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 53,
      "description": "Create a test case to validate that the system correctly formats a collection of text values into a properly delimited output format using default formatting rules. Begin by preparing an in-memory output destination to capture the formatted results, then configure a formatting tool using standard delimiter and quoting conventions. Supply a sequence of three column values representing typical record data, instruct the formatting tool to process these values as a single record entry, then close the formatting tool to finalize the output. After processing, verify that the captured output matches the expected format by comparing it against the standard representation for such data, ensuring proper delimiter placement, quote handling, and record termination according to the default formatting specification. Use JUnit 5 as the testing framework and verify the output correctness using standard equality assertions to confirm the formatted text matches business expectations for delimited value representation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatDefaultPrinterTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class CSVFormatDefaultPrinterTest {\n\n    @Test\n    void testDefaultFormatPrinting() throws IOException {\n        // Prepare an in-memory output destination to capture the formatted results.\n        final StringWriter stringWriter = new StringWriter();\n\n        // Configure a formatting tool using standard delimiter and quoting conventions\n        // (CSVFormat.DEFAULT uses comma delimiter, double quote character, and CRLF record separator).\n        try (final CSVPrinter printer = new CSVPrinter(stringWriter, CSVFormat.DEFAULT)) {\n            // Supply a sequence of three column values representing typical record data.\n            final List<String> recordValues = Arrays.asList(\"value1\", \"value2\", \"value3\");\n\n            // Instruct the formatting tool to process these values as a single record entry.\n            printer.printRecord(recordValues);\n        }\n\n        // Verify that the captured output matches the expected format.\n        // Expected format for CSVFormat.DEFAULT: \"value1\",\"value2\",\"value3\"\\r\\n\n        final String expectedOutput = \"\\\"value1\\\",\\\"value2\\\",\\\"value3\\\"\\r\\n\";\n        Assertions.assertEquals(expectedOutput, stringWriter.toString(),\n            \"The formatted output should match the default CSV format.\");\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.3333,
      "callable_precision": 0.6667,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9677,
      "line_coverage": 0.9686,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5352,
    "output_tokens": 1703,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 55,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources block, create a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where the first argument is a `PrintWriter` wrapping `baos` and the second is the static constant `CSVFormat.DEFAULT`, immediately invoke `printRecord` on `printer` passing a `Stream<String>` obtained by first calling a private method that returns `newStream().parallel()` (where `newStream()` produces the base stream and `parallel()` converts it to a parallel stream), and upon exiting the try-with-resources block (which auto-closes the printer), invoke a private method that calls `baos.toString()` and passes the resulting String to another private method for output verification. Annotate the test method with `@Test` and declare it to throw `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.Test;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.Arrays;\nimport java.util.stream.Stream;\n\nimport static org.junit.Assert.assertEquals;\n\npublic class CSVPrinterStreamTest {\n\n    @Test\n    public void testPrintRecordWithParallelStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(newStream().parallel());\n        }\n        verifyOutput(baos.toString());\n    }\n\n    private Stream<String> newStream() {\n        return Arrays.asList(\"Value1\", \"Value2\", \"Value3\").stream();\n    }\n\n    private void verifyOutput(final String output) {\n        // CSVFormat.DEFAULT uses a comma delimiter and CRLF line ending\n        assertEquals(\"Value1,Value2,Value3\\r\\n\", output);\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5404,
    "output_tokens": 1679,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 58,
      "description": "Create a test case to validate that the system can reliably produce a textual representation of a token across all possible token classification states and edge conditions without encountering failures. Begin by establishing a new token in its initial state and verify that its textual representation includes the default classification label. After confirming the initial state, restore the token to its baseline configuration and ensure the representation still reflects the default classification. Simulate an exceptional scenario where the token's classification becomes undefined, then verify the system still produces a meaningful textual representation rather than failing or returning empty content. Following this edge case validation, restore the token again to its baseline and then configure it with each possible classification type from the system's complete set of token categories. For every classification type, confirm the textual representation accurately includes the corresponding classification label. Additionally, simulate a scenario where the token's internal content grows to a substantial size and verify the textual representation continues to display the correct classification label regardless of content volume, ensuring the representation mechanism remains stable under varying data conditions. This validation uses JUnit 5 with parameterized testing to exercise all classification variations, applying standard equality and containment assertions to verify the business outcomes.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenToStringTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\nimport static org.junit.jupiter.api.Assertions.fail;\n\npublic class TokenToStringTest {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testTokenToStringRepresentations(Token.Type tokenType) {\n        // --- Initial state and default classification ---\n        // Establish a new token in its initial state. By default, its type is INVALID.\n        Token initialToken = new Token();\n        assertTrue(initialToken.toString().contains(Token.Type.INVALID.name()),\n                \"Initial token toString() should contain INVALID type, reflecting default classification.\");\n        assertTrue(initialToken.toString().contains(\"[]\"),\n                \"Initial token toString() should contain empty content brackets.\");\n\n        // --- Exceptional scenario: undefined classification (null type) ---\n        // Simulate a scenario where the token's classification becomes undefined.\n        Token undefinedTypeToken = new Token();\n        try {\n            // Use reflection to set the 'type' field to null to simulate an undefined state.\n            // This tests robustness when 'type' might unexpectedly be null.\n            java.lang.reflect.Field typeField = Token.class.getDeclaredField(\"type\");\n            typeField.setAccessible(true);\n            typeField.set(undefinedTypeToken, null);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n            fail(\"Could not set Token type to null for testing undefined scenario: \" + e.getMessage());\n        }\n\n        // Verify the system still produces a meaningful textual representation.\n        String undefinedToString = undefinedTypeToken.toString();\n        assertTrue(undefinedToString.contains(\"null [\"),\n                \"toString() for a token with null type should indicate 'null' for the type portion.\");\n        assertFalse(undefinedToString.isEmpty(),\n                \"toString() for a token with null type should not be empty.\");\n        assertTrue(undefinedToString.endsWith(\"]\"),\n                \"toString() for a token with null type should still end with content brackets.\");\n\n        // --- Restore to baseline configuration ---\n        // A new Token object naturally provides a baseline configuration (type = INVALID, content = empty).\n        Token baselineToken = new Token();\n        assertTrue(baselineToken.toString().contains(Token.Type.INVALID.name()),\n                \"Baseline token toString() should reflect INVALID type after simulating an undefined state.\");\n        assertTrue(baselineToken.toString().contains(\"[]\"),\n                \"Baseline token toString() should contain empty content brackets.\");\n\n\n        // --- Test each classification type from the system's complete set ---\n        Token tokenForType = new Token();\n        tokenForType.type = tokenType; // Set to the current parameterized type\n        assertEquals(tokenType.name() + \" []\", tokenForType.toString(),\n                \"toString() should correctly represent the assigned token type with empty content for \" + tokenType.name() + \".\");\n\n        // --- Simulate substantial content volume and verify classification label ---\n        String longContent = \"A\".repeat(5000); // Substantial content size\n        Token tokenWithLongContent = new Token();\n        tokenWithLongContent.type = tokenType;\n        tokenWithLongContent.content.append(longContent);\n\n        String longContentToString = tokenWithLongContent.toString();\n        assertTrue(longContentToString.contains(tokenType.name()),\n                \"toString() with long content should still contain the correct token type name for \" + tokenType.name() + \".\");\n        assertTrue(longContentToString.contains(longContent),\n                \"toString() with long content should contain the full content for \" + tokenType.name() + \".\");\n        assertEquals(tokenType.name() + \" [\" + longContent + \"]\", longContentToString,\n                \"toString() should correctly represent assigned token type and full long content for \" + tokenType.name() + \".\");\n\n        // Additional check for each type with some basic content\n        Token tokenWithSampleContent = new Token();\n        tokenWithSampleContent.type = tokenType;\n        tokenWithSampleContent.content.append(\"sample data\");\n        assertEquals(tokenType.name() + \" [sample data]\", tokenWithSampleContent.toString(),\n                \"toString() should correctly represent assigned token type with sample data for \" + tokenType.name() + \".\");\n    }\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 3
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 41526,
    "output_tokens": 4886,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 59,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then instantiate a `ByteArrayOutputStream` and assign it to variable `baos`, followed by opening a try-with-resources block that creates a `CSVPrinter` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` and assigns it to variable `printer`, then within the try block invoke `printRecord` on `printer` passing a `Stream<String>` created by calling `newStream().sequential()` as the argument (where `newStream()` returns a stream of strings), and upon exiting the try-with-resources block (which automatically closes `printer`), invoke `toString()` on `baos` to convert the byte array output stream to a string and pass that string to a verification method that asserts the output matches the expected CSV format. The test uses JUnit 5 with the `@Test` annotation and standard Java I/O classes (`ByteArrayOutputStream`, `PrintWriter`) along with Apache Commons CSV classes (`CSVPrinter`, `CSVFormat`).",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamRecordTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\nclass CSVPrinterStreamRecordTest {\n\n    @Test\n    void testPrintRecordWithStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            // The prompt states \"passing a Stream<String> created by calling newStream().sequential() as the argument\".\n            // CSVPrinter.printRecord expects an Iterable or Object[].\n            // To fulfill the intent of printing the stream's elements as a CSV record,\n            // we collect the stream into a List, which is an Iterable, compatible with printRecord.\n            printer.printRecord(newStream().sequential().collect(Collectors.toList()));\n        }\n        final String actualCsv = baos.toString(StandardCharsets.UTF_8.name());\n        final String expectedCsv = \"\"A\",\"B\",\"C\"\n\"; // CSVFormat.DEFAULT uses CRLF record separator\n        Assertions.assertEquals(expectedCsv, actualCsv);\n    }\n\n    private Stream<String> newStream() {\n        return Stream.of(\"A\", \"B\", \"C\");\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 37561,
    "output_tokens": 5284,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 63,
      "description": "Define a test method that validates the CSV Printer's ability to write a stream of string values as a single record to an output destination. Initialize a ByteArrayOutputStream to capture the CSV output, then create a private helper method that constructs a CSV Printer instance wrapping the output stream with a PrintWriter and configuring it to use the default CSV format. Invoke this helper to obtain the printer within a try-with-resources block to ensure automatic closure. Create another private helper method that generates a stream containing three string column values, then pass this stream to the printer's printRecord method which accepts a Stream parameter to write the values as a delimited record. Upon closing the printer, invoke a private helper method that accepts the ByteArrayOutputStream and validates the generated CSV output by converting the stream contents to a string representation and verifying the expected format, delimiter placement, and value sequence. The test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.stream.Stream;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\npublic class CSVPrinterStreamTest {\n\n    /**\n     * Tests the CSV Printer's ability to write a stream of string values as a single record to an output destination.\n     * It initializes a ByteArrayOutputStream to capture the CSV output, creates a CSV Printer instance\n     * wrapping the output stream with a PrintWriter and configuring it to use the default CSV format.\n     * It then generates a stream containing three string column values, passes this stream to the printer's\n     * printRecord method which accepts a Stream parameter to write the values as a delimited record.\n     * Upon closing the printer, it validates the generated CSV output by converting the stream contents\n     * to a string representation and verifying the expected format, delimiter placement, and value sequence.\n     */\n    @Test\n    public void testPrintStreamRecord() throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (CSVPrinter printer = createCsvPrinter(baos)) {\n            Stream<String> values = createStringStream();\n            printer.printRecord(values);\n        }\n        validateOutput(baos);\n    }\n\n    /**\n     * Helper method to construct a CSV Printer instance.\n     * Wraps the given ByteArrayOutputStream with a PrintWriter and configures it to use the default CSV format.\n     *\n     * @param baos The ByteArrayOutputStream to write to.\n     * @return A configured CSVPrinter instance.\n     */\n    private CSVPrinter createCsvPrinter(ByteArrayOutputStream baos) {\n        return new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT);\n    }\n\n    /**\n     * Helper method to generate a stream containing three string column values.\n     *\n     * @return A Stream of strings.\n     */\n    private Stream<String> createStringStream() {\n        return Stream.of(\"value1\", \"value2\", \"value3\");\n    }\n\n    /**\n     * Helper method to validate the generated CSV output.\n     * Converts the stream contents to a string representation and verifies the expected format,\n     * delimiter placement, and value sequence.\n     *\n     * @param baos The ByteArrayOutputStream containing the CSV output.\n     */\n    private void validateOutput(ByteArrayOutputStream baos) {\n        String expected = \"value1,value2,value3\\r\\n\";\n        String actual = baos.toString();\n        assertEquals(expected, actual, \"The CSV output does not match the expected format.\");\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5376,
    "output_tokens": 1846,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 67,
      "description": "Define a parameterized test method accepting a single parameter of type `org.apache.commons.csv.Token.Type`, annotated with `@ParameterizedTest` and `@EnumSource(Token.Type.class)` to supply all enum constants of `Token.Type` as test inputs. Begin by instantiating a new `Token` object using the no-argument constructor and assign it to a final variable named `token`. Immediately retrieve the name of the `Token.Type.INVALID` enum constant by invoking `Token.Type.INVALID.name()` and assign the resulting `String` to a final variable named `resetName`. Invoke `toString()` on `token`, then invoke `contains(resetName)` on the returned `String`, and assert the result is true using `assertTrue`. Next, invoke `reset()` on `token`, then again invoke `toString()` on `token`, call `contains(resetName)` on the result, and assert true using `assertTrue`. Directly assign `null` to the `type` field of `token`, invoke `toString()` on `token`, call `isEmpty()` on the returned `String`, and assert the result is false using `assertFalse`. Invoke `reset()` on `token`, then assign the parameterized `type` argument to the `type` field of `token`. Invoke `toString()` on `token`, call `contains(type.name())` on the result where `type.name()` retrieves the name of the current parameter enum constant, and assert true using `assertTrue`. Access the `content` field of `token` (which is a `StringBuilder`) and invoke `setLength(1000)` on it. Finally, invoke `toString()` on `token`, call `contains(type.name())` on the returned `String`, and assert true using `assertTrue`. The test uses JUnit 5 Assertions with annotations `@ParameterizedTest` and `@EnumSource(Token.Type.class)`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenParameterizedTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\npublic class TokenParameterizedTest {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testTokenManipulation(final Token.Type type) {\n        final Token token = new Token();\n        final String resetName = Token.Type.INVALID.name();\n\n        Assertions.assertTrue(token.toString().contains(resetName));\n\n        token.reset();\n        Assertions.assertTrue(token.toString().contains(resetName));\n\n        token.type = null;\n        Assertions.assertFalse(token.toString().isEmpty());\n\n        token.reset();\n        token.type = type;\n        Assertions.assertTrue(token.toString().contains(type.name()));\n\n        token.content.setLength(1000);\n        Assertions.assertTrue(token.toString().contains(type.name()));\n    }\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5600,
    "output_tokens": 1284,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 68,
      "description": "Define a test method that validates CSV printing behavior when a sequential stream is used as input by initializing a ByteArrayOutputStream to capture the printed output, then create a private helper method that constructs a CSV Printer configured with the default CSV format and wraps the output stream in a PrintWriter. Create another private helper method that generates a sequential stream of string values by obtaining a base stream and explicitly marking it as sequential. Invoke the print record method on the CSV Printer passing the sequential stream as the record data source, which will internally iterate over the stream elements and write each value to the output stream according to the format's delimiter and quoting rules. Upon completion of the print operation, close the CSV Printer resource to flush any buffered content to the underlying output stream. Create a private helper method that validates the captured output by converting the ByteArrayOutputStream contents to a string representation and verifying the formatted CSV record matches expected structure and content. This test uses JUnit 5 for the test framework and standard Java I/O libraries for stream handling.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterSequentialStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStreamWriter;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\n/**\n * Tests the CSVPrinter's behavior when printing records from a sequential stream.\n */\npublic class CSVPrinterSequentialStreamTest {\n\n    /**\n     * Validates CSV printing behavior when a sequential stream is used as input.\n     * It initializes a ByteArrayOutputStream to capture the printed output, creates\n     * a CSVPrinter configured with the default CSV format, and wraps the output stream\n     * in a PrintWriter. It generates a sequential stream of string values and invokes\n     * the printRecord method on the CSVPrinter, passing the sequential stream's elements\n     * as the record data source. Upon completion, it closes the CSVPrinter and\n     * validates the captured output against an expected CSV string.\n     *\n     * @throws IOException If an I/O error occurs during printing.\n     */\n    @Test\n    void testPrintSequentialStream() throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        // The expected CSV output, using the default delimiter (comma) and record separator (CRLF)\n        String expectedCsv = \"value1,value2,value3\" + CSVFormat.DEFAULT.getRecordSeparator();\n\n        // Use try-with-resources to ensure the CSVPrinter is closed properly\n        try (CSVPrinter printer = createCSVPrinter(baos)) {\n            // Generate a sequential stream of string values\n            Stream<String> sequentialStream = generateSequentialStream(\"value1\", \"value2\", \"value3\");\n\n            // Print the record, converting the stream to a List (Iterable) for printRecord method\n            printer.printRecord(sequentialStream.collect(Collectors.toList()));\n        }\n\n        // Validate the captured output against the expected CSV string\n        assertPrintedCSV(expectedCsv, baos);\n    }\n\n    /**\n     * Constructs a CSV Printer configured with the default CSV format and\n     * wraps the provided ByteArrayOutputStream in a PrintWriter.\n     *\n     * @param baos The ByteArrayOutputStream to capture the printed content.\n     * @return A configured CSVPrinter instance.\n     * @throws IOException If an I/O error occurs during stream wrapping.\n     */\n    private CSVPrinter createCSVPrinter(ByteArrayOutputStream baos) throws IOException {\n        // Wrap the ByteArrayOutputStream with an OutputStreamWriter and PrintWriter for CSVPrinter\n        PrintWriter writer = new PrintWriter(new OutputStreamWriter(baos, StandardCharsets.UTF_8));\n        // Return a new CSVPrinter using the default CSV format and the created PrintWriter\n        return new CSVPrinter(CSVFormat.DEFAULT, writer);\n    }\n\n    /**\n     * Generates a sequential stream of string values from the given array.\n     * The stream is explicitly marked as sequential.\n     *\n     * @param values The string values to be included in the stream.\n     * @return A sequential {@link Stream} of strings.\n     */\n    private Stream<String> generateSequentialStream(String... values) {\n        // Create a stream from the array and explicitly ensure it's sequential\n        return Arrays.stream(values).sequential();\n    }\n\n    /**\n     * Validates the content captured by the ByteArrayOutputStream against an expected string.\n     *\n     * @param expected The expected string content.\n     * @param actual   The ByteArrayOutputStream containing the actual content.\n     */\n    private void assertPrintedCSV(String expected, ByteArrayOutputStream actual) {\n        // Convert the ByteArrayOutputStream content to a string using UTF-8 and assert equality\n        Assertions.assertEquals(expected, actual.toString(StandardCharsets.UTF_8));\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "search_file_content": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 10851,
    "output_tokens": 3362,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 69,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources statement instantiate a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where `CSVFormat.DEFAULT` is the static constant from the `CSVFormat` class, immediately invoke `printRecord` on `printer` passing the result of `Stream.of(\"col a\", \"col b\", \"col c\")` as the argument, and upon exiting the try-with-resources block invoke a private method that executes the logic of converting `baos` to a `String` via `baos.toString()` and then passing that `String` to another private method for output verification (define these private methods to encapsulate the exact behavior: the first accepts a `ByteArrayOutputStream` and calls `toString()` on it before delegating to the second method, and the second accepts a `String` and performs the necessary assertions on the formatted output). Annotations: method-level `@Test`. Assertion libraries: implementation-dependent (based on the private verification method). Mocking libraries: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterRecordTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.Assertions;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.PrintWriter;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.stream.Stream;\n\npublic class CSVPrinterRecordTest {\n\n    @Test\n    public void testPrintRecordWithStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(Stream.of(\"col a\", \"col b\", \"col c\").toArray());\n        }\n        verifyOutput(baos);\n    }\n\n    private void verifyOutput(final ByteArrayOutputStream baos) throws IOException {\n        // Use StandardCharsets.UTF_8 for consistency in converting bytes to string\n        final String output = baos.toString(StandardCharsets.UTF_8.name());\n        verifyOutputString(output);\n    }\n\n    private void verifyOutputString(final String output) {\n        // CSVFormat.DEFAULT uses comma as delimiter, no quoting for simple strings, and CRLF for line endings.\n        // The expected output for \"col a\", \"col b\", \"col c\" should be \"col a,col b,col c\n\"\n        Assertions.assertEquals(\"col a,col b,col c\\r\\n\", output);\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 70,
      "description": "Define a test method that validates CSV printing behavior when processing a parallel stream of strings by initializing a byte array output stream to capture the printed output, then create a private helper method that constructs a CSV printer wrapping the byte stream with a print writer configured for default CSV format, and create another private helper method that generates a parallel stream of strings by converting a standard stream to parallel mode. Invoke the print record method on the CSV printer passing the parallel stream as input, which internally acquires a reentrant lock, adapts the stream based on its parallel status, processes each element through ordered iteration, and releases the lock upon completion. After the printer resource is automatically closed, create a private helper method that validates the output by converting the byte stream to a string representation and comparing it against expected CSV formatting. The test verifies that the CSV printer correctly handles parallel stream inputs by ensuring thread-safe record printing and proper delimiter-separated value formatting. This test uses JUnit 5 for the test framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterParallelStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStreamWriter;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nclass CSVPrinterParallelStreamTest {\n\n    @Test\n    void testPrintParallelStreamRecords() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n        final String[] records = {\"value1\", \"value2\", \"value3\", \"value4\"};\n        final String expectedCsv = \"value1\\r\\nvalue2\\r\\nvalue3\\r\\nvalue4\\r\\n\";\n\n        try (final CSVPrinter printer = createCsvPrinter(baos)) {\n            final Stream<String[]> parallelStream = createParallelStreamOfRecords(records);\n            printer.printRecords(parallelStream);\n        }\n\n        validateOutput(baos, expectedCsv);\n    }\n\n    /**\n     * Constructs a CSVPrinter wrapping the byte stream with a print writer configured for default CSV format.\n     *\n     * @param baos The ByteArrayOutputStream to write to.\n     * @return A configured CSVPrinter.\n     * @throws IOException if an I/O error occurs.\n     */\n    private CSVPrinter createCsvPrinter(final ByteArrayOutputStream baos) throws IOException {\n        final PrintWriter pw = new PrintWriter(new OutputStreamWriter(baos, StandardCharsets.UTF_8));\n        return new CSVPrinter(pw, CSVFormat.DEFAULT);\n    }\n\n    /**\n     * Generates a parallel stream of string arrays, where each string array represents a single record.\n     *\n     * @param values An array of strings to be converted into records.\n     * @return A parallel Stream of String arrays.\n     */\n    private Stream<String[]> createParallelStreamOfRecords(final String... values) {\n        return Arrays.stream(values)\n                     .map(s -> new String[]{s}) // Each string becomes a single-element record\n                     .parallel();\n    }\n\n    /**\n     * Validates the output by converting the byte stream to a string representation and comparing it against expected CSV formatting.\n     *\n     * @param baos The ByteArrayOutputStream containing the actual CSV output.\n     * @param expected The expected CSV string.\n     * @throws IOException if an I/O error occurs during conversion.\n     */\n    private void validateOutput(final ByteArrayOutputStream baos, final String expected) throws IOException {\n        final String actual = baos.toString(StandardCharsets.UTF_8.name());\n        assertEquals(expected, actual, \"The CSV output does not match the expected format.\");\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.4286,
      "callable_precision": 0.4286,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9333,
      "line_coverage": 0.9548,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5386,
    "output_tokens": 3548,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 95,
      "description": "Create a test case to validate that the system correctly processes CSV data formatted according to PostgreSQL conventions, ensuring that missing values are interpreted appropriately across multiple records. Load a sample CSV file from the test resources that contains three records, each demonstrating different patterns of empty and missing cell values. Process the file using the PostgreSQL CSV formatting rules and retrieve the records sequentially. For the first record, verify that the system captures two populated values followed by a missing value represented as absent data. For the second record, confirm that the system distinguishes between a missing value in the middle position and an explicitly empty value in the final position. For the third record, ensure that the system correctly handles a missing value at the beginning while preserving the subsequent populated values. The test confirms that the parsing logic respects the PostgreSQL CSV specification for handling various forms of absent data, including true null values versus empty strings. Upon completion, release any resources held during the file processing operation. The validation strategy employs JUnit 5 as the testing framework with standard equality assertions to confirm the expected value patterns in each record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.PostgreSQLMissingValuesTest",
      "code": "package org.apache.commons.csv;\n\nimport org.apache.commons.csv.CSVFormat;\nimport org.apache.commons.csv.CSVParser;\nimport org.apache.commons.csv.CSVRecord;\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertNull;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport java.util.List;\n\npublic class PostgreSQLMissingValuesTest {\n\n    // CSV data formatted according to PostgreSQL conventions with various missing and empty values.\n    // \\N represents a missing (null) value. \"\" represents an explicitly empty string.\n    private static final String CSV_DATA =\n            \"Header1,Header2,Header3\\n\" +\n            \"Value1,Value2,\\\\N\\n\" +\n            \"ValueA,\\\\N,\\\"\\\"\\n\" +\n            \"\\\\N,ValueD,ValueE\";\n\n    @Test\n    void testPostgreSQLMissingValues() throws IOException {\n        // Configure CSVFormat for PostgreSQL CSV conventions.\n        // We explicitly set withHeader() because our CSV_DATA includes a header row.\n        CSVFormat postgresFormat = CSVFormat.POSTGRESQL_CSV.builder()\n                                        .setHeader()\n                                        .build();\n\n        // Use a StringReader to process the CSV data provided as a string literal.\n        // The try-with-resources statement ensures that the reader and parser are closed properly.\n        try (StringReader reader = new StringReader(CSV_DATA);\n             CSVParser parser = new CSVParser(reader, postgresFormat)) {\n\n            List<CSVRecord> records = parser.getRecords();\n\n            // Verify that the parser correctly identified three data records.\n            assertEquals(3, records.size(), \"Expected three records to be parsed.\");\n\n            // --- Validate First Record ---\n            // Expected: [\"Value1\", \"Value2\", null] (where \\N is parsed as null)\n            CSVRecord record1 = records.get(0);\n            assertEquals(\"Value1\", record1.get(\"Header1\"), \"Record 1: Header1 should be 'Value1'\");\n            assertEquals(\"Value2\", record1.get(\"Header2\"), \"Record 1: Header2 should be 'Value2'\");\n            assertNull(record1.get(\"Header3\"), \"Record 1: Header3 (missing value) should be null\");\n\n            // --- Validate Second Record ---\n            // Expected: [\"ValueA\", null, \"\"] (where \\N is parsed as null, and \"\" is an empty string)\n            CSVRecord record2 = records.get(1);\n            assertEquals(\"ValueA\", record2.get(\"Header1\"), \"Record 2: Header1 should be 'ValueA'\");\n            assertNull(record2.get(\"Header2\"), \"Record 2: Header2 (missing value) should be null\");\n            assertEquals(\"\", record2.get(\"Header3\"), \"Record 2: Header3 (empty string) should be ''\");\n\n            // --- Validate Third Record ---\n            // Expected: [null, \"ValueD\", \"ValueE\"] (where \\N is parsed as null)\n            CSVRecord record3 = records.get(2);\n            assertNull(record3.get(\"Header1\"), \"Record 3: Header1 (missing value) should be null\");\n            assertEquals(\"ValueD\", record3.get(\"Header2\"), \"Record 3: Header2 should be 'ValueD'\");\n            assertEquals(\"ValueE\", record3.get(\"Header3\"), \"Record 3: Header3 should be 'ValueE'\");\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9531,
      "line_coverage": 0.9539,
      "branch_coverage": 0.9538
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "search_file_content": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 11006,
    "output_tokens": 4903,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  }
]