[
  {
    "compiles": false,
    "nl2test_input": {
      "id": 111,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure it with a delimiter string representing a line feed character by converting the line feed constant to its string representation. Upon invoking the builder's get method to construct the format instance, assert that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test verifies the format builder's input validation enforces delimiter constraints at construction time. The test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "",
      "code": "",
      "method_signature": null
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 10629,
    "output_tokens": 4835,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": true
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 118,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that constructs the invalid format configuration. Within the lambda, invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `Builder` instance, then chain `setDelimiter` passing the result of `String.valueOf(Constants.LF)` as the argument to set the delimiter to the line feed character, and finally chain `get()` to build the `CSVFormat` instance, which should trigger the exception during validation. The test uses JUnit 5 Assertions via `assertThrows` and operates on the `org.apache.commons.csv.CSVFormat.Builder` fluent API with method chaining. The test method has no class-level annotations, no field declarations, no setup methods, and no teardown methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatTestVerifyingLineFeedDelimiter",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat}.\n */\npublic class CSVFormatTestVerifyingLineFeedDelimiter {\n\n    @Test\n    public void testSetDelimiterWithLFThrowsIllegalArgumentException() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(String.valueOf(Constants.LF)).get();\n        });\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 29299,
    "output_tokens": 1202,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 119,
      "description": "Define a test method that validates the CSV Parser's handling of PostgreSQL CSV format when parsing records containing null values and empty strings from a file resource. Initialize a CSV Format instance configured for PostgreSQL CSV dialect, then open a buffered reader targeting the test resource file \"csv-254.csv\" using UTF-8 encoding and construct a CSV Parser by invoking the parse method on the format with the reader, ensuring both resources are managed within a try-with-resources block for automatic closure. Obtain an iterator over CSV Records from the parser to enable sequential record retrieval. For the first record, advance the iterator and create a helper method that validates the record's field values match an expected array containing two non-null strings and one null value. For the second record, advance the iterator again and validate against an expected array containing one non-null string, one null value, and one empty string. For the third record, advance the iterator once more and validate against an expected array containing one null value followed by two non-null strings. The helper method should compare each field in the retrieved record against the corresponding expected value, accounting for the distinction between null values and empty strings as defined by the PostgreSQL CSV format's null handling behavior. Upon exiting the try-with-resources block, the reader and parser resources are automatically closed. This test uses JUnit for test execution and relies on the CSV Parser's ability to correctly interpret null representations in PostgreSQL CSV format.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserPostgreSqlTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.Assert.assertEquals;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.net.URL;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Iterator;\n\nimport org.junit.Test;\n\npublic class CSVParserPostgreSqlTest {\n\n    private void validate(final CSVRecord record, final String... expectedValues) {\n        assertEquals(expectedValues.length, record.size());\n        for (int i = 0; i < expectedValues.length; i++) {\n            assertEquals(expectedValues[i], record.get(i));\n        }\n    }\n\n    @Test\n    public void testPostgreSqlCsvParserWithNullsAndEmptyStrings() throws IOException {\n        final URL resource = getClass().getResource(\"/org/apache/commons/csv/CSV-254/csv-254.csv\");\n        final CSVFormat format = CSVFormat.POSTGRESQL_CSV;\n        try (final BufferedReader reader = new BufferedReader(new InputStreamReader(resource.openStream(), StandardCharsets.UTF_8));\n             final CSVParser parser = format.parse(reader)) {\n            final Iterator<CSVRecord> iterator = parser.iterator();\n\n            final CSVRecord record1 = iterator.next();\n            validate(record1, \"a\", \"b\", null);\n\n            final CSVRecord record2 = iterator.next();\n            validate(record2, \"a\", null, \"\");\n\n            final CSVRecord record3 = iterator.next();\n            validate(record3, null, \"a\", \"b\");\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 27410,
    "output_tokens": 5505,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 122,
      "description": "Define a test method that validates the CSV Parser's ability to handle null format parameters by opening an input stream from a CSV file located at a specific test resource path, then invoke the static parse method on the CSV Parser with the input stream, the system's default charset, and a null format parameter to verify that null maps to the default CSV format configuration. Upon obtaining the parser instance, create a private helper method that iterates through all records in the parser and asserts that each record is non-null to confirm successful parsing and record retrieval. Ensure the parser and input stream are properly closed after iteration completes by leveraging try-with-resources to automatically release file system resources. This test uses JUnit 5 for the testing framework and standard Java assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserNullFormatTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.net.URL;\nimport java.nio.charset.Charset;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests the CSVParser's handling of null format parameters.\n */\npublic class CSVParserNullFormatTest {\n\n    private static final String TEST_RESOURCE = \"org/apache/commons/csv/CSVFileParser/test_default_comment.txt\";\n\n    @Test\n    public void testParseWithNullFormat() throws IOException {\n        final URL resourceUrl = getClass().getClassLoader().getResource(TEST_RESOURCE);\n        assertNotNull(resourceUrl, \"Test resource not found: \" + TEST_RESOURCE);\n\n        try (final InputStream inputStream = resourceUrl.openStream();\n             final CSVParser parser = CSVParser.parse(inputStream, Charset.defaultCharset(), null)) {\n            assertRecordsNonNull(parser);\n        }\n    }\n\n    private void assertRecordsNonNull(final CSVParser parser) {\n        for (final CSVRecord record : parser) {\n            assertNotNull(record, \"Record should not be null\");\n        }\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.2857,
      "callable_precision": 0.2222,
      "focal_recall": 0.5,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.8923,
      "line_coverage": 0.8404,
      "branch_coverage": 0.8533
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 12704,
    "output_tokens": 2058,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 123,
      "description": "Define a test method that validates the CSV Parser's behavior when provided with a null format parameter by constructing a Path object pointing to a CSV test resource file, then invoking the static parse method on CSVParser with this path, the system's default charset, and null as the format argument, which should internally default to the standard CSV format. Upon obtaining the parser instance within a try-with-resources block to ensure automatic closure, create a private helper method that iterates through all records produced by the parser and asserts that each record is non-null, thereby confirming the parser successfully processes the file despite the null format input. The parser's automatic resource management handles cleanup when the try block completes, releasing the file handle and any associated streams. This test uses JUnit 5 for the test framework and standard Java assertions for validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserNullFormatTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVParser} with a null format.\n */\npublic class CSVParserNullFormatTest {\n\n    private void checkRecords(final CSVParser parser) {\n        parser.forEach(record -> {\n            assertNotNull(record);\n        });\n    }\n\n    @Test\n    public void testParseNullFormat() throws IOException {\n        final Path path = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n        try (final CSVParser parser = CSVParser.parse(path, Charset.defaultCharset(), null)) {\n            checkRecords(parser);\n        }\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.5,
      "callable_precision": 0.5,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9848,
      "line_coverage": 0.9741,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 2,
          "run_shell_command": 2,
          "read_file": 3
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 161529,
    "output_tokens": 2954,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 124,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data formatting rule with a line break character as the value separator, ensuring that format configuration adheres to fundamental structural constraints by preventing malformed delimiter settings. Begin by establishing a baseline formatting configuration representing the standard comma-separated format, then attempt to modify this configuration by specifying a line feed character as the delimiter instead of a conventional separator like a comma or semicolon, and confirm that the system immediately halts this operation by raising a validation error indicating the delimiter choice violates formatting rules. This validation ensures that data formatting configurations maintain structural integrity by disallowing separators that would conflict with record boundaries, protecting downstream processing from ambiguous or unparsable data structures. Verify the rejection behavior using standard equality assertions within the JUnit 5 testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.DisallowLineBreakAsDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\n/**\n * This test case validates that the CSVFormat configuration rejects line break characters as delimiters.\n */\npublic class DisallowLineBreakAsDelimiterTest {\n\n    /**\n     * Tests that configuring a CSVFormat with a line feed ('\n') or carriage return ('\n') as a delimiter\n     * throws an IllegalArgumentException. This ensures the structural integrity of the CSV format by preventing\n     * delimiters that would conflict with record separators.\n     */\n    @Test\n    public void testRejectsLineBreakCharactersAsDelimiter() {\n        // Start with a standard CSV format configuration\n        final CSVFormat standardFormat = CSVFormat.DEFAULT;\n\n        // Verify that attempting to set the delimiter to a line feed character is rejected\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            standardFormat.withDelimiter('\\n');\n        }, \"Setting delimiter to line feed should throw IllegalArgumentException\");\n\n        // Verify that attempting to set the delimiter to a carriage return character is also rejected\n        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n            standardFormat.withDelimiter('\\r');\n        }, \"Setting delimiter to carriage return should throw IllegalArgumentException\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 0.25,
      "callable_precision": 0.25,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 128,
      "description": "Create a test case to validate the system's ability to process structured data files when no specific formatting rules are provided, ensuring the system applies sensible defaults and successfully extracts all records. Begin by locating a pre-existing sample data file within the test resources that contains structured tabular information, then configure the system to read this file using the platform's default character encoding while explicitly indicating that no custom formatting rules should be applied, which should cause the system to automatically apply standard default formatting conventions. Once the data reader is initialized, instruct the system to process the entire file by iterating through each record and confirming that every extracted record contains valid information without encountering any parsing failures or empty results. After confirming successful extraction of all records, ensure the system properly releases the file handle and any associated resources to prevent resource leaks. The test should use JUnit 5 as the testing framework and verify successful record extraction using standard equality assertions that confirm each record is properly populated.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.DefaultParserTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.util.Arrays;\nimport java.util.List;\nimport org.junit.jupiter.api.Test;\n\n/**\n * A simple test case for the CSVParser that validates parsing of a default CSV file.\n */\npublic class DefaultParserTest {\n\n    @Test\n    public void testDefaultParsing() throws IOException {\n        final File testFile = new File(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n        final CSVFormat format = CSVFormat.DEFAULT;\n\n        try (final CSVParser parser = CSVParser.parse(testFile, Charset.defaultCharset(), format)) {\n            final List<CSVRecord> records = parser.getRecords();\n            assertNotNull(records);\n            assertEquals(6, records.size());\n\n            final CSVRecord firstRecord = records.get(0);\n            assertEquals(Arrays.asList(\"A\", \"B\", \"C\", \"D\"), firstRecord.toList());\n\n            final CSVRecord fourthRecord = records.get(3);\n            assertEquals(Arrays.asList(\" i \", \" j \", \" k \", \" l \"), fourthRecord.toList());\n\n            for (final CSVRecord record : records) {\n                assertNotNull(record);\n            }\n        }\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.2857,
      "callable_precision": 0.125,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 56140,
    "output_tokens": 3334,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 129,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, and begin by opening a try-with-resources block that first invokes `Files.newInputStream` passing the result of `Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\")` to obtain an `InputStream` assigned to variable `in`, then immediately invoke the static method `CSVParser.parse` passing three arguments\u2014`in`, the result of `Charset.defaultCharset()`, and the literal `null`\u2014assigning the returned `CSVParser` to variable `parser`. Within the try block body, invoke the `forEach` method on `parser` passing a method reference `Assertions::assertNotNull` to iterate over all records and assert each is non-null. Upon exiting the try-with-resources block, both `in` and `parser` are automatically closed. The test uses JUnit 5 Assertions for verification, with method-level annotation `@Test` and no class-level annotations.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParseInputStreamCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserParseTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\npublic class CSVParserParseTest {\n\n    @Test\n    public void testParse() throws IOException {\n        try (InputStream in = Files.newInputStream(Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\"));\n             CSVParser parser = CSVParser.parse(in, Charset.defaultCharset(), CSVFormat.DEFAULT)) {\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParseInputStreamCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.8571,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9846,
      "line_coverage": 0.9739,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 14153,
    "output_tokens": 3283,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 132,
      "description": "Define a test method that declares a `Path` variable named `path` by invoking `Paths.get` with the String literal `\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\"`, then open a try-with-resources block that declares a `CSVParser` variable named `parser` by invoking the static method `CSVParser.parse` with three arguments: the `path` variable, the result of calling `Charset.defaultCharset()`, and the literal `null` for the format parameter (which maps to the default format), and within the try block, iterate over each record in the `parser` by invoking `forEach` on it with a method reference `Assertions::assertNotNull` to verify that every record produced is non-null, ensuring the parser processes the file completely despite the null format argument, and finally allow the try-with-resources to automatically close the parser upon block exit. The test uses `@Test` as the method-level annotation, AssertJ or JUnit 5 Assertions for the assertion library, and throws `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserNullFormatTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport org.junit.jupiter.api.Assertions;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVParser} when parsing with a null format.\n */\npublic class CSVParserNullFormatTest {\n\n    @Test\n    public void testParseWithNullFormat() throws IOException {\n        final Path path = Paths.get(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n        try (final CSVParser parser = CSVParser.parse(path, Charset.defaultCharset(), null)) {\n            parser.forEach(Assertions::assertNotNull);\n        }\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6667,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9848,
      "line_coverage": 0.9741,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 29411,
    "output_tokens": 1705,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 136,
      "description": "Create a test case to validate that the CSV parsing system correctly handles scenarios where no explicit formatting rules are provided by the user, ensuring the system applies its standard default processing behavior when interpreting structured data files. Establish a scenario where a CSV data file containing tabular information exists at a known location within the system's test resources, then initiate a parsing operation against this file using the platform's default character encoding while explicitly omitting any custom formatting configuration, which signals the system to fall back to its built-in default parsing rules. Once the parsing session is active, verify the system successfully processes the entire contents of the file by consuming all available records from beginning to end, confirming that each record is properly recognized and accessible without encountering errors or incomplete data extraction. After confirming complete data consumption, release the parsing session to free system resources. Validate this behavior using JUnit 5 as the testing framework with standard equality assertions to confirm successful record processing throughout the parsing lifecycle.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testParsePathCharsetNullFormat()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.DefaultParserTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for default CSV parsing behavior.\n */\npublic class DefaultParserTest {\n\n    @Test\n    public void testDefaultParsing() throws IOException {\n        final File csvFile = new File(\"src/test/resources/org/apache/commons/csv/CSVFileParser/test.csv\");\n\n        try (final CSVParser parser = CSVParser.parse(csvFile, StandardCharsets.UTF_8, CSVFormat.DEFAULT)) {\n            final List<CSVRecord> records = parser.getRecords();\n            // Verifies that all records are consumed from the file.\n            assertEquals(3, records.size());\n        }\n    }\n}",
      "method_signature": "testParsePathCharsetNullFormat()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.1667,
      "callable_precision": 0.2,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 13476,
    "output_tokens": 2728,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 139,
      "description": "Create a test case to validate that the system rejects attempts to configure a data format with a carriage return character as the field separator, since this character is reserved for line breaks and would conflict with proper record parsing. Begin by accessing the standard default format configuration and instruct the configuration system to apply a carriage return character as the delimiter, then attempt to finalize this configuration. Ensure the system immediately fails this operation by raising a validation error indicating the configuration is invalid, confirming that the business rule preventing line break characters from serving as field delimiters is properly enforced. Verify using JUnit 5 with standard exception assertion capabilities to confirm the expected validation failure occurs.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatTest1",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat}.\n */\npublic class CSVFormatTest1 {\n\n    @Test\n    public void testWithDelimiterThrowsOnCarriageReturn() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.withDelimiter('\\r');\n        });\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.3333,
      "callable_precision": 0.5,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 5316,
    "output_tokens": 8297,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 141,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then assign the constant `CSVFormat.POSTGRESQL_CSV` to a variable named `csvFormat` of type `CSVFormat`. Open a try-with-resources statement that first creates a `BufferedReader` named `reader` by invoking `Files.newBufferedReader` with arguments `Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\")` and `StandardCharsets.UTF_8`, then within the same try-with-resources block create a `CSVParser` named `parser` by invoking `csvFormat.parse(reader)`. Inside the try block, obtain an `Iterator<CSVRecord>` named `csvRecords` by calling `parser.iterator()`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then iterates through the array indices and for each index retrieves the corresponding value from the record using `get(i)`, comparing the array element to the record value with appropriate null-handling logic (if the array element is null, assert the record value is null; otherwise assert equality), and invoke this private method three times in sequence: first with a new `String[]` containing `\"AA\"`, `\"33\"`, and `null`, passing `csvRecords.next()` as the second argument; second with a new `String[]` containing `\"AA\"`, `null`, and `\"\"` (empty string), passing `csvRecords.next()` as the second argument; and third with a new `String[]` containing `null`, `\"33\"`, and `\"CC\"`, passing `csvRecords.next()` as the second argument. The try-with-resources construct automatically closes both `parser` and `reader` upon completion. The test uses the `@Test` annotation from JUnit 5, and the assertion logic within the private helper method should use either JUnit 5 Assertions (`assertEquals`, `assertNull`) or AssertJ (`assertThat`) to verify value equality and null conditions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.Csv254Test",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertNull;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.Iterator;\n\nimport org.junit.jupiter.api.Test;\n\npublic class Csv254Test {\n\n    private void assertRecord(final String[] expected, final CSVRecord record) {\n        for (int i = 0; i < expected.length; i++) {\n            final String expectedValue = expected[i];\n            final String actualValue = record.get(i);\n            if (expectedValue == null) {\n                assertNull(actualValue);\n            } else {\n                assertEquals(expectedValue, actualValue);\n            }\n        }\n    }\n\n    @Test\n    public void testPostgresqlCsv() throws IOException {\n        final CSVFormat csvFormat = CSVFormat.POSTGRESQL_CSV;\n        try (final BufferedReader reader = Files.newBufferedReader(Paths.get(\"src/test/resources/org/apache/commons/csv/CSV-254/csv-254.csv\"),\n                StandardCharsets.UTF_8);\n                final CSVParser parser = csvFormat.parse(reader)) {\n            final Iterator<CSVRecord> csvRecords = parser.iterator();\n            assertRecord(new String[] { \"AA\", \"33\", null }, csvRecords.next());\n            assertRecord(new String[] { \"AA\", null, \"\" }, csvRecords.next());\n            assertRecord(new String[] { null, \"33\", \"CC\" }, csvRecords.next());\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.7,
      "callable_precision": 0.3684,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9844,
      "line_coverage": 0.9965,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 26364,
    "output_tokens": 1816,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 144,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by constructing a builder from the default CSV format, configuring it with a carriage return character as the delimiter, and verifying that invoking the builder's get method to finalize the format throws an IllegalArgumentException, confirming that line break characters are properly rejected as delimiters during format construction, using a standard assertion framework for exception validation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "",
      "code": "",
      "method_signature": null
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": true
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 154,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format's builder factory, then configure the builder by invoking its delimiter setter with a string representation of the carriage return constant. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that line break characters are rejected as delimiters. This test uses JUnit 5 for the test framework and its assertion mechanism.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat.Builder} delimiter validation.\n */\npublic class CSVFormatBuilderDelimiterTest {\n\n    @Test\n    public void testInvalidDelimiterThrowsIllegalArgumentException() {\n        final CSVFormat.Builder builder = CSVFormat.DEFAULT.builder();\n        builder.setDelimiter(Constants.CR);\n        assertThrows(IllegalArgumentException.class, builder::build, \"Line break characters are not allowed as delimiters\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.75,
      "callable_precision": 0.75,
      "focal_recall": 0.3333,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 24622,
    "output_tokens": 5265,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 158,
      "description": "Define a test method that validates the CSV Format Builder's delimiter validation logic by attempting to configure a format with an invalid delimiter character. Obtain a builder instance from the default CSV format, then configure the builder to use a line feed character as the delimiter. Upon invoking the builder's get method to construct the format instance, verify that an IllegalArgumentException is thrown, confirming that the builder rejects line break characters as delimiters. This test uses JUnit 5 for test execution and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat.Builder}.\n */\npublic class CSVFormatBuilderTest {\n\n    /**\n     * Validates that the builder rejects line break characters as delimiters.\n     */\n    @Test\n    public void testSetDelimiterWithInvalidCharacter() {\n        final CSVFormat.Builder builder = CSVFormat.DEFAULT.builder();\n        assertThrows(IllegalArgumentException.class, () -> builder.setDelimiter('\n'));\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 32980,
    "output_tokens": 3184,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 162,
      "description": "Create a test case to validate that the system rejects an attempt to configure a data format with a line feed character as the value separator by confirming the operation fails due to invalid configuration, starting from the standard comma-separated format configuration, then attempting to reconfigure it with a line feed character as the delimiter, and verifying the system raises an error indicating the configuration is not permitted since line breaks cannot serve as field separators, using JUnit 5 for test execution and standard assertion capabilities to confirm the expected failure occurs when finalizing the invalid configuration.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatConfigurationTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat}.\n */\npublic class CSVFormatConfigurationTest {\n\n    @Test\n    public void testWithDelimiterLFNotAllowed() {\n        final IllegalArgumentException e = assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter('\\n').get();\n        });\n        assertEquals(\"The delimiter cannot be a line break\", e.getMessage());\n    }\n\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.5,
      "callable_recall": 1.0,
      "callable_precision": 0.5,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 0.25,
      "method_coverage": 0.2727,
      "line_coverage": 0.1546,
      "branch_coverage": 0.2
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "run_shell_command": 1,
          "read_file": 2,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 165,
      "description": "Create a test to validate that the system properly rejects an attempt to configure a format specification with a carriage return character as the delimiter, which is a business rule violation since line-breaking characters are not permitted as value separators to ensure proper record parsing. Begin by establishing a baseline format configuration using the standard default settings, then attempt to modify this configuration by specifying a carriage return character as the delimiter through the configuration builder, and verify that the system immediately prevents the finalization of this invalid configuration by raising a validation error indicating an illegal argument, thereby ensuring data integrity and preventing malformed output files. The test uses JUnit 5 as the testing framework and verifies the expected failure condition using standard exception assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatInvalidDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Validates that configuring a CSV format with a line-breaking character as a\n * delimiter is properly rejected.\n */\npublic class CSVFormatInvalidDelimiterTest {\n\n    /**\n     * Tests that an {@link IllegalArgumentException} is thrown when a carriage\n     * return character is specified as the delimiter, as this is an invalid\n     * configuration that would produce malformed CSV data.\n     */\n    @Test\n    public void testRejectCarriageReturnAsDelimiter() {\n        final CSVFormat format = CSVFormat.DEFAULT;\n\n        assertThrows(IllegalArgumentException.class, () -> {\n            format.withDelimiter('\n');\n        }, \"A carriage return is not a valid delimiter and should be rejected.\");\n    }\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 3,
          "run_shell_command": 5,
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 290284,
    "output_tokens": 5519,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 166,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format with a carriage return character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument. Within the lambda, access the static field `DEFAULT` on `CSVFormat`, then chain a call to `builder()` which returns a `CSVFormat.Builder` instance. On this builder, chain `setDelimiter` passing the constant `Constants.CR` (representing the carriage return character `'\\r'`) as the argument, which returns the same builder instance. Finally, chain `get()` on the builder to construct the `CSVFormat` instance, which should trigger the exception due to the invalid delimiter. The test uses JUnit 5 Assertions via `assertThrows`, and the method-level annotation is `@Test` with no class-level annotations present.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\n/**\n * Tests for {@link CSVFormat.Builder}.\n */\npublic class CSVFormatBuilderTest {\n\n    @Test\n    public void testSetDelimiterWithCarriageReturn() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(Constants.CR).get();\n        });\n    }\n}",
      "method_signature": "testDelimiterCharLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.75,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 29353,
    "output_tokens": 1591,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 176,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a delimiter string containing a carriage return line break character, beginning by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument, where the lambda executes the following chain: invoke the static method `builder()` on `CSVFormat.DEFAULT` to obtain a `CSVFormat.Builder` instance, then chain `setDelimiter` on that builder passing the result of `String.valueOf(Constants.CR)` as the argument (where `Constants.CR` represents the carriage return character `'\\r'`), and finally chain `get()` on the builder to trigger the format construction and validation, with the entire lambda expression serving as the executable that `assertThrows` will invoke to confirm the exception is raised during the `get()` call when the delimiter validation detects the line break character. The test uses JUnit 5 Assertions with method-level annotation `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat.Builder}.\n */\nclass CSVFormatBuilderTest {\n\n    @Test\n    void testSetDelimiterWithCarriageReturnThrowsIllegalArgumentException() {\n        assertThrows(IllegalArgumentException.class, () -> {\n            CSVFormat.DEFAULT.builder().setDelimiter(String.valueOf(Constants.CR)).get();\n        });\n    }\n\n}",
      "method_signature": "testDelimiterStringLineBreakCrThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 0.8,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 2,
          "run_shell_command": 3,
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 76416,
    "output_tokens": 1621,
    "llm_calls": 0,
    "failed_test_file_generation": true,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 177,
      "description": "Create a test case to validate that the system can successfully parse structured data when configured with a specific processing format that uses the first character of a predefined input string as the field separator and enables whitespace trimming around values, ensuring the parser initializes correctly and releases all system resources properly afterward, verifying this scenario using JUnit 5 with standard try-with-resources pattern for automatic resource cleanup without requiring explicit assertions since the test confirms successful initialization and teardown through exception-free execution.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserResourceHandlingTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests the initialization and resource handling of the CSVParser.\n */\npublic class CSVParserResourceHandlingTest {\n\n    /**\n     * This test case validates that the CSVParser can be successfully initialized with a custom CSVFormat\n     * and that all underlying resources are properly released.\n     *\n     * The test configures the parser to use a specific delimiter from a predefined string and to trim\n     * whitespace. The core of the test is the use of a try-with-resources statement, which ensures that\n     * the parser's close() method is automatically invoked.\n     *\n     * Successful execution of this test, marked by the absence of any exceptions, confirms that the\n     * parser initializes correctly and that its resources are cleaned up afterward, fulfilling the\n     * contract of the AutoCloseable interface.\n     *\n     * @throws IOException if an I/O error occurs, though none is expected in this test.\n     */\n    @Test\n    public void testParserInitializationAndResourceCleanup() throws IOException {\n        final String inputData = \"  value1 |  value2  \";\n        final String delimiterString = \"|\";\n\n        final CSVFormat format = CSVFormat.DEFAULT.builder()\n                .setDelimiter(delimiterString.charAt(0))\n                .setTrim(true)\n                .build();\n\n        try (final CSVParser parser = new CSVParser(new StringReader(inputData), format)) {\n            // Initialization and automatic resource cleanup via try-with-resources is the focus of this test.\n            // A successful run with no exceptions thrown is the validation.\n        }\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5,
      "callable_precision": 0.4286,
      "focal_recall": 0.4,
      "focal_precision": 0.5
    },
    "coverage_eval": {
      "class_coverage": 0.625,
      "method_coverage": 0.6857,
      "line_coverage": 0.4762,
      "branch_coverage": 0.7273
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 12832,
    "output_tokens": 2184,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 181,
      "description": "Define a test method annotated with `@Test` that verifies an `IllegalArgumentException` is thrown when attempting to configure a CSV format builder with a line feed character as the delimiter. Begin by invoking `assertThrows` with `IllegalArgumentException.class` as the first argument and a lambda expression as the second argument that executes the following sequence: access the static field `CSVFormat.DEFAULT`, invoke `builder()` on it to obtain a `CSVFormat.Builder` instance, chain `setDelimiter(Constants.LF)` on that builder (where `Constants.LF` is a character constant representing the line feed character `'\\n'`), and finally chain `get()` to trigger the builder's validation logic that should throw the exception due to the invalid delimiter. The test uses JUnit 5's `assertThrows` assertion method to verify that the exact exception type is thrown during the builder's `get()` invocation. Class-level annotations: none. Method-level annotations: `@Test`. Assertion library: JUnit 5 Assertions. Mocking library: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVFormatTest",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat.Builder}.\n */\nclass CSVFormatBuilderTest {\n\n    @Test\n    void testSetDelimiterWithLFThrowsIllegalArgumentException() {\n        assertThrows(IllegalArgumentException.class, () -> CSVFormat.DEFAULT.builder().setDelimiter(Constants.LF).get());\n    }\n\n}",
      "method_signature": "testDelimiterCharLineBreakLfThrowsException1()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 24429,
    "output_tokens": 1412,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 192,
      "description": "Define a test method that validates the CSV parsing functionality when configuring a format through the builder pattern without specifying a header. Begin by retrieving the first character from the input string to serve as the delimiter character. Construct a CSV format by obtaining a builder from the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character and enabling the ignore surrounding spaces option before finalizing the format instance. With the configured format established, instantiate a CSV parser by invoking the static parse method with the input string and the constructed format, utilizing a try-with-resources block to ensure proper resource cleanup. The parser instance is created but not actively used within the test scope, as the test's purpose is to verify that the format configuration and parser instantiation complete without throwing exceptions when no explicit header is defined. Upon exiting the try-with-resources block, the parser is automatically closed, releasing any associated resources. This test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat#builder()} without a header.\n */\npublic class CSVFormatBuilderTest {\n\n    @Test\n    public void testBuilderWithoutHeader() throws IOException {\n        final String input = \"a,b,c\";\n        final char delimiter = input.charAt(0);\n        final CSVFormat format = CSVFormat.RFC4180.builder()\n                .withDelimiter(delimiter)\n                .withIgnoreSurroundingSpaces(true)\n                .build();\n        try (final CSVParser parser = CSVParser.parse(input, format)) {\n            // The parser is not used, the test is for format configuration and parser instantiation.\n        }\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 13278,
    "output_tokens": 2512,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 199,
      "description": "Define a test method that validates the parser's behavior when encountering a CSV input with a missing header name by configuring a CSV format builder starting from the RFC4180 preset, then extracting the first character from a predefined input string to set as the delimiter, followed by enabling first-record-as-header mode and activating surrounding space trimming to complete the format configuration. With the format constructed, wrap the input string in a string reader and attempt to instantiate a CSV parser using this reader and format within a try-with-resources block that immediately closes the parser without performing any operations. Assert that this instantiation attempt throws an IllegalArgumentException, confirming that the parser correctly rejects CSV data where header column names are missing or malformed when the format expects the first record to define headers. This test uses JUnit for the test framework and assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMissingHeaderTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVParser} when dealing with missing header names.\n */\npublic class CSVParserMissingHeaderTest {\n\n    @Test\n    public void testMissingHeaderNameThrowsIllegalArgumentException() {\n        final String input = \",header2\\r\\nvalue1,value2\\r\\n\";\n        final CSVFormat.Builder formatBuilder = CSVFormat.Builder.create(CSVFormat.RFC4180);\n        formatBuilder.setDelimiter(input.charAt(0));\n        formatBuilder.setSkipHeaderRecord(true);\n        formatBuilder.setTrim(true);\n        final CSVFormat format = formatBuilder.build();\n\n        assertThrows(IllegalArgumentException.class, () -> {\n            try (final CSVParser parser = new CSVParser(new StringReader(input), format)) {\n                // The exception should be thrown by the constructor.\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5714,
      "callable_precision": 0.4444,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.8333,
      "method_coverage": 0.3818,
      "line_coverage": 0.4874,
      "branch_coverage": 0.2632
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 200,
      "description": "Define a test class containing a private static final field `INPUT` of type `String`, then write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on the static field `CSVFormat.RFC4180`, which returns a `CSVFormat.Builder` instance, then immediately chain `setDelimiter(char)` passing the character obtained by calling `charAt(0)` on the `INPUT` field, chain `setIgnoreSurroundingSpaces(true)` to enable trimming behavior, and finally chain `get()` to build the format, assigning the resulting `CSVFormat` instance to a local variable named `format`. Next, open a try-with-resources block by invoking the static method `parse(String, CSVFormat)` on `CSVParser`, passing `INPUT` as the first argument and `format` as the second argument, assigning the returned `CSVParser` instance to a resource variable named `parser`, and leave the try block body empty to allow automatic resource closure without performing any parsing operations. The test uses class-level annotation `@Test`, method-level annotation `@Test`, assertion libraries none, and mocking libraries none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testNoHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserBuildTest",
      "code": "package org.apache.commons.csv;\n\nimport java.io.IOException;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Test for {@link CSVParser} on build.\n */\npublic class CSVParserBuildTest {\n\n    private static final String INPUT = \",\";\n\n    @Test\n    public void test() throws IOException {\n        final CSVFormat format = CSVFormat.RFC4180.builder().setDelimiter(INPUT.charAt(0)).setIgnoreSurroundingSpaces(true).get();\n        try (final CSVParser parser = CSVParser.parse(INPUT, format)) {\n            // empty\n        }\n    }\n}",
      "method_signature": "testNoHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 52365,
    "output_tokens": 4851,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 201,
      "description": "Create a test case to validate that the system correctly enforces the requirement for complete header information when processing structured data files where the first line serves as column definitions and surrounding whitespace should be trimmed from values. Configure the processing rules to expect the first record as the header definition while ignoring any extra spaces around field values, using a specific delimiter character extracted from a predefined input sample. Attempt to initialize the data processing mechanism with these configured rules applied to the sample input, ensuring the system properly detects when header column names are missing or incomplete. Verify that the system rejects such malformed input by raising an appropriate validation failure, confirming that incomplete header definitions are not silently accepted during initialization. Once the validation behavior is confirmed, release any resources allocated during the processing attempt. The test employs JUnit 5 as the testing framework and uses standard exception assertion capabilities to verify the system throws the expected validation error when encountering missing column names in the header record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVHeaderValidationTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport java.io.IOException;\nimport java.io.StringReader;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for header validation.\n */\npublic class CSVHeaderValidationTest {\n\n    @Test\n    public void testIncompleteHeaderThrowsException() {\n        final String input = \"ColumnA, ,ColumnC\\nValue1,Value2,Value3\";\n        final CSVFormat format = CSVFormat.DEFAULT.builder()\n                .setDelimiter(',')\n                .setTrim(true)\n                .setFirstRecordAsHeader(true)\n                .build();\n\n        final IllegalArgumentException e = assertThrows(IllegalArgumentException.class, () -> {\n            try (final CSVParser parser = new CSVParser(new StringReader(input), format)) {\n                // The exception should be thrown on initialization as the header is processed.\n            }\n        });\n\n        final String expectedMessage = \"The header contains a duplicate name: \\\"\\\" in [ColumnA, , ColumnC]\";\n        final String actualMessage = e.getMessage();\n        assert(actualMessage != null && actualMessage.contains(\"The header contains a duplicate name:\"));\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 211,
      "description": "Define a test method that declares a `private static final String` field named `INPUT` at the class level, then within the method body, begin by invoking `CSVFormat.RFC4180.withDelimiter(INPUT.charAt(0))` to obtain a `CSVFormat` instance, chain `.withFirstRecordAsHeader()` on the result, chain `.withIgnoreSurroundingSpaces()` on that result, and assign the final `CSVFormat` to a local variable named `format`. Next, invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that constructs a new `CSVParser` by passing `new StringReader(INPUT)` as the first argument and `format` as the second argument, assigning the parser to a variable named `parser`, with an empty body inside the try block. The test method is annotated with `@Test` and declares `throws IOException`. The test uses JUnit 5 Assertions for the `assertThrows` call.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderDepreacted()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatQuoteDelimiterTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport java.io.IOException;\nimport java.io.StringReader;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for invalid CSVFormat configurations that are detected by CSVParser.\n */\npublic class CSVFormatQuoteDelimiterTest {\n\n    private static final String INPUT = \"\"\";\n\n    @Test\n    public void testThrowsOnDuplicateDelimiterAndQuote() throws IOException {\n        final CSVFormat format = CSVFormat.RFC4180.withDelimiter(INPUT.charAt(0))\n                .withFirstRecordAsHeader()\n                .withIgnoreSurroundingSpaces();\n\n        assertThrows(IllegalArgumentException.class, () -> {\n            try (final CSVParser parser = new CSVParser(new StringReader(INPUT), format)) {\n                // empty\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderDepreacted()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 13382,
    "output_tokens": 2560,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 228,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates how the CSV Parser enforces this constraint when streaming records. Create a Reader from a CSV string containing three rows with comma-separated values (each row having three columns). Build a CSV Format instance by starting with the default format, invoking the builder to configure the maximum row limit using the provided parameter, and finalizing the format configuration. Parse the CSV input using the configured format within a try-with-resources block to ensure automatic parser closure. Stream the records from the parser, collect them into a list, and immediately assert that the list is not empty. Retrieve the first record from the list and validate its column values match the first row of the input data. If the maximum row parameter is less than or equal to zero or greater than one, retrieve the second record and validate its values against the second row. If the maximum row parameter is less than or equal to zero or greater than two, retrieve the third record and validate its values against the third row. Create a private helper method that compares a string array against the values of a CSV Record to support these validations. Upon exiting the try-with-resources block, the parser is automatically closed. Execute this test across multiple parameterized inputs including negative values, zero, small positive integers, and the maximum long value using JUnit 5's parameterized test support.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRowsTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertArrayEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertNotNull;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\n/**\n * Tests for {@link CSVParser} streaming with a maximum row limit.\n */\npublic class CSVParserMaxRowsTest {\n\n    private static final String CSV_INPUT = \"a,b,c\\r\\nd,e,f\\r\\ng,h,i\";\n    private static final String[] ROW_1 = { \"a\", \"b\", \"c\" };\n    private static final String[] ROW_2 = { \"d\", \"e\", \"f\" };\n    private static final String[] ROW_3 = { \"g\", \"h\", \"i\" };\n\n    /**\n     * Compares the values of a CSVRecord against a string array.\n     *\n     * @param expected The expected values.\n     * @param actual   The CSVRecord to validate.\n     */\n    private void assertRecord(final String[] expected, final CSVRecord actual) {\n        assertNotNull(actual);\n        assertArrayEquals(expected, actual.values());\n    }\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, Long.MAX_VALUE })\n    void testStreamingWithMaxRows(final long maxRows) throws IOException {\n        final Reader reader = new StringReader(CSV_INPUT);\n        final CSVFormat format = CSVFormat.DEFAULT.builder().setMaxRows(maxRows).build();\n\n        try (final CSVParser parser = format.parse(reader)) {\n            final List<CSVRecord> records = parser.stream().collect(Collectors.toList());\n\n            assertFalse(records.isEmpty(), \"The record list should not be empty.\");\n\n            // Row 1 is always expected\n            assertRecord(ROW_1, records.get(0));\n\n            // Row 2 is expected if maxRows is unlimited (<=0) or greater than 1\n            if (maxRows <= 0 || maxRows > 1) {\n                assertRecord(ROW_2, records.get(1));\n            }\n\n            // Row 3 is expected if maxRows is unlimited (<=0) or greater than 2\n            if (maxRows <= 0 || maxRows > 2) {\n                assertRecord(ROW_3, records.get(2));\n            }\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.1429,
      "callable_recall": 0.6875,
      "callable_precision": 0.44,
      "focal_recall": 0.8,
      "focal_precision": 0.8
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 0.9962,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 2,
          "run_shell_command": 2,
          "read_file": 2
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 230,
      "description": "Define a test method that validates the CSV Format Builder's behavior when constructing a format configuration with an empty header array followed by parsing malformed CSV input. Begin by retrieving the first character from a static input string to use as the delimiter character. Build a CSV format by invoking the builder method on the RFC4180 predefined format, then configure it by setting the delimiter to the extracted character, enabling automatic header detection with an empty header array, instructing the parser to skip the header record, and enabling the trimming of surrounding spaces before finalizing the format instance. With the configured format in hand, verify that attempting to parse the input string using the CSV Parser triggers a validation error due to missing header names by asserting that an IllegalArgumentException is thrown when the parser is instantiated within a try-with-resources block that immediately closes upon construction. This test uses JUnit 5 for the test framework and its assertion capabilities.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVFormatBuilderTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVFormat.Builder}.\n */\npublic class CSVFormatBuilderTest {\n\n    private static final String INPUT = \" \\n\";\n\n    @Test\n    public void testBuildWithEmptyHeaderAndMalformedInput() {\n        final char delimiter = INPUT.charAt(0);\n        final CSVFormat.Builder builder = CSVFormat.Builder.create(CSVFormat.RFC4180);\n        final CSVFormat format = builder.setDelimiter(delimiter)\n                .setHeader()\n                .setSkipHeaderRecord(true)\n                .setTrim(true)\n                .build();\n\n        assertThrows(IllegalArgumentException.class, () -> {\n            try (CSVParser parser = CSVParser.parse(INPUT, format)) {\n                // The parser is expected to throw an exception upon construction.\n            }\n        });\n    }\n}",
      "method_signature": "testHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6667,
      "callable_precision": 0.6667,
      "focal_recall": 0.5714,
      "focal_precision": 0.5714
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9818,
      "line_coverage": 0.9668,
      "branch_coverage": 0.9153
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 2,
          "run_shell_command": 2,
          "read_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 236,
      "description": "Create a test case to validate that the system correctly processes structured data from a text source while respecting a configurable limit on the number of rows to retrieve, ensuring the system behaves consistently across various limit configurations including unlimited processing, single-row retrieval, and specific row counts up to the maximum supported boundary. Prepare a text source containing three rows of comma-separated values with three columns each, representing a simple tabular dataset. Configure the data processing system to use standard comma-separated formatting, then apply a specified maximum row limit ranging from negative values and zero (representing no limit) through small positive integers to the largest possible numeric value. Initiate the data retrieval process by streaming the records from the configured source and collecting them into a list for validation. Verify that the system returned at least one row, then confirm the first row contains the expected values from the initial line of input. When the configured limit allows processing beyond the first row (either no limit or a limit greater than one), validate that the second row is present and contains the expected values from the second line of input. Similarly, when the limit permits processing all three rows (either no limit or a limit greater than two), ensure the third row is present and contains the expected values from the final line of input. Release the data processing resources after each validation cycle. Validate the behavior using JUnit 5 with parameterized test support to execute the scenario across multiple row limit values, employing AssertJ for verifying the presence of records and confirming the expected data values match the parsed output.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport java.io.IOException;\nimport java.util.List;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\n/**\n * Test for {@link CSVParser} with a configurable row limit.\n */\npublic class CSVParserLimitTest {\n\n    private static final String THREE_ROWS_CSV = \"r1c1,r1c2,r1c3\n\" +\n                                                 \"r2c1,r2c2,r2c3\n\" +\n                                                 \"r3c1,r3c2,r3c3\";\n\n    @ParameterizedTest\n    @ValueSource(longs = {-1, 0, 1, 2, 3, Long.MAX_VALUE})\n    void testLimit(final long limit) throws IOException {\n        final CSVFormat format = CSVFormat.DEFAULT.withLimit(limit);\n\n        try (final CSVParser parser = CSVParser.parse(THREE_ROWS_CSV, format)) {\n            final List<CSVRecord> records = parser.getRecords();\n\n            // As per the test description, a limit of <= 0 represents no limit.\n            final int expectedSize;\n            if (limit > 0 && limit < 3) {\n                expectedSize = (int) limit;\n            } else {\n                expectedSize = 3;\n            }\n            assertThat(records).hasSize(expectedSize);\n\n            // \"Verify that the system returned at least one row\"\n            if (expectedSize > 0) {\n                assertThat(records).isNotEmpty();\n                // \"confirm the first row contains the expected values\"\n                final CSVRecord row1 = records.get(0);\n                assertThat(row1).containsExactly(\"r1c1\", \"r1c2\", \"r1c3\");\n            }\n\n            // \"When the configured limit allows processing beyond the first row ... validate that the second row is present\"\n            if (expectedSize > 1) {\n                final CSVRecord row2 = records.get(1);\n                assertThat(row2).containsExactly(\"r2c1\", \"r2c2\", \"r2c3\");\n            }\n\n            // \"when the limit permits processing all three rows ... ensure the third row is present\"\n            if (expectedSize > 2) {\n                final CSVRecord row3 = records.get(2);\n                assertThat(row3).containsExactly(\"r3c1\", \"r3c2\", \"r3c3\");\n            }\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 15997,
    "output_tokens": 5015,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 240,
      "description": "Create a test case to validate that the system properly rejects malformed data when attempting to parse information with an improperly configured structure where column headers are expected but not provided, ensuring the system enforces data integrity rules by confirming that when a parser is set up to automatically detect column headers from the first row while simultaneously being instructed to skip that header row and to remove extra spaces around values, and this parser is then given input data to process, the system immediately detects the missing header information and refuses to proceed with the operation by signaling a validation failure, thus preventing the creation of corrupted or inconsistent data records. Configure the parsing behavior to use the first character from the test input as the value separator, enable automatic header detection without explicitly naming the columns, activate the setting to bypass the header row during processing, and apply trimming of surrounding whitespace, then attempt to initiate the parsing operation with the provided input data and verify that the system blocks this action by raising an appropriate validation error indicating that required header information is absent. Verify the expected system behavior using JUnit 5 for test execution and standard equality assertions to confirm the validation failure occurs as intended.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.MalformedHeaderHandlingTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * This test validates that the CSV parsing system correctly rejects a malformed\n * configuration where headers are expected but cannot be read.\n */\npublic class MalformedHeaderHandlingTest {\n\n    /**\n     * This test case ensures that when a CSV parser is configured to both\n     * automatically detect headers from the first data row and simultaneously skip\n     * that same header row, the system identifies this logical conflict and\n     * throws an {@link IllegalArgumentException}. This prevents data corruption\n     * by enforcing that the header source is accessible. The test configures the\n     * parser to use a specific delimiter from the input, enables header\n     * auto-detection, and sets the skip-header-row flag to true. It then\n     * confirms that attempting to parse data with this setup results in the\n     * expected validation error.\n     */\n    @Test\n    public void testRejectsConflictingHeaderConfiguration() {\n        final String csvData = \",Header1,Header2\nValue1,Value2,Value3\";\n\n        // Create a CSVFormat configuration that is logically invalid:\n        // - It's told to use the first record as the header source (withHeader()).\n        // - It's also told to skip the first record (withSkipHeaderRecord(true)).\n        final CSVFormat format = CSVFormat.DEFAULT\n                .withDelimiter(csvData.charAt(0))\n                .withHeader()\n                .withSkipHeaderRecord(true)\n                .withTrim(true);\n\n        // Assert that attempting to parse with this configuration throws an\n        // IllegalArgumentException because the parser cannot skip a record it\n        // needs to read for header information.\n        final IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -> {\n            CSVParser.parse(csvData, format);\n        });\n        \n        // Further validate that the exception message clearly states the reason for failure.\n        final String expectedMessage = \"The header record cannot be skipped because it is being used to define the headers.\";\n        assertEquals(expectedMessage, exception.getMessage());\n    }\n}",
      "method_signature": "testHeaderBuilder()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 18200,
    "output_tokens": 7378,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 241,
      "description": "Define a test class containing a private static final String field named `INPUT` and write a test method annotated with `@Test` that declares it may throw `IOException`. Begin by invoking `builder()` on `CSVFormat.RFC4180`, then chain `setDelimiter(INPUT.charAt(0))` (passing the character at index `0` of the `INPUT` string), chain `setHeader()` with no arguments, chain `setSkipHeaderRecord(true)`, chain `setIgnoreSurroundingSpaces(true)`, and finally chain `get()` to obtain a `CSVFormat` instance, assigning the result to a local variable named `format`. Immediately invoke `assertThrows(IllegalArgumentException.class, () -> { ... })` where the lambda body contains a try-with-resources statement that invokes `CSVParser.parse(INPUT, format)` (passing the `INPUT` string literal and the `format` variable), assigns the result to a variable named `parser` of type `CSVParser`, and leaves the try block body empty (no operations performed with `parser`), thereby verifying that parsing the input with the configured format throws an `IllegalArgumentException` due to a missing header name. The test uses JUnit 5 Assertions via the `assertThrows` method and is annotated with `@Test`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv257Test",
      "method_signature": "testHeaderBuilder()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "",
      "code": "",
      "method_signature": null
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 10916,
    "output_tokens": 812,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": true
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 246,
      "description": "Define a parameterized test method accepting a `long` parameter named `maxRows` annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that declares it may throw `Exception`. Begin by creating a `Reader` instance named `in` by instantiating a `StringReader` with the exact String literal `\"a,b,c\\n1,2,3\\nx,y,z\"`. Open a try-with-resources block declaring a `CSVParser` variable named `parser` initialized by invoking `CSVFormat.DEFAULT.builder()`, chaining `.setMaxRows(maxRows)`, chaining `.get()`, and finally invoking `.parse(in)` with the reader. Within the try block, declare a `List<CSVRecord>` variable named `list` and assign it the result of invoking `parser.stream()` followed by `.collect(Collectors.toList())`. Immediately assert that `list` is not empty by invoking `assertFalse(list.isEmpty())`. Define a private method that accepts a `String[]` array and a `CSVRecord`, then verifies that the record's values match the array elements in order; invoke this method with a new `String[]` array containing `\"a\"`, `\"b\"`, `\"c\"` and `list.get(0)` as arguments. Next, check if `maxRows <= 0 || maxRows > 1` evaluates to true; if so, invoke the same verification method with a new `String[]` array containing `\"1\"`, `\"2\"`, `\"3\"` and `list.get(1)`. Then check if `maxRows <= 0 || maxRows > 2` evaluates to true; if so, invoke the verification method again with a new `String[]` array containing `\"x\"`, `\"y\"`, `\"z\"` and `list.get(2)`. The try-with-resources block automatically closes the parser upon exit. The test uses JUnit 5 Assertions (`assertFalse`) and the `@ParameterizedTest` annotation with `@ValueSource` to supply test parameters.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testStreamMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserSetMaxRowsTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertArrayEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.Reader;\nimport java.io.StringReader;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\npublic class CSVParserSetMaxRowsTest {\n\n    private void assertRecord(final String[] expected, final CSVRecord record) {\n        assertArrayEquals(expected, record.values());\n    }\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    void testSetMaxRows(final long maxRows) throws Exception {\n        final Reader in = new StringReader(\"a,b,c\\n1,2,3\\nx,y,z\");\n        try (final CSVParser parser = CSVFormat.DEFAULT.builder().setMaxRows(maxRows).get().parse(in)) {\n            final List<CSVRecord> list = parser.stream().collect(Collectors.toList());\n            assertFalse(list.isEmpty());\n            assertRecord(new String[] { \"a\", \"b\", \"c\" }, list.get(0));\n            if (maxRows <= 0 || maxRows > 1) {\n                assertRecord(new String[] { \"1\", \"2\", \"3\" }, list.get(1));\n            }\n            if (maxRows <= 0 || maxRows > 2) {\n                assertRecord(new String[] { \"x\", \"y\", \"z\" }, list.get(2));\n            }\n        }\n    }\n}",
      "method_signature": "testStreamMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.25,
      "callable_recall": 0.8125,
      "callable_precision": 0.5909,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 256,
      "description": "Create a validation scenario to ensure the system correctly handles requests to process a specific maximum number of records from structured data input, testing the system's ability to respect configurable row limits across various threshold values including edge cases such as unlimited processing, single-record processing, and processing beyond the available data set. Begin by preparing a predefined set of structured records representing typical business data entries. For each tested row limit value (ranging from values indicating no limit, to processing one record, several records, or the maximum possible number), configure the data processing system to ignore surrounding whitespace and apply the specified row limit, then initiate processing of the structured input. After processing completes, verify that the system produced exactly the expected number of records based on the configured limit, ensuring that when the limit is set to zero or a negative value the system processes all available records, when the limit exceeds the available data the system processes only the existing records, and when a specific positive limit is provided the system processes exactly that many records without exceeding the threshold. For each processed record, confirm that the system correctly extracted and preserved the business values from the corresponding input row, ensuring data integrity across all scenarios. Once validation is complete, release the processing resources to maintain system efficiency. Validate the outcomes using JUnit 5 as the testing framework with AssertJ for fluent equality assertions to confirm record counts and data accuracy.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVRecordLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport java.io.IOException;\nimport java.util.List;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Create a validation scenario to ensure the system correctly handles requests to process a specific maximum number of\n * records from structured data input, testing the system's ability to respect configurable row limits across various\n * threshold values including edge cases such as unlimited processing, single-record processing, and processing beyond\n * the available data set.\n */\npublic class CSVRecordLimitTest {\n\n    private static final String BUSINESS_DATA_ENTRIES = \"col1,col2\n\" + \"val1,val2\n\" + \" val3, val4 \n\" + \"val5,val6\";\n\n    /**\n     * For each tested row limit value (ranging from values indicating no limit, to processing one record, several\n     * records, or the maximum possible number), configure the data processing system to ignore surrounding whitespace\n     * and apply the specified row limit, then initiate processing of the structured input.\n     * <p>\n     * After processing completes, verify that the system produced exactly the expected number of records based on the\n     * configured limit, ensuring that when the limit is set to zero or a negative value the system processes all\n     * available records, when the limit exceeds the available data the system processes only the existing records, and\n     * when a specific positive limit is provided the system processes exactly that many records without exceeding the\n     * threshold.\n     * </p>\n     * <p>\n     * For each processed record, confirm that the system correctly extracted and preserved the business values from the\n     * corresponding input row, ensuring data integrity across all scenarios. Once validation is complete, release the\n     * processing resources to maintain system efficiency.\n     * </p>\n     * <p>\n     * Validate the outcomes using JUnit 5 as the testing framework with AssertJ for fluent equality assertions to\n     * confirm record counts and data accuracy.\n     * </p>\n     *\n     * @throws IOException\n     */\n    @Test\n    void testRespectsConfigurableRowLimits() throws IOException {\n        // Scenario: Unlimited processing for negative limit value.\n        CSVFormat formatUnlimitedNegative = CSVFormat.DEFAULT.withHeader().withIgnoreSurroundingSpaces(true).withLimit(-1);\n        try (CSVParser parser = CSVParser.parse(BUSINESS_DATA_ENTRIES, formatUnlimitedNegative)) {\n            List<CSVRecord> records = parser.getRecords();\n            assertThat(records).hasSize(3);\n            assertThat(records.get(2).get(\"col1\")).isEqualTo(\"val5\");\n        }\n\n        // Scenario: Unlimited processing for zero limit value.\n        CSVFormat formatUnlimitedZero = CSVFormat.DEFAULT.withHeader().withIgnoreSurroundingSpaces(true).withLimit(0);\n        try (CSVParser parser = CSVParser.parse(BUSINESS_DATA_ENTRIES, formatUnlimitedZero)) {\n            List<CSVRecord> records = parser.getRecords();\n            assertThat(records).hasSize(3);\n            assertThat(records.get(2).get(\"col1\")).isEqualTo(\"val5\");\n        }\n\n        // Scenario: Single-record processing.\n        CSVFormat formatSingle = CSVFormat.DEFAULT.withHeader().withIgnoreSurroundingSpaces(true).withLimit(1);\n        try (CSVParser parser = CSVParser.parse(BUSINESS_DATA_ENTRIES, formatSingle)) {\n            List<CSVRecord> records = parser.getRecords();\n            assertThat(records).hasSize(1);\n            assertThat(records.get(0).get(\"col1\")).isEqualTo(\"val1\");\n            assertThat(records.get(0).get(\"col2\")).isEqualTo(\"val2\");\n        }\n\n        // Scenario: Processing a subset of records.\n        CSVFormat formatSubset = CSVFormat.DEFAULT.withHeader().withIgnoreSurroundingSpaces(true).withLimit(2);\n        try (CSVParser parser = CSVParser.parse(BUSINESS_DATA_ENTRIES, formatSubset)) {\n            List<CSVRecord> records = parser.getRecords();\n            assertThat(records).hasSize(2);\n            // Verify data integrity of the second record.\n            assertThat(records.get(1).get(\"col1\")).isEqualTo(\"val3\");\n            assertThat(records.get(1).get(\"col2\")).isEqualTo(\"val4\");\n        }\n\n        // Scenario: Processing beyond the available data set.\n        CSVFormat formatBeyond = CSVFormat.DEFAULT.withHeader().withIgnoreSurroundingSpaces(true).withLimit(5);\n        try (CSVParser parser = CSVParser.parse(BUSINESS_DATA_ENTRIES, formatBeyond)) {\n            List<CSVRecord> records = parser.getRecords();\n            assertThat(records).hasSize(3);\n        }\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 20301,
    "output_tokens": 9385,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 265,
      "description": "Define a test method that accepts a long parameter representing the maximum row limit and validates the CSV Parser's row-limiting behavior across boundary conditions including negative values, zero, positive integers, and maximum long values. Configure a CSV Format Builder starting from the DEFAULT format, chaining calls to enable surrounding space trimming and to set the maximum row limit using the provided parameter value, then build the format instance. Instantiate a CSV Parser by invoking the static parse method with a predefined CSV input string and the configured format, ensuring the parser is managed within a try-with-resources block for automatic closure. Upon parser creation, invoke the getRecords method to retrieve all parsed records as a list. Calculate the expected record count by comparing the maximum row parameter against the length of a predefined result array, where non-positive values or values exceeding the array length should yield the full array length, otherwise the limit itself. Assert that the retrieved records list size matches the calculated expected length, then verify the list is not empty. Iterate through the expected number of records, and for each iteration index, invoke a helper method that validates the values of the record at that index against the corresponding row in the result array, ensuring field-level correctness across all processed records. The parser resource is automatically closed upon exiting the try-with-resources block. This test uses JUnit 5 for parameterized testing.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserLimitTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.IOException;\nimport java.util.List;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\n/**\n * Tests for CSV Parser's row-limiting behavior.\n */\npublic class CSVParserLimitTest {\n\n    private static final String CSV_INPUT = \" a, b ,c\\n 1 ,2,  3\\n x,y, z \";\n    private static final String[][] RESULT = { { \"a\", \"b\", \"c\" }, { \"1\", \"2\", \"3\" }, { \"x\", \"y\", \"z\" } };\n\n    private void validate(final CSVRecord record, final String[] expected) {\n        assertEquals(expected.length, record.size());\n        for (int i = 0; i < expected.length; i++) {\n            assertEquals(expected[i], record.get(i));\n        }\n    }\n\n    @ParameterizedTest\n    @ValueSource(longs = {-1, 0, 1, 2, 3, 4, Long.MAX_VALUE})\n    void testGetRecordsWithLimit(final long maxRows) throws IOException {\n        final CSVFormat.Builder formatBuilder = CSVFormat.Builder.create(CSVFormat.DEFAULT).setTrim(true);\n        formatBuilder.setRecordAutolimiting(maxRows);\n        final CSVFormat format = formatBuilder.build();\n\n        try (final CSVParser parser = CSVParser.parse(CSV_INPUT, format)) {\n            final List<CSVRecord> records = parser.getRecords();\n            final int expectedCount = maxRows > 0 ? (int) Math.min(maxRows, RESULT.length) : RESULT.length;\n\n            assertEquals(expectedCount, records.size());\n\n            if (expectedCount > 0) {\n                assertFalse(records.isEmpty());\n                for (int i = 0; i < expectedCount; i++) {\n                    validate(records.get(i), RESULT[i]);\n                }\n            }\n        }\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 27,
      "description": "Create a test case to validate the system's ability to export record data in CSV format when the data source provides values through a sequential processing stream rather than a pre-loaded collection, ensuring the output writer correctly handles streaming inputs and produces properly formatted comma-separated records with the expected line termination, then verify the generated output matches the standard CSV structure by examining the resulting text representation against established formatting rules using standard equality assertions with JUnit 5 and AssertJ.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.stream.Stream;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\n/**\n * Test for {@link CSVPrinter} streaming capabilities.\n */\npublic class CSVPrinterStreamTest {\n\n    @Test\n    public void testExportRecordsFromStream() throws IOException {\n        // Arrange\n        StringWriter writer = new StringWriter();\n        String[] header = {\"ID\", \"Name\", \"Value\"};\n        CSVFormat format = CSVFormat.DEFAULT.builder().setHeader(header).build();\n        Stream<Object[]> dataStream = Stream.of(\n            new Object[]{\"1\", \"First\", \"100\"},\n            new Object[]{\"2\", \"Second\", \"200\"},\n            new Object[]{\"3\", \"Third\", \"300\"}\n        );\n\n        String expectedOutput = \"ID,Name,Value\n\" +\n                                \"1,First,100\n\" +\n                                \"2,Second,200\n\" +\n                                \"3,Third,300\n\";\n\n        // Act\n        try (CSVPrinter printer = new CSVPrinter(writer, format)) {\n            printer.printRecords(dataStream);\n        }\n\n        String actualOutput = writer.toString();\n\n        // Assert\n        assertThat(actualOutput).isEqualTo(expectedOutput);\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 18487,
    "output_tokens": 1388,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 300,
      "description": "Define a test class containing a private static final field `EXCEL_WITH_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get()`, a private static final field `UTF_8` of type `Charset` initialized by calling `StandardCharsets.UTF_8`, a private static final field `UTF_8_NAME` of type `String` initialized by calling `UTF_8.name()`, a private static final field `CSV_INPUT` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_1` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `CSV_INPUT_2` of type `String` initialized with the literal `\"a,b,c\\r\\n1,2,3\\r\\nx,y,z\"`, a private static final field `RESULT` of type `String[][]` initialized with the two-dimensional array `{{\"a\", \"b\", \"c\"}, {\"1\", \"2\", \"3\"}, {\"x\", \"y\", \"z\"}}`, a private static final field `CSV_INPUT_NO_COMMENT` of type `String` initialized with the literal `\"A,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n\"`, a private static final field `CSV_INPUT_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# header comment\\r\\nA,B\\r\\n1,2\\r\\n# trailer comment\\r\\n\"`, a private static final field `CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT` of type `String` initialized with the literal `\"# multi-line\\r\\n# header comment\\r\\nA,B\\r\\n1,2\\r\\n# multi-line\\r\\n# trailer comment\\r\\n\"`, a private static final field `FORMAT_AUTO_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader().get()`, a private static final field `FORMAT_EXPLICIT_HEADER` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get()`, and a private static field `FORMAT_EXPLICIT_HEADER_NOSKIP` of type `CSVFormat` initialized by calling `CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").get()`. Write a parameterized test method annotated with `@ParameterizedTest` and `@ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })` that accepts a single parameter `maxRows` of type `long`. Within a try-with-resources block, invoke `CSVParser.parse` with arguments `CSV_INPUT` and the result of calling `CSVFormat.DEFAULT.builder().setIgnoreSurroundingSpaces(true).setMaxRows(maxRows).get()`, assigning the returned `CSVParser` to variable `parser`. Invoke `getRecords()` on `parser` and assign the returned `List<CSVRecord>` to variable `records`. Compute `expectedLength` of type `long` by evaluating the ternary expression `maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows`. Assert that `expectedLength` equals `records.size()` using `assertEquals(expectedLength, records.size())`. Assert that `records.isEmpty()` returns `false` using `assertFalse(records.isEmpty())`. Iterate from `i = 0` to `i < expectedLength` with increment `i++`, and within each iteration, define a private method that accepts `RESULT[i]` and `records.get(i)` and executes the exact logic of `assertValuesEquals`, then invoke that method with arguments `RESULT[i]` and `records.get(i)`. The test method declares that it throws `IOException`. The test uses JUnit 5 Assertions (`assertEquals`, `assertFalse`) and the parameterized test annotation `@ParameterizedTest` with `@ValueSource`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.CSVParserTest",
      "method_signature": "testGetRecordsMaxRows(long)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVParserMaxRowsTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertArrayEquals;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\n/**\n * Tests for {@link CSVParser} with {@link CSVFormat#withMaxRows(long)}.\n */\npublic class CSVParserMaxRowsTest {\n\n    private static final CSVFormat EXCEL_WITH_HEADER = CSVFormat.EXCEL.builder().setHeader(\"A\", \"B\", \"C\").get();\n    private static final Charset UTF_8 = StandardCharsets.UTF_8;\n    private static final String UTF_8_NAME = UTF_8.name();\n    private static final String CSV_INPUT = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String CSV_INPUT_1 = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String CSV_INPUT_2 = \"a,b,c\\r\\n1,2,3\\r\\nx,y,z\";\n    private static final String[][] RESULT = { { \"a\", \"b\", \"c\" }, { \"1\", \"2\", \"3\" }, { \"x\", \"y\", \"z\" } };\n    private static final String CSV_INPUT_NO_COMMENT = \"A,B\\r\\n1,2\\r\\n\";\n    private static final String CSV_INPUT_HEADER_COMMENT = \"# header comment\\r\\nA,B\\r\\n1,2\\r\\n\";\n    private static final String CSV_INPUT_HEADER_TRAILER_COMMENT = \"# header comment\\r\\nA,B\\r\\n1,2\\r\\n# trailer comment\\r\\n\";\n    private static final String CSV_INPUT_MULTILINE_HEADER_TRAILER_COMMENT = \"# multi-line\\r\\n# header comment\\r\\nA,B\\r\\n1,2\\r\\n# multi-line\\r\\n# trailer comment\\r\\n\";\n    private static final CSVFormat FORMAT_AUTO_HEADER = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader().get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").setSkipHeaderRecord(true).get();\n    private static final CSVFormat FORMAT_EXPLICIT_HEADER_NOSKIP = CSVFormat.DEFAULT.builder().setCommentMarker('#').setHeader(\"A\", \"B\").get();\n\n    private void assertValuesEquals(final String[] expected, final CSVRecord actual) {\n        assertArrayEquals(expected, actual.values());\n    }\n\n    @ParameterizedTest\n    @ValueSource(longs = { -1, 0, 1, 2, 3, 4, Long.MAX_VALUE })\n    public void testGetRecordsMaxRows(final long maxRows) throws IOException {\n        try (final CSVParser parser = CSVParser.parse(CSV_INPUT,\n                CSVFormat.DEFAULT.builder().setIgnoreSurroundingSpaces(true).setMaxRows(maxRows).get())) {\n            final List<CSVRecord> records = parser.getRecords();\n            final long expectedLength = maxRows <= 0 || maxRows > RESULT.length ? RESULT.length : maxRows;\n            assertEquals(expectedLength, records.size());\n            if (expectedLength > 0) {\n                assertFalse(records.isEmpty());\n            }\n            for (int i = 0; i < expectedLength; i++) {\n                assertValuesEquals(RESULT[i], records.get(i));\n            }\n        }\n    }\n}",
      "method_signature": "testGetRecordsMaxRows(long)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.6667,
      "callable_recall": 0.9167,
      "callable_precision": 0.7857,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9412,
      "line_coverage": 0.9188,
      "branch_coverage": 0.9178
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 45,
      "description": "Define a parameterized test method that accepts each enumeration value from the Token Type enumeration to validate the string representation behavior of a Token instance across various states and type assignments. Instantiate a new Token object and capture the name of the INVALID type constant for reference throughout the test. Immediately invoke the toString method on the newly created token and assert that the resulting string contains the INVALID type name, establishing the baseline state representation. Reset the token to its initial state and verify once more that toString still includes the INVALID type name, confirming reset behavior preserves the default type representation. Directly assign null to the token's type field and validate that the toString output is not empty, demonstrating robustness when the type is explicitly nullified. Reset the token again to restore its default state, then assign the parameterized type value to the token's type field and assert that toString now contains the name of the assigned type, verifying correct type reflection in the string representation. Modify the token's internal content buffer by setting its length to a large value such as one thousand characters, then confirm that toString continues to include the assigned type name, ensuring the string representation remains stable even when content size changes significantly. This test uses JUnit 5 for parameterization and standard assertion methods.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenToStringTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport org.apache.commons.csv.Token.Type;\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\n/**\n * Tests for {@link Token#toString()}.\n */\npublic class TokenToStringTest {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    public void testToString(final Token.Type type) {\n        final Token token = new Token();\n        final String invalidName = Type.INVALID.name();\n\n        assertTrue(token.toString().contains(invalidName));\n\n        token.reset();\n        assertTrue(token.toString().contains(invalidName));\n\n        token.type = null;\n        assertFalse(token.toString().isEmpty());\n\n        token.reset();\n        token.type = type;\n        assertTrue(token.toString().contains(type.name()));\n\n        token.content.setLength(1000);\n        assertTrue(token.toString().contains(type.name()));\n    }\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 1.0,
      "callable_precision": 1.0,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2,
          "write_file": 1,
          "run_shell_command": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 94117,
    "output_tokens": 4282,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 49,
      "description": "Create a test case to validate that the system correctly processes and formats data when receiving information through a concurrent processing stream. Configure a temporary output destination to capture the formatted results, then establish a formatting handler using standard comma-separated value conventions. Submit a collection of values for processing where the data arrives through a parallel execution pathway rather than sequentially, ensuring the system properly serializes and formats these concurrently-processed values into a single delimited record. After the formatting operation completes and resources are released, verify that the output destination contains the correctly formatted record with all values properly delimited and terminated according to the expected business format specifications. Use JUnit 5 as the testing framework and verify the final output matches the expected format using standard equality assertions.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterParallelStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests the behavior of CSVPrinter when handling data from concurrent sources.\n */\npublic class CSVPrinterParallelStreamTest {\n\n    /**\n     * Tests that the system correctly processes and formats a single record\n     * from values generated via a parallel stream.\n     *\n     * @throws IOException if an I/O error occurs\n     */\n    @Test\n    public void testSingleRecordFromParallelStream() throws IOException {\n        final StringWriter writer = new StringWriter();\n        try (final CSVPrinter printer = new CSVPrinter(writer, CSVFormat.DEFAULT)) {\n            // A collection of values to be processed.\n            final List<String> values = Arrays.asList(\"value1\", \"value2\", \"value3\", \"value4\");\n\n            // The data arrives through a parallel execution pathway.\n            final List<Object> concurrentlyProcessedValues = values.parallelStream()\n                    .collect(Collectors.toList());\n\n            // The system serializes and formats the values into a single delimited record.\n            printer.printRecord(concurrentlyProcessedValues);\n        }\n\n        // Verify the output destination contains the correctly formatted record.\n        final String expectedOutput = \"value1,value2,value3,value4\\r\\n\";\n        assertEquals(expectedOutput, writer.toString());\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.2857,
      "callable_precision": 0.4444,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9667,
      "line_coverage": 0.9677,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 53,
      "description": "Create a test case to validate that the system correctly formats a collection of text values into a properly delimited output format using default formatting rules. Begin by preparing an in-memory output destination to capture the formatted results, then configure a formatting tool using standard delimiter and quoting conventions. Supply a sequence of three column values representing typical record data, instruct the formatting tool to process these values as a single record entry, then close the formatting tool to finalize the output. After processing, verify that the captured output matches the expected format by comparing it against the standard representation for such data, ensuring proper delimiter placement, quote handling, and record termination according to the default formatting specification. Use JUnit 5 as the testing framework and verify the output correctness using standard equality assertions to confirm the formatted text matches business expectations for delimited value representation.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterDefaultFormatTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.IOException;\nimport java.io.StringWriter;\nimport java.util.Arrays;\n\n/**\n * A test case to validate that the CSVPrinter correctly formats a collection of\n * text values into a properly delimited output format using default formatting rules.\n */\npublic class CSVPrinterDefaultFormatTest {\n\n    /**\n     * Tests the printing of a single record with default CSV format settings.\n     * The test verifies that the output string matches the expected comma-separated\n     * format with a correct record terminator.\n     *\n     * @throws IOException if an I/O error occurs\n     */\n    @Test\n    public void testDefaultRecordFormatting() throws IOException {\n        StringWriter stringWriter = new StringWriter();\n        // Use default format: comma-delimited, quoting enabled, CRLF for record separation.\n        CSVFormat format = CSVFormat.DEFAULT;\n\n        try (CSVPrinter printer = new CSVPrinter(stringWriter, format)) {\n            // Supply a sequence of three column values for a single record.\n            printer.printRecord(\"data1\", \"data2\", \"data3\");\n        } // printer is auto-closed here, finalizing the output.\n\n        // Expected format: values separated by commas, terminated by a carriage return and line feed.\n        String expectedOutput = \"data1,data2,data3\\r\\n\";\n\n        // Verify that the captured output matches the expected delimited format.\n        assertEquals(expectedOutput, stringWriter.toString());\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.3333,
      "callable_precision": 0.8,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9677,
      "line_coverage": 0.9686,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 55,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources block, create a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where the first argument is a `PrintWriter` wrapping `baos` and the second is the static constant `CSVFormat.DEFAULT`, immediately invoke `printRecord` on `printer` passing a `Stream<String>` obtained by first calling a private method that returns `newStream().parallel()` (where `newStream()` produces the base stream and `parallel()` converts it to a parallel stream), and upon exiting the try-with-resources block (which auto-closes the printer), invoke a private method that calls `baos.toString()` and passes the resulting String to another private method for output verification. Annotate the test method with `@Test` and declare it to throw `IOException`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.stream.Stream;\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests for {@link CSVPrinter}.\n */\npublic class CSVPrinterStreamTest {\n\n    private void check(final String expected, final String actual) {\n        assertEquals(expected, actual);\n    }\n\n    private Stream<String> newStream() {\n        return Stream.of(\"one\", \"two\", \"three\");\n    }\n\n    private void runTest(final ByteArrayOutputStream baos) {\n        check(\"one,two,three\\r\\n\", baos.toString());\n    }\n\n    @Test\n    public void testPrintRecordStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(newStream().parallel());\n        }\n        runTest(baos);\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.3333,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.6429,
      "callable_precision": 0.8182,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 58,
      "description": "Create a test case to validate that the system can reliably produce a textual representation of a token across all possible token classification states and edge conditions without encountering failures. Begin by establishing a new token in its initial state and verify that its textual representation includes the default classification label. After confirming the initial state, restore the token to its baseline configuration and ensure the representation still reflects the default classification. Simulate an exceptional scenario where the token's classification becomes undefined, then verify the system still produces a meaningful textual representation rather than failing or returning empty content. Following this edge case validation, restore the token again to its baseline and then configure it with each possible classification type from the system's complete set of token categories. For every classification type, confirm the textual representation accurately includes the corresponding classification label. Additionally, simulate a scenario where the token's internal content grows to a substantial size and verify the textual representation continues to display the correct classification label regardless of content volume, ensuring the representation mechanism remains stable under varying data conditions. This validation uses JUnit 5 with parameterized testing to exercise all classification variations, applying standard equality and containment assertions to verify the business outcomes.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenToStringTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\n/**\n * Validates the textual representation of a {@link Token} across various states.\n */\npublic class TokenToStringTest {\n\n    private static final int LARGE_CONTENT_SIZE = 10000;\n\n    /**\n     * Tests that a token's textual representation accurately reflects its classification\n     * state across all possible token types and edge conditions, including substantial\n     * content volumes. This test uses parameterization to ensure complete coverage of\n     * all {@link Token.Type} enumeration values.\n     *\n     * @param type The token type to be tested, provided by the EnumSource.\n     */\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testTokenToStringProducesCorrectTextualRepresentation(final Token.Type type) {\n        final Token token = new Token();\n        final char[] content = \"test-content\".toCharArray();\n        token.reset(type, content, content.length, true);\n\n        // Verify that the textual representation starts with the correct classification label.\n        final String tokenString = token.toString();\n        assertTrue(tokenString.startsWith(type.name()),\n            () -> \"Representation for type \" + type + \" should start with its name.\");\n\n        // The INVALID type naturally covers the initial, baseline, and exceptional undefined states.\n        if (type == Token.Type.INVALID) {\n            final Token initialToken = new Token();\n            assertTrue(initialToken.toString().startsWith(\"INVALID\"),\n                \"A new token's initial state should be represented as INVALID.\");\n        }\n\n        // Simulate a scenario with substantially large content for one token type to test stability.\n        if (type == Token.Type.TOKEN) {\n            final StringBuilder largeContentBuilder = new StringBuilder(LARGE_CONTENT_SIZE);\n            for (int i = 0; i < LARGE_CONTENT_SIZE; i++) {\n                largeContentBuilder.append('X');\n            }\n            final char[] largeContent = largeContentBuilder.toString().toCharArray();\n            token.reset(Token.Type.TOKEN, largeContent, largeContent.length, true);\n\n            final String largeTokenString = token.toString();\n            assertTrue(largeTokenString.startsWith(\"TOKEN\"),\n                \"Classification label should remain correct regardless of content volume.\");\n            assertTrue(largeTokenString.contains(\"content=\"),\n                \"Representation should remain stable and not fail under large content conditions.\");\n        }\n    }\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 24334,
    "output_tokens": 15616,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 59,
      "description": "Define a test method annotated with `@Test` that declares it throws `IOException`, then instantiate a `ByteArrayOutputStream` and assign it to variable `baos`, followed by opening a try-with-resources block that creates a `CSVPrinter` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` and assigns it to variable `printer`, then within the try block invoke `printRecord` on `printer` passing a `Stream<String>` created by calling `newStream().sequential()` as the argument (where `newStream()` returns a stream of strings), and upon exiting the try-with-resources block (which automatically closes `printer`), invoke `toString()` on `baos` to convert the byte array output stream to a string and pass that string to a verification method that asserts the output matches the expected CSV format. The test uses JUnit 5 with the `@Test` annotation and standard Java I/O classes (`ByteArrayOutputStream`, `PrintWriter`) along with Apache Commons CSV classes (`CSVPrinter`, `CSVFormat`).",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.stream.Stream;\n\nimport org.junit.jupiter.api.Test;\n\npublic class CSVPrinterStreamTest {\n\n    private Stream<String> newStream() {\n        return Stream.of(\"a\", \"b\", \"c\");\n    }\n\n    @Test\n    public void testPrintRecordStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(newStream().sequential());\n        }\n        assertEquals(\"a,b,c\n\", baos.toString());\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 25805,
    "output_tokens": 1351,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 63,
      "description": "Define a test method that validates the CSV Printer's ability to write a stream of string values as a single record to an output destination. Initialize a ByteArrayOutputStream to capture the CSV output, then create a private helper method that constructs a CSV Printer instance wrapping the output stream with a PrintWriter and configuring it to use the default CSV format. Invoke this helper to obtain the printer within a try-with-resources block to ensure automatic closure. Create another private helper method that generates a stream containing three string column values, then pass this stream to the printer's printRecord method which accepts a Stream parameter to write the values as a delimited record. Upon closing the printer, invoke a private helper method that accepts the ByteArrayOutputStream and validates the generated CSV output by converting the stream contents to a string representation and verifying the expected format, delimiter placement, and value sequence. The test uses JUnit 5 for the testing framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.stream.Stream;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\n/**\n * Tests for {@link CSVPrinter} writing a stream of values.\n */\npublic class CSVPrinterStreamTest {\n\n    private CSVPrinter createPrinter(final ByteArrayOutputStream out) throws IOException {\n        return new CSVPrinter(new PrintWriter(out), CSVFormat.DEFAULT);\n    }\n\n    private Stream<String> createStream() {\n        return Stream.of(\"value1\", \"value2\", \"value3\");\n    }\n\n    private void validateOutput(final ByteArrayOutputStream out) {\n        final String expected = \"value1,value2,value3\" + CSVFormat.DEFAULT.getRecordSeparator();\n        assertEquals(expected, out.toString(StandardCharsets.UTF_8));\n    }\n\n    @Test\n    public void testPrintRecordStream() throws IOException {\n        final ByteArrayOutputStream out = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = createPrinter(out)) {\n            printer.printRecord(createStream());\n        }\n        validateOutput(out);\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 23556,
    "output_tokens": 4503,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 67,
      "description": "Define a parameterized test method accepting a single parameter of type `org.apache.commons.csv.Token.Type`, annotated with `@ParameterizedTest` and `@EnumSource(Token.Type.class)` to supply all enum constants of `Token.Type` as test inputs. Begin by instantiating a new `Token` object using the no-argument constructor and assign it to a final variable named `token`. Immediately retrieve the name of the `Token.Type.INVALID` enum constant by invoking `Token.Type.INVALID.name()` and assign the resulting `String` to a final variable named `resetName`. Invoke `toString()` on `token`, then invoke `contains(resetName)` on the returned `String`, and assert the result is true using `assertTrue`. Next, invoke `reset()` on `token`, then again invoke `toString()` on `token`, call `contains(resetName)` on the result, and assert true using `assertTrue`. Directly assign `null` to the `type` field of `token`, invoke `toString()` on `token`, call `isEmpty()` on the returned `String`, and assert the result is false using `assertFalse`. Invoke `reset()` on `token`, then assign the parameterized `type` argument to the `type` field of `token`. Invoke `toString()` on `token`, call `contains(type.name())` on the result where `type.name()` retrieves the name of the current parameter enum constant, and assert true using `assertTrue`. Access the `content` field of `token` (which is a `StringBuilder`) and invoke `setLength(1000)` on it. Finally, invoke `toString()` on `token`, call `contains(type.name())` on the returned `String`, and assert true using `assertTrue`. The test uses JUnit 5 Assertions with annotations `@ParameterizedTest` and `@EnumSource(Token.Type.class)`.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.TokenTest",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.TokenTest1",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.EnumSource;\n\n/**\n * Tests {@link Token}.\n */\nclass TokenTest1 {\n\n    @ParameterizedTest\n    @EnumSource(Token.Type.class)\n    void testToString(final Token.Type type) {\n        final Token token = new Token();\n        final String resetName = Token.Type.INVALID.name();\n        assertTrue(token.toString().contains(resetName));\n        token.reset();\n        assertTrue(token.toString().contains(resetName));\n        token.type = null;\n        assertThrows(NullPointerException.class, () -> assertFalse(token.toString().isEmpty()));\n        token.reset();\n        token.type = type;\n        assertTrue(token.toString().contains(type.name()));\n        token.content.setLength(1000);\n        assertTrue(token.toString().contains(type.name()));\n    }\n\n}",
      "method_signature": "testToString(org.apache.commons.csv.Token.Type)"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 0.8,
      "assertion_precision": 0.8,
      "callable_recall": 0.9545,
      "callable_precision": 0.9545,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 19897,
    "output_tokens": 8661,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": false,
    "nl2test_input": {
      "id": 68,
      "description": "Define a test method that validates CSV printing behavior when a sequential stream is used as input by initializing a ByteArrayOutputStream to capture the printed output, then create a private helper method that constructs a CSV Printer configured with the default CSV format and wraps the output stream in a PrintWriter. Create another private helper method that generates a sequential stream of string values by obtaining a base stream and explicitly marking it as sequential. Invoke the print record method on the CSV Printer passing the sequential stream as the record data source, which will internally iterate over the stream elements and write each value to the output stream according to the format's delimiter and quoting rules. Upon completion of the print operation, close the CSV Printer resource to flush any buffered content to the underlying output stream. Create a private helper method that validates the captured output by converting the ByteArrayOutputStream contents to a string representation and verifying the formatted CSV record matches expected structure and content. This test uses JUnit 5 for the test framework and standard Java I/O libraries for stream handling.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testSequentialStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterSequentialStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.stream.Stream;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Validates CSV printing behavior when a sequential stream is used as input.\n */\npublic class CSVPrinterSequentialStreamTest {\n\n    private void validate(final ByteArrayOutputStream out) {\n        assertEquals(\"a,b,c\\r\\n\", out.toString(StandardCharsets.UTF_8));\n    }\n\n    private CSVPrinter constructCsvPrinter(final ByteArrayOutputStream out) throws IOException {\n        return new CSVPrinter(new PrintWriter(out), CSVFormat.DEFAULT);\n    }\n\n    private Stream<String> generateSequentialStream() {\n        return Stream.of(\"a\", \"b\", \"c\").sequential();\n    }\n\n    @Test\n    public void testPrintRecordWithSequentialStream() throws IOException {\n        final ByteArrayOutputStream out = new ByteArrayOutputStream();\n        try (final CSVPrinter printer = constructCsvPrinter(out)) {\n            printer.printRecord(generateSequentialStream()::iterator);\n        }\n        validate(out);\n    }\n}",
      "method_signature": "testSequentialStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 0.0,
      "obj_creation_precision": 0.0,
      "assertion_recall": 0.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.0,
      "callable_precision": 0.0,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 0.0,
      "method_coverage": 0.0,
      "line_coverage": 0.0,
      "branch_coverage": 0.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 69,
      "description": "Define a test method that declares a `ByteArrayOutputStream` named `baos` by invoking its no-argument constructor, then within a try-with-resources statement instantiate a `CSVPrinter` named `printer` by invoking `new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)` where `CSVFormat.DEFAULT` is the static constant from the `CSVFormat` class, immediately invoke `printRecord` on `printer` passing the result of `Stream.of(\"col a\", \"col b\", \"col c\")` as the argument, and upon exiting the try-with-resources block invoke a private method that executes the logic of converting `baos` to a `String` via `baos.toString()` and then passing that `String` to another private method for output verification (define these private methods to encapsulate the exact behavior: the first accepts a `ByteArrayOutputStream` and calls `toString()` on it before delegating to the second method, and the second accepts a `String` and performs the necessary assertions on the formatted output). Annotations: method-level `@Test`. Assertion libraries: implementation-dependent (based on the private verification method). Mocking libraries: none.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testDefaultStream()",
      "abstraction_level": "low",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterTest1",
      "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.csv;\n\nimport org.junit.jupiter.api.Test;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.stream.Stream;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\npublic class CSVPrinterTest1 {\n\n    @Test\n    public void testPrintRecordStream() throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (CSVPrinter printer = new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT)) {\n            printer.printRecord(Stream.of(\"col a\", \"col b\", \"col c\"));\n        }\n        verifyOutput(baos);\n    }\n\n    private void verifyOutput(ByteArrayOutputStream baos) {\n        verifyString(baos.toString());\n    }\n\n    private void verifyString(String output) {\n        assertEquals(\"col a,col b,col c\\r\\n\", output);\n    }\n}",
      "method_signature": "testDefaultStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 0.3333,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.5833,
      "callable_precision": 0.7778,
      "focal_recall": 1.0,
      "focal_precision": 1.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 1.0,
      "line_coverage": 1.0,
      "branch_coverage": 1.0
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 2,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 70,
      "description": "Define a test method that validates CSV printing behavior when processing a parallel stream of strings by initializing a byte array output stream to capture the printed output, then create a private helper method that constructs a CSV printer wrapping the byte stream with a print writer configured for default CSV format, and create another private helper method that generates a parallel stream of strings by converting a standard stream to parallel mode. Invoke the print record method on the CSV printer passing the parallel stream as input, which internally acquires a reentrant lock, adapts the stream based on its parallel status, processes each element through ordered iteration, and releases the lock upon completion. After the printer resource is automatically closed, create a private helper method that validates the output by converting the byte stream to a string representation and comparing it against expected CSV formatting. The test verifies that the CSV printer correctly handles parallel stream inputs by ensuring thread-safe record printing and proper delimiter-separated value formatting. This test uses JUnit 5 for the test framework.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.JiraCsv318Test",
      "method_signature": "testParallelStream()",
      "abstraction_level": "medium",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.CSVPrinterParallelStreamTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Stream;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Tests CSV printing behavior when processing a parallel stream.\n */\npublic class CSVPrinterParallelStreamTest {\n\n    private CSVPrinter createCsvPrinter(final ByteArrayOutputStream baos) throws IOException {\n        return new CSVPrinter(new PrintWriter(baos), CSVFormat.DEFAULT);\n    }\n\n    private Stream<List<String>> createParallelStream() {\n        return Stream.of(\n            Arrays.asList(\"a\", \"b\", \"c\"),\n            Arrays.asList(\"d\", \"e\", \"f\"),\n            Arrays.asList(\"g\", \"h\", \"i\")\n        ).parallel();\n    }\n\n    private void validateOutput(final ByteArrayOutputStream baos) {\n        final String expected = \"a,b,c\\r\\nd,e,f\\r\\ng,h,i\\r\\n\";\n        final String actual = new String(baos.toByteArray(), StandardCharsets.UTF_8);\n        assertEquals(expected, actual);\n    }\n\n    @Test\n    public void testPrintRecordsWithParallelStream() throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try (final CSVPrinter csvPrinter = createCsvPrinter(baos)) {\n            final Stream<List<String>> parallelStream = createParallelStream();\n            // The printRecords method internally handles the stream, including parallel streams,\n            // by using a ReentrantLock to ensure thread-safe writing of records.\n            csvPrinter.printRecords(parallelStream);\n        } // CSVPrinter is closed automatically, which flushes the underlying PrintWriter.\n        validateOutput(baos);\n    }\n}",
      "method_signature": "testParallelStream()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 1.0,
      "callable_recall": 0.4286,
      "callable_precision": 0.4,
      "focal_recall": 0.0,
      "focal_precision": 0.0
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9667,
      "line_coverage": 0.9677,
      "branch_coverage": 0.973
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 0,
    "output_tokens": 0,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  },
  {
    "compiles": true,
    "nl2test_input": {
      "id": 95,
      "description": "Create a test case to validate that the system correctly processes CSV data formatted according to PostgreSQL conventions, ensuring that missing values are interpreted appropriately across multiple records. Load a sample CSV file from the test resources that contains three records, each demonstrating different patterns of empty and missing cell values. Process the file using the PostgreSQL CSV formatting rules and retrieve the records sequentially. For the first record, verify that the system captures two populated values followed by a missing value represented as absent data. For the second record, confirm that the system distinguishes between a missing value in the middle position and an explicitly empty value in the final position. For the third record, ensure that the system correctly handles a missing value at the beginning while preserving the subsequent populated values. The test confirms that the parsing logic respects the PostgreSQL CSV specification for handling various forms of absent data, including true null values versus empty strings. Upon completion, release any resources held during the file processing operation. The validation strategy employs JUnit 5 as the testing framework with standard equality assertions to confirm the expected value patterns in each record.",
      "project_name": "commons-csv",
      "qualified_class_name": "org.apache.commons.csv.issues.JiraCsv254Test",
      "method_signature": "test()",
      "abstraction_level": "high",
      "is_bdd": false
    },
    "nl2test_metadata": {
      "qualified_test_class_name": "org.apache.commons.csv.PostgreSQLCsvTest",
      "code": "package org.apache.commons.csv;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertNull;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.List;\n\nimport org.junit.jupiter.api.Test;\n\n/**\n * Test case for parsing PostgreSQL CSV format, focusing on handling of missing and empty values.\n */\npublic class PostgreSQLCsvTest {\n\n    /**\n     * Validates that the parser correctly interprets missing values (nulls) and empty strings\n     * according to PostgreSQL's CSV conventions. The test reads a predefined CSV file from the\n     * test resources and asserts the content of each record against expected patterns of populated,\n     * missing, and empty values.\n     *\n     * @throws IOException if an I/O error occurs during file reading.\n     */\n    @Test\n    public void testPostgreSQLCsvParsingWithNulls() throws IOException {\n        final String filePath = \"src/test/resources/org/apache/commons/csv/CSV-290/psql.csv\";\n        try (final Reader reader = Files.newBufferedReader(Paths.get(filePath));\n             final CSVParser parser = CSVFormat.POSTGRESQL_CSV.parse(reader)) {\n\n            final List<CSVRecord> records = parser.getRecords();\n            assertEquals(3, records.size(), \"Should contain three records\");\n\n            // Record 1: Asserts two values followed by a missing value (null)\n            final CSVRecord record1 = records.get(0);\n            assertEquals(3, record1.size());\n            assertEquals(\"value1\", record1.get(0));\n            assertEquals(\"value2\", record1.get(1));\n            assertNull(record1.get(2));\n\n            // Record 2: Asserts a missing value between a populated and an empty value\n            final CSVRecord record2 = records.get(1);\n            assertEquals(3, record2.size());\n            assertEquals(\"value3\", record2.get(0));\n            assertNull(record2.get(1));\n            assertEquals(\"\", record2.get(2));\n\n            // Record 3: Asserts a missing value at the beginning of the record\n            final CSVRecord record3 = records.get(2);\n            assertEquals(3, record3.size());\n            assertNull(record3.get(0));\n            assertEquals(\"value4\", record3.get(1));\n            assertEquals(\"value5\", record3.get(2));\n        }\n    }\n}",
      "method_signature": "test()"
    },
    "structured_eval": {
      "obj_creation_recall": 1.0,
      "obj_creation_precision": 1.0,
      "assertion_recall": 1.0,
      "assertion_precision": 0.0,
      "callable_recall": 0.3,
      "callable_precision": 0.0909,
      "focal_recall": 0.5,
      "focal_precision": 0.25
    },
    "coverage_eval": {
      "class_coverage": 1.0,
      "method_coverage": 0.9844,
      "line_coverage": 0.9858,
      "branch_coverage": 0.9846
    },
    "localization_eval": null,
    "tool_log": {
      "supervisor_tool_log": {
        "tool_counts": {
          "read_file": 1,
          "write_file": 1
        },
        "tool_trajectories": []
      },
      "localization_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      },
      "composition_tool_log": {
        "tool_counts": {},
        "tool_trajectories": []
      }
    },
    "input_tokens": 27882,
    "output_tokens": 15721,
    "llm_calls": 0,
    "failed_test_file_generation": false,
    "failed_code_generation": false
  }
]